{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Agents**\n",
    "\n",
    "An agent-based workflow where LLMs act autonomously within a loop, interacting with their environment and receiving feedback to refine their actions and decisions.\n",
    "\n",
    "\n",
    "<img src=\"../images/autonomous-agent.webp\" alt=\"Autonomous Agents\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Use Cases:**\n",
    " \n",
    "- Building a personal research assistant that autonomously searches academic papers, extracts key findings, and generates literature review summaries based on specific research questions.\n",
    "- Creating an autonomous code reviewer that analyzes pull requests, identifies potential bugs and security issues, suggests improvements, and generates detailed review comments.\n",
    "- Developing a customer support agent that handles inquiries by searching knowledge bases, generating appropriate responses, and escalating complex issues to human agents when needed.\n",
    "- Managing social media presence by analyzing trending topics, generating relevant content, scheduling posts, and engaging with followers through personalized responses.\n",
    "- Building an autonomous testing agent that generates test cases, executes tests, analyzes failures, and provides detailed bug reports with suggested fixes.\n",
    "- Creating a data monitoring agent that continuously analyzes system metrics, detects anomalies, investigates root causes, and generates incident reports with recommended actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai pydantic --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-xxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL=\"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define a sample function the agent can call.\n",
    "# In practice, you might connect to real APIs or services for your agent's tasks.\n",
    "def search_knowledge_base(query: str, options: dict) -> str:\n",
    "    \"\"\"\n",
    "    Pretend to look for information about the provided query in a knowledge base.\n",
    "    Returns a brief summary as a string.\n",
    "    \"\"\"\n",
    "    # For demonstration, we'll return a placeholder string.\n",
    "    # In a real scenario, you'd perform a search and generate a proper result.\n",
    "    return f\"Summary for '{query}': This is a simulated summary from the knowledge base.\"\n",
    "\n",
    "# Next, we define our function schema to provide to the model.\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"search_knowledge_base\",\n",
    "        \"description\": \"Query a knowledge base to retrieve relevant info on a topic.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The user question or search query.\"\n",
    "                },\n",
    "                \"options\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"num_results\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"Number of top results to return.\"\n",
    "                        },\n",
    "                        \"domain_filter\": {\n",
    "                            \"type\": [\n",
    "                                \"string\",\n",
    "                                \"null\"\n",
    "                            ],\n",
    "                            \"description\": \"Optional domain to narrow the search (e.g. 'finance', 'medical'). Pass null if not needed.\"\n",
    "                        },\n",
    "                        \"sort_by\": {\n",
    "                            \"type\": [\n",
    "                                \"string\",\n",
    "                                \"null\"\n",
    "                            ],\n",
    "                            \"enum\": [\n",
    "                                \"relevance\",\n",
    "                                \"date\",\n",
    "                                \"popularity\",\n",
    "                                \"alphabetical\"\n",
    "                            ],\n",
    "                            \"description\": \"How to sort results. Pass null if not needed.\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\n",
    "                        \"num_results\",\n",
    "                        \"domain_filter\",\n",
    "                        \"sort_by\"\n",
    "                    ],\n",
    "                    \"additionalProperties\": False\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"query\",\n",
    "                \"options\"\n",
    "            ],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}]\n",
    "\n",
    "# We simulate a user asking the agent a question that might prompt the model to call the function.\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello, I'd like to know more about quantum computing. Could you give me a quick summary?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Step 1: We call the model, providing the function tools. The model may decide to call the tool.\n",
    "completion_1 = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function -  search_knowledge_base\n"
     ]
    }
   ],
   "source": [
    "# Step 2: The model might return a tool call. We'll check for any function calls and execute them.\n",
    "tool_calls = completion_1.choices[0].message.tool_calls\n",
    "\n",
    "results = []\n",
    "if tool_calls:\n",
    "    for call in tool_calls:\n",
    "        function_name = call.function.name\n",
    "        # Parse the JSON arguments:\n",
    "        function_args = json.loads(call.function.arguments)\n",
    "        \n",
    "        if function_name == \"search_knowledge_base\":\n",
    "            print('Calling function - ', function_name)\n",
    "            search_result = search_knowledge_base(**function_args)\n",
    "            # We'll store the result and associate it with this tool_call\n",
    "            results.append(\n",
    "                {\n",
    "                    \"tool_call_id\": call.id,\n",
    "                    \"content\": search_result\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: We send the results back to the model so it can incorporate them into its final answer.\n",
    "# We'll add both the original function call message and the tool's reply to our conversation.\n",
    "\n",
    "if tool_calls and results:\n",
    "    # Append the tool call message from the model\n",
    "    messages.append(completion_1.choices[0].message)\n",
    "    # Append our result(s) as 'tool' role messages\n",
    "    for r in results:\n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": r[\"tool_call_id\"],\n",
    "            \"content\": r[\"content\"]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer from Agent:\n",
      "Quantum computing is an advanced field of computing that uses the principles of quantum mechanics to process information. Unlike classical computers, which use bits as the smallest unit of data (0 or 1), quantum computers use quantum bits or qubits. Qubits can exist in multiple states simultaneously due to superposition, and they can be entangled, meaning the state of one qubit can depend on the state of another, even at a distance. This allows quantum computers to potentially solve complex problems much faster than classical computers, particularly in areas like cryptography, optimization, and simulation of quantum systems.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Make another call to the model, now that it has the tool's output.\n",
    "completion_2 = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "# Finally, we print out the model's final answer. This is how the user sees it.\n",
    "final_answer = completion_2.choices[0].message.content\n",
    "print(\"Final Answer from Agent:\")\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Alternative Approach\n",
    "\n",
    "If an agent has finished all of it's tool calls, then it has likely finished with the task. \n",
    "\n",
    "Therefore we could also write the above code within a while loop that checks if the agent has finished all of it's tool calls. If it has, then we can break the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_knowledge_base(query: str, options: dict) -> str:\n",
    "    \"\"\"\n",
    "    Pretend to look for information about the provided query in a knowledge base.\n",
    "    \"\"\"\n",
    "    return f\"ChatGPT is a large language model developed by OpenAI.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function -  search_knowledge_base\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"user\", \"content\": \"Can you find information about ChatGPT in the AI knowledge base?\"})\n",
    "\n",
    "while True:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "    tool_calls = completion.choices[0].message.tool_calls\n",
    "    if not tool_calls:\n",
    "        break\n",
    "    else: \n",
    "        for call in tool_calls:\n",
    "            # Add the tool call to the messages\n",
    "            messages.append(completion.choices[0].message)\n",
    "            \n",
    "            # Parse the JSON arguments:\n",
    "            function_name = call.function.name\n",
    "            function_args = json.loads(call.function.arguments)\n",
    "            if function_name == \"search_knowledge_base\":\n",
    "                print('Calling function - ', function_name)\n",
    "                search_result = search_knowledge_base(**function_args)\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": call.id,\n",
    "                    \"content\": search_result\n",
    "                })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
