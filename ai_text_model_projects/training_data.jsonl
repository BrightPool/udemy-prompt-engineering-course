{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How Agencies Make Money' for the blog post 'Agency Economics'"}, {"role": "assistant", "content": "Where does your money go when you hire a marketing agency? What can the economics of an agency tell you about when to hire one? How can you avoid being ripped off when working with an agency?If you work in an agency, you might similarly be wondering why so little of the revenue you manage ends up in your paycheck. If you run an agency, you\u2019re probably frustrated at how little you make in profit, and every month you struggle to make payroll.As the agency I founded grew from 2, to 20, and then 50 people, I spent a lot of time with difficult clients, talking to similarly exasperated agency owners and figuring out how agencies make money. So now that I\u2019ve left the agency world, I\u2019m putting a model out there to show how agencies work, what incentives they have and how to use that information.Feel free to jump straight into the model and play around.UPDATE: I built a better model in a tool called Causal, which lets you easily forecast a range of outcomes. I find it's a little easier to understand than gsheets.There are three major metrics that determine how much money an agency makes. It\u2019s important to understand each one and how it drives incentives.Revenue \u2014 how much do they charge clients?Variable Costs \u2014 how much does it cost to service clients?Fixed Costs \u2014 what overheads do they have aside from client work?"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Revenue' for the blog post 'Agency Economics'"}, {"role": "assistant", "content": "There are lots of ways to charge for agency services, by the hour, based on value or as a retainer. Whatever way you pay, it always comes down to number of clients and average revenue per month per client.\u00a0The way the agency charges will affect their behavior, but only in that it will affect their risk of collecting payment. This always backs out to an expected value based on risk, so if there\u2019s a $20,000 bonus payment with a 10% chance of success, that\u2019s worth ~$2,000 in cash."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Variable Costs' for the blog post 'Agency Economics'"}, {"role": "assistant", "content": "Regardless of how you make money, the number one cost of any agency is staff. They might be freelance or employed full time, but there is a fixed number of hours in a week, and an average capacity in terms of hours of work each client takes each month. Bonus payments, equity or other incentives can change behavior, but you can always put a risk-adjusted price on them and work out the effective hourly rate.Now this is where you\u2019re probably getting angry. You\u2019re seeing that for the $5,000 a client paid, only $1,505 or 30% of it went to the person actually doing the work!? Worse, the charming, talented founder you wanted to work with in the sales meetings is barely going to be present, what with 39 other clients and a business to run. No wonder working with an agency feels like getting ripped off."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Fixed Costs' for the blog post 'Agency Economics'"}, {"role": "assistant", "content": "This is where the agency model is made or broken. Small agencies have very few fixed costs, so don\u2019t charge a big enough gross margin. Then as they grow, and need to layer on marketing, sales, HR, finance, etc, they are confronted with reality \u2014 they either go out of business, stop growing, or learn to charge more.These are just illustrative costs per client for a 40 client, 20 person agency collecting $200,000 a month. This isn\u2019t exactly what Ladder paid (I don\u2019t have access to those records anymore) but I made realistic assumptions based on my knowledge of the US market. Each cost is relatively small, but in real terms it means we\u2019re down from 70% gross profit to 15% net margin."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Explaining Fixed Costs' for the blog post 'Agency Economics'"}, {"role": "assistant", "content": "In this fictional (but typical) agency, we have two executives (usually the founders) who pay themselves $150,000 a year. There are 3 in management, earning $110,000 each, and 1 person for each department of sales, marketing, finance and HR.\u00a0I also added a $5,000 per month advertising budget (usually a mix of Google and LinkedIn Ads, blog content production, event sponsorship and production of sales materials). There\u2019s also a $5,000 annual budget to advertise jobs (a recruiter costs 20% of first year salary per hire, so assume you can\u2019t afford one). \u2018Other\u2019 captures the cost of SaaS subscriptions (easily more than $5k per month at scale), office space and travel & entertainment.This adds up to an eye-watering $2,730 per month per client, or more than half of every dollar they pay you, just going to fixed admin costs. This is how whole teams of smart, hard-working, talented agency folks can work long hours and still be left in a precarious financial situation.\u00a0You thought they were ripping off their clients, and yet, the agency owners are still only collecting $20 profit per hour from your account \u2014 and this is a healthy agency that charges enough! According to Campaign magazine, agencies should target 15-20%, yet the top 50 UK agencies reported an average of 10.4% profit margin."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Why Must Agencies Charge So Much?' for the blog post 'Agency Economics'"}, {"role": "assistant", "content": "Diving into the model, you can play agency owner and see why. Change any of the assumptions in blue on the right to simulate what would happen. Think the management team gets paid too much? Decrease the salary and see how little difference it makes. I hope you don\u2019t lose them when they get offered a 10-20% payrise to go client-side (with less work).Isn\u2019t it unfair to charge our clients so much? Let\u2019s see what happens when we charge less. Cut the annual deal size by just $5,000 \u2013 this is the equivalent of keeping a client for 11 months instead of 12, or giving them a $420 per month discount. This cuts the margin to a teeth-clenching 8% \u2014 if just 1 in 20 clients pays you late, you might not be able to cover payroll. Realistically it\u2019s more like 10%-20% that pay late (which is why you need to make 15% margin).Even at a healthy 15% margin, it would take you 6 \u00bd straight months of profit to save up 1 month of reserve cash. You can\u2019t easily cut staff in troubled times, but what can you do? Lose 10 clients without replacing them (for example thanks to a global pandemic), you\u2019d be running at below breakeven. With no cash reserves you\u2019d be unable to meet payroll. In reality it\u2019s even tough than that \u2013 in real life you have a handful of big clients that drive 80% of your revenue. Lose one of those and you can become unprofitable overnight.Of course you can argue that these fixed costs are too high \u2014 of course that\u2019s what I did often! What I eventually found though, was at scale, cut back on any one of these costs and the agency suffers. Cut your 1 sales person and now as a founder you\u2019re doing 30 sales calls a week, and working late into your evenings and on weekends. Cut marketing and your sales team runs out of leads. Cut management and your team fails to get the training and supervision they need \u2014 it's a matter of time before a client asks for a refund due to someone\u2019s mistake.You might find, as most agency owners do, that the economics get better the bigger the client. The fixed costs don\u2019t really increase by much to service big clients, so they\u2019re spread out across a bigger base. There are also cultural norms around spending 10-20% of media on your agency, which anchor the amount you can charge low. For a small client though spending less than $5,000 a month on marketing, you can\u2019t just charge them $1,000 to $2,000 \u2013 there\u2019s no way to make that work in the model with fixed costs. It\u2019s also a fallacy, because when you add in the cost of creative and other services, most CMOs spend roughly the same on agency services as they do on media (and the same again on technology and team).Finally big clients are happier to pay more for less, because it\u2019s not their money! Their business won\u2019t fail if you do a bad job. That plus they act as sales material to help you close other big clients \u2013 deliver for one Fortune 500 company and more people will trust you to deliver for them too. This is why agencies inevitably move upstream when they wise up to these laws of economics."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'When to Hire an Agency' for the blog post 'Agency Economics'"}, {"role": "assistant", "content": "You might disagree with my methodology or my numbers, but hopefully by now it\u2019s clear that when you compare the true cost of doing business, you\u2019re getting exactly what the market can bear to offer. Despite all the work they do to differentiate, Agencies are largely commoditized, so they exist under close to perfect competition \u2014 if any one agency is making too much margin, it\u2019s only a matter of time before other agencies come in to eat their lunch.\u00a0It should be clear by now that an agency isn\u2019t \u2018ripping you off\u2019 \u2013 they\u2019re lucky to be barely staying afloat! So they\u2019re probably not ripping you off, they just have a very specific economic structure. Sometimes that structure makes sense to engage with, other times you can get much better results hiring a freelancer or building an in-house team.So when does it make sense to hire an agency? In my opinion there are three stages to scaling a marketing function, and different structures make economic sense at different stages."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '1. Discovery' for the blog post 'Agency Economics'"}, {"role": "assistant", "content": "If you don\u2019t have a lot of experience with a marketing channel or activity, or your business hasn\u2019t done much of it before, then DO NOT HIRE AN AGENCY. This is especially important for small businesses or startups, as well as new product launches for established businesses, because about 9 in 10 products fail. When things aren\u2019t working, the last thing you want is to be locked into an agency retainer, and the last thing the agency wants is to be blamed for a lack of traction. Same goes for an employee \u2014 you\u2019re doing them a disservice if you hire them and then need to fire them when it doesn\u2019t work out.If you\u2019re an agency owner that grows to be successful, eventually you will learn to move on from these clients. They can be great to get started and build case studies, but ultimately they can\u2019t be profitable for you at scale (especially given the thin margins we saw in the model!). They often churn in high numbers, which makes it impossible to grow past a certain point. Most successful agencies will filter out these clients with high retainers ($10k+) or minimum spends ($100k+).If you really can\u2019t try to do it yourself, this is the perfect opportunity for a freelancer. You need a very tight feedback loop to get new activities right, and dealing with just one person, who\u2019s livelihood in part depends on you continuing to pay them (otherwise they have to go back to networking which they hate), aligns the incentives beautifully. Even if the freelancer costs a large hourly rate, it\u2019s worth it for the flexibility of being able to try something with no long term commitment, with someone who was at least good enough to strike it out on their own."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '2. Growth' for the blog post 'Agency Economics'"}, {"role": "assistant", "content": "This is the stage where you\u2019ve proven something is working at a small scale. For example you ran $5,000 of Facebook ads and despite not knowing what you were doing, you saw great results. Or perhaps you contracted an SEO freelancer who got several quick wins over the first year, so now you\u2019re driving 10,000 visits a month and it\u2019s time to ramp up. The key is that you know the fundamentals of the channel, and have validated that it works for your business.This is the time to hire an agency. You can actually be a good client for them, because you now know the basics of how things work. They have a foundation to build off, and should be able to run an audit to point out where they would improve things. Unless the freelancer you worked with is gearing up to start their own agency, you\u2019ll find you\u2019re outgrowing them. No freelancer should want to work full time on a client (and in many locations it would be illegal), so you\u2019re only ever getting a fraction of their time.As your activity becomes more serious, you\u2019ll find you need better reporting, more responsiveness in returning emails, and knowledge gaps where you could do with a wider spread of skill sets, as well as a deeper bench. Now you\u2019re ready to go find an agency. Make sure you interview them like you would any employee (and treat them with as much respect!). Three other rules that can help you when making this choice:Focus on methodology rather than results or flashy logos \u2014 it\u2019s easy to get lucky or fake case studies, what\u2019s hard is designing a repeatable process to get results.Don\u2019t work with an agency \u2018above your station\u2019 \u2014 you never want to be someone\u2019s smallest client, but as a top 3 client for an up-and-coming agency, you\u2019ll be true partners.Be a servant-leader for your agency \u2014 handing everything over and expecting magic is not delegation, it\u2019s abdication. You have to be an active contributor to get results.Meet the people you\u2019ll work with \u2014 the agency might not like this because they can\u2019t guarantee resources before a sale is closed (I didn\u2019t) but it\u2019s the right thing to do.Get references from ex-clients \u2014 don\u2019t put them in a tough position by asking for references, instead get your own by cold emailing ex-clients or asking around."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '3. Scale' for the blog post 'Agency Economics'"}, {"role": "assistant", "content": "So when does it make sense to take an activity in-house? For some channels, the right answer could be never! For example most clients don\u2019t do their own branding, they hire creative agencies. Some clients maintain their agency relationships spanning multiple decades to their mutual benefit. This makes sense when your culture or volume might lead to worse outcomes for your company versus continuing to use an agency.\u00a0For example most companies don\u2019t need a new brand every year, and a sales or engineering-led company might struggle to hire or retain the best creatives. Think about this strategically for your agency \u2014 are you doing something non-core to the business, that is needed infrequently, or employing people your client couldn\u2019t easily hire? If not, then you might find client retention particularly difficult, which means you\u2019ll forever be husting on sales to replace the ones that get away.Where it does make sense to take work in-house, is when you have some unfair advantage in the discipline. If this activity is core to the way your company makes money, or you\u2019re amongst the top 10% in the world at it (or could be), then it\u2019s strongly worth considering. Sometimes if you\u2019re a \u2018cool\u2019 or \u2018innovative\u2019 company with a great culture, you can get better work out of employees who will work for less just to be a part of your team. However remember that also is true of agency employees, who will fight to be on the agencies\u2019 most illustrious account.If you do decide you need to take an activity in-house, take it slow. Remember that the efficiency gains will be relatively dubious (it costs the same amount of admin to run any organization of similar size). The chances are you can get more mileage out of switching agencies, than taking it on yourself. However when you do decide to make the switch, give ample time to do so: put the account up for review, give the agency a fair shot at retaining the business, be open about what changes they\u2019d need to make to remain competitive. Give them 3 to 6 months notice if possible \u2014 this is enough time enough to close another deal to replace you, or make staff redundant if necessary.\u00a0Most of all I\u2019d implore you to take personal feelings out of it. You might not be getting value for money out of your agency \u2014 maybe they\u2019re even genuinely bad at their jobs. Yet they\u2019re just people, working for a living \u2014 they don\u2019t owe you anything over and above the contractual agreement you made, which at the end of the day was just an educated guess at what you needed, made under conditions of uncertainty and commercial pressure. If you are unhappy with your agency, don\u2019t be an asshole about it \u2014 nobody works more for their least favorite client, and word travels fast. Be straight with them, and if it doesn\u2019t work out, move on."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Why Build Your Own AI Assistant?' for the blog post 'Building your own AI assistant like Iron Man'"}, {"role": "assistant", "content": "Most people assume that new inventions occur as \u201cEureka!\u201d moments had by scientists in lab coats, which are then commercialized and marketed to the public.In reality, a remarkable array of new inventions first appeared in the minds of science fiction writers, who possessed little or no scientific expertise.Behind every breakthrough technology you\u2019ll find a science fiction fan earnestly trying to bring the stories from their childhood to life.\u00a0For example:Jules Verne \u201cthe father of science fiction\u201d is credited with inspiring Simon Lake to invent the submarine, and Igor Sikorsky to invent the helicopter.Douglas Adams Hitchhiker\u2019s Guide to the Galaxy inspired Babelfish, a precursor to Google Translate, as well as IBM\u2019s supercomputer Deep Blue.The dystopian novel Snow Crash, is responsible for Google Earth and the \u2018Metaverse\u2019, that Meta (n\u00e9e Facebook) has funneled billions of dollars into.Many of the products we know and love, from the iPhone to Uber, were quite literally memed into existence.\u00a0Of all the Sci-Fi tropes, the one gathering the most steam in recent years is that of an \u201cAI assistant\u201d. Their job is to assist their owner with any sort of task, such as hacking, monitoring, analyzing and searching.There are many examples in popular culture \u2013 HAL in 2001: A Space Odyssey, Joi in Blade Runner 2049, Cortana in Halo \u2013 but the first one most people think of today is JARVIS; the benevolent AI assistant of Tony Stark, a.k.a Iron Man.https://www.linkedin.com/pulse/how-studying-ai-ruins-marvel-movies-you-tony-starks-jarvis-feroli/\u200dThis always felt laughably far in the future, until OpenAI released GPT-3 in June 2020 and I got to play around with the beta version.However it wasn\u2019t until AI exploded into mainstream usage with 1 million people using ChatGPT within a week of its release in November 2022, that I noticed regular people starting to get interested and ask me about AI.https://www.softwebsolutions.com/resources/everything-you-want-to-know-about-chatgpt.html\u00a0Recently as I was doing some prompt engineering, playing around with Langchain (a tool for orchestrating AI tasks) and Pinecone DB (a vector database AI can use as memory), I realized that all of the pieces to build your own AI assistant like JARVIS were in place.***\u00a0I've actually released a prompt engineering course on Udemy with my business partner James Phoenix, so you can get stuck into this right away***Not only that, but with the open-source Stable Diffusion image model, and Meta\u2019s \u201cleaked\u201d ChatGPT competitor LLaMA, it might actually be possible to get the whole thing running locally on your computer for free (if you have an M1 / M2 Mac or PC with a GPU).I prescribe to the Mark Watney school of decision making, so I figure why not try to build my own and see where I get to? I\u2019m sharing this as a template for anyone else who wants to be Iron Man, in the hopes that we can share tips on how to improve it.Why build your own? Well your AI assistant deals with lots of sensitive information that you probably want to avoid sharing, and their content moderation policies are evolving rapidly as they get dunked on by the popular press. You don\u2019t want to become reliant on AI for your work and life, only for it to be hacked or censored.It\u2019s also just nice to have control over the user interface and functionality, so you can adapt your AI assistant to whatever use cases you need, without worrying about when OpenAI is going to change things or let you off the waitlist. I\u2019ve already personally had content moderation issues, being banned for 10 days because of a cartoon mouse.https://twitter.com/hammer_mt/status/1580467310326091776?s=20"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'What\u2019s the Architecture of Our AI Agent?' for the blog post 'Building your own AI assistant like Iron Man'"}, {"role": "assistant", "content": "All of the pieces are already available to build what\u2019s damn near to an AI assistant portrayed in Iron Man and wide popular culture. To be clear you're not required to \"train\" your own model, or understand AI: all you need is a bit of prompt engineering and some code to stitch these various packages together.To be useful we need to give our AI agent a functioning long term memory, the ability to \u201csee\u201d images, \u201chear\u201d audio, and \u201cspeak\u201d back to us. We also need a guiding thought \u2192 action \u2192 observation loop, as well as the ability to equip the AI with tools to use. It might sound like science fiction, but all of this is already possible with off-the-shelf, open-source tools, available today."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Chat UI' for the blog post 'Building your own AI assistant like Iron Man'"}, {"role": "assistant", "content": "We\u2019ll start with the chat interface, which is easy because it\u2019s basically a glorified text form. Chatbot UI has already cloned the ChatGPT experience using Next.js, TypeScript, and Tailwind CSS, frameworks I\u2019m already familiar with.https://github.com/mckaywrigley/chatbot-ui\u200d"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Reason and Act' for the blog post 'Building your own AI assistant like Iron Man'"}, {"role": "assistant", "content": "The thought \u2192 action \u2192 observation loop is also surprisingly easy to do, using another open-source library called Langchain. They implement something called \u201cReason and Act\u201d, or \u201cReAct\u201d, which is essentially just a clever prompt for getting the AI to think through actions before making them. This is also the key to tool use, as the actions can be programmed as a kind of app store for AI, or \u201cPlugins\u201d as OpenAI calls them, of which Lanchain has an open-source version.https://openai.com/blog/chatgpt-plugins"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Long Term Memory' for the blog post 'Building your own AI assistant like Iron Man'"}, {"role": "assistant", "content": "For memory there are two types; short term memory which is just the context window of the chat, and long term memory in the form of a vector database. Vector databases let us look up documents based on similarity, so for example \u201ca mouse ate some food\u201d would match to a search for \u201ccheese\u201d, because mice and cheese appear together often, even though the word we searched for isn\u2019t in the document. LlamaIndex (formerly GPTIndex) helps us with this task, paired up with Langchain to do the coordination and retrieval.\u00a0https://blog.griddynamics.com/semantic-vector-search-the-new-frontier-in-product-discovery/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Vision, Audio, Speech' for the blog post 'Building your own AI assistant like Iron Man'"}, {"role": "assistant", "content": "How do we teach our AI to \u201csee\u201d, \u201chear\u201d, and \u201cspeak\u201d? Again we have readily available solutions for all of these seemingly impossible tasks. CLIP is an open-source component used by image generation models DALL-E and Stable Diffusion, which can take any image and reverse-engineer the caption as text. Whisper is an open-source audio transcription library, released by OpenAI. Finally the speech is handled by \u201cSovits\u201d, short for \u201cSoft-VC and VITS\u201d, which was behind a pretty impressive Kanye West demo.https://twitter.com/LinusEkenstam/status/1639937115147444224?t=SiN6eR5ePhu6B3s4jScGhQ&s=19"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Model Inference' for the blog post 'Building your own AI assistant like Iron Man'"}, {"role": "assistant", "content": "We could build all of this infrastructure and get back an impressive amount of flexibility and control over our AI assistant. We can easily replace DALL-E\u2019s image generation capability with open-source Stable Diffusion, and honestly we\u2019d want to anyway because it\u2019s far better. However we\u2019d still be reliant upon OpenAI for the actual AI itself; we\u2019d have to call GPT-4 for every chat message. That means we\u2019re still stuck at the mercy of their content moderation policy, and are still sending sensitive data to their servers.\u00a0However there\u2019s one final development that brought a fully open-source AI stack within reach; somebody leaked Meta\u2019s LLaMA model! Let\u2019s be clear, it\u2019s not as good as ChatGPT, and definitely not within sight of GPT-4, but it\u2019s getting better quickly. Shortly after the leak, a group at Stanford fine-tuned LLaMA with data generated by OpenAI\u2019s GPT-3 for only $600, and released \u201cAlpaca\u201d, which is tantalizingly close to the performance you get from ChatGPT. Even better, there\u2019s an open-source library, \u201calpaca.cpp\u201d, that lets you run it on your local devices for free.\u00a0https://arstechnica.com/information-technology/2023/03/you-can-now-run-a-gpt-3-level-ai-model-on-your-laptop-phone-and-raspberry-pi/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Building the AI Agent' for the blog post 'Building your own AI assistant like Iron Man'"}, {"role": "assistant", "content": "Honestly I haven\u2019t gotten this far yet; this is just an idea that came to me that I thought would be interesting to work on. I have built most of these things in isolation, but it didn't occur to me to stitch them all together until recently.As I get parts of this done I\u2019ll update this part of the post so you can follow along and build your own.\u00a0I'll open-source the whole thing so that you can clone it and deploy your own without understanding the underlying code.The space is changing so much right now that I know for sure my technology and tool choices, as well as the prompts I use, will quickly become out of date. If you spot anything that could be improved, please let me know.\u200d"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '1. Browse model summary' for the blog post 'You're the secret sauce: writing original content with AI'"}, {"role": "assistant", "content": "I hate to say it, but those AI bros on Twitter are right: 99% of people use ChatGPT wrong!. The most popular use case is content writing, as evidenced by the early growth of companies like Jasper and Copy.ai. Most people just give the AI a single prompt then use the output or complain the results are too generic.Those who get serious about AI quickly graduate from \u201cWrite me a blog post on {topic}\u201d, using prompt engineering to arrive at something that looks like this:```Create a blog post about \u201c{blogPostTopic}\u201d. Write it in a \u201c{tone}\u201d tone. Use transition words. Use active voice. Write over 1000 words. Use very creative titles for the blog post. Add a title for each section. Ensure there are a minimum of 9 sections. Each section should have a minimum of two paragraphs. Include the following keywords: \u201c{keywords}\u201d. Create a good slug for this post and a meta description with a maximum of 100 words and add it to the end of the blog post.```sourceOnce the post is written, a human editor takes over, and fixes any hallucinations (where the AI confidently makes something up), as well as rewriting it in the house style and attempting to make it more human and interesting. AI generated content tends to be a little dull and overly comprehensive, which is what you get when you train something on the average of the internet and beat it into submission with reinforcement learning.This is exactly the wrong thing to do. They have it backwards.ChatGPT is a helpful assistant, but it isn\u2019t the star of the show. It isn\u2019t human, so it doesn\u2019t have life experiences that we would relate to. It\u2019s too perfect. It doesn\u2019t make mistakes. It can\u2019t be the hero of the story, because it doesn\u2019t have any flaws to overcome to create the drama. It knows the sum total of all human knowledge, but not how to give it meaning. It can imitate great art, but you need to tell it what to imitate.\"In order to write about life first you must live it.\" - Ernest HemingwayUnopinionated content may as well not be written. When everyone is writing about the same keywords, quoting the same sources, generating the same copycat content, the search results pages become undifferentiated and unusable. When everything looks the same, the articles that stand out will be the ones that actually get read (by humans).Google calls this \u2018information gain\u2019 in a patent they filed in 2020, with the aim of rewarding content for being different. Every search results page is already personalized and soon enough will be processed by AIs more than humans. Neither AI nor humans want to see the same thing 10 times, they want to see 10 novel things, so they can reason about what is better for the current situation they find themselves in. Aim to be a net contributor to the training data, not just a consumer of it.Here\u2019s how the process works:Browse model summary \u2013 use an AI model capable of browsing the web to look up the topic and summarize it.Conduct an AI interview \u2013 get ChatGPT to interview you about your experience to find unique opinions and insights.Generate an outline \u2013 prompt to make an outline that incorporates the summary and your interview answers, with title options.Write one section at a time \u2013 loop through the outline and generate each section, providing feedback if needed along the way.Rewrite in the right style \u2013 define a style guide and ask the AI to do a rewrite to produce the final article.These stages don\u2019t occur all in the same prompt, they\u2019re chained together in a systematic way to deliver better end results \u2013 AI chaining is one of the 5 principles of prompting, and is used in most production AI systems. Each part of this sequence is designed to minimize hallucinations while maximizing creativity, and make original content worth reading without taking up too much of your time.Let\u2019s go through these one by one.We start simple, with asking the AI to look up the topic. It\u2019s essential to have a model with access to the internet, so if you don\u2019t have the \u201cBrowse with Bing\u201d plugin for ChatGPT, use the Bing chat mode, or Google\u2019s Bard. This is the number one thing you can do to avoid hallucination and be up to date with the latest on the topic.https://chat.openai.com/share/ae77086b-c99d-4216-9618-db877a45ea33Prompt:```Please look up {topic} and provide a summary:```There are three reasons we start with this:It stops the AI hallucinating on topics it doesn\u2019t know about.Without it, the post tends to not be comprehensive enough and can be outdated.It acts as a prompt to you, to get you thinking about the topic.This doesn\u2019t have to be done in the same chat window as the other prompts, or even using the same model. Just remember to copy and paste across for stage 2."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '2. Conduct an AI interview' for the blog post 'You're the secret sauce: writing original content with AI'"}, {"role": "assistant", "content": "This is where the magic happens: you get ChatGPT to interview you. It\u2019s actually pretty good at coming up with interview questions, especially when it has a recent summary of the topic to go from. You want the full list of questions at once, usually five is enough, otherwise it loses coherence and goes off on a tangent when doing questions one at a time.https://chat.openai.com/share/ae77086b-c99d-4216-9618-db877a45ea33Prompt:```Ask me five interview questions on {topic}. Your goal is to discover any unique opinions, experiences, or insights not covered in the summary:```I had a lot of these parts in place for a long time, but only recently cracked it by adding the interview stage. It was the missing piece, which is now reliably giving me good quality, creative writing that passes the Turing test, avoids AI detectors, with minimal or no editing needed. Rather than expecting ChatGPT to write something original, you provide the secret sauce. You\u2019re the one the audience wants to hear from, ChatGPT is just your ghostwriter.Note: if you don\u2019t have anything interesting to say, find someone who does. Tap your network or find someone at your company who is an expert on the topic. You can still use ChatGPT for all the heavy lifting, just get your expert to record a loom video and send you the transcript. I've heard from a few people who've used this system and in the process realized they had nothing useful to say on a topic. And that's fine! You can use this as an indication of what not to do, as Tom Roach advises:\u200d"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '3. Generate an outline' for the blog post 'You're the secret sauce: writing original content with AI'"}, {"role": "assistant", "content": "Most prolific prompters have stumbled upon this trick: rather than asking for a blog post, ask for an outline and ask it to fill that in. Generating the outline ahead of time helps make the whole post coherent, and ensures you don\u2019t get duplication across sections. This is based on the least to most technique, which is useful for other complex tasks involving AI.https://chat.openai.com/share/ae77086b-c99d-4216-9618-db877a45ea33Prompt:```Based on my answers and the summary, generate an outline for a blog article on {topic}, with 10 very creative title options:```At this stage it\u2019s important to give feedback and make edits if necessary. You can drop sections or add them just by chatting, or copy and paste elsewhere to edit before pasting your final version back into chat. If you\u2019ve done some keyword research on the topic now is a good time to drop that in, to make sure primary and secondary keywords are represented in the headings.This is also the time when you choose your title, which is the one thing I find AI never gets right. However I do find that asking it to generate 10 titles for me does give me enough creative inspiration for me to write the final title myself. Make sure to tell ChatGPT what title you chose in the end, so it can match the writing to it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '4. Write one section at a time' for the blog post 'You're the secret sauce: writing original content with AI'"}, {"role": "assistant", "content": "One weakness with AI models that anyone who uses AI to write content at scale will have run into, is that it\u2019s woefully bad at knowing how long an article is. It regularly doesn\u2019t follow the number of words you prompt it with, and will write a short article with no real substance. Other times it writes too much, and has to be cut down. The antidote is writing each section of the outline one at a time, because it forces a kind of symmetry and consistency.\u00a0https://chat.openai.com/share/ae77086b-c99d-4216-9618-db877a45ea33Prompt:```Write one section of the blog article at a time, with a minimum of two paragraphs. Incorporate my feedback before continuing to the next section:```Typically I find that it needs the context in the interview and summary to write these sections correctly, so if you do start a new chat session be sure to copy and paste those across. If it makes mistakes, tell it, and it\u2019s usually pretty good at learning from them. For example if a section is too short, correct it, and usually the following sections are longer afterwards. One issue I\u2019ve seen is a tendency to hallucinate new sections as it gets lower down the context window, so always check each new section name back to the original outline."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '5. Rewrite in the right style' for the blog post 'You're the secret sauce: writing original content with AI'"}, {"role": "assistant", "content": "To enact this last prompt, you have to know what style you want to write in. ChatGPT does know about the styles of prominent bloggers, brands, and celebrities, so you can ask it to emulate Seth Godin, the HubSpot blog, or Malcolm Gladwell. One strategy for getting something familiar that works but is slightly more original, is \u201cunbundling\u201d, a term coined by Bakz T. Future. Jump into a different chat window and run this:\u200dPrompt:```Briefly describe the writing style of Harry Dry from MarketingExamples.com in bullet points:```From here you can remix the style, keeping the bullet points you agree with and dropping or replacing those you don\u2019t. If you want to build an in-house style guide, simply copy and paste 5-10 of your best blog posts into ChatGPT and ask it to describe your style. If your posts are lengthy, you may need to use Anthropic\u2019s Claude model for this, as it has a 100k token window, or about 75,000 words. Another neat trick is to use this when writing guest posts, to align your writing to what has already been published on the site.Now you have your style, you can go back to your other chat window with the article in it, and run this simple prompt:https://chat.openai.com/share/ae77086b-c99d-4216-9618-db877a45ea33Prompt:```Rewrite the article in the following style:{ style }```The style I\u00a0used was as follows:Concise and to the pointProfessional and knowledgeable toneRelatable and accessible languageUses storytelling to convey ideasRelies on examples and case studiesMixes personal anecdotes with industry insightsProvides actionable advice and tipsUses subheadings and bullet points for easy readabilityNote: this is probably the only section you really need GPT-4 for. GPT-3.5-Turbo (which powers ChatGPT) is unreliable at following instructions for role playing, whereas GPT-4 is smarter and was specifically trained to solve this issue, and the quality is worth paying for by signing up for ChatGPT plus."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Bonus: Meta-prompting for images' for the blog post 'You're the secret sauce: writing original content with AI'"}, {"role": "assistant", "content": "Here I\u00a0spent a bunch of time writing these prompts, but just like any text ChatGPT is pretty good at writing prompts too. When you get an AI to write prompts for you, it's called meta-prompting, and it works particularly well when it comes to creating a custom image for your blog, by asking it for a prompt you can plug into DALL-E (I\u00a0actually use Midjourney, but I\u00a0just wager ChatGPT knows more about OpenAI's own tools).https://chat.openai.com/share/ae77086b-c99d-4216-9618-db877a45ea33\u200dPrompt:```Describe an image that would go well at the top of this article``````turn this into a prompt for DALL-E```This was a big insight when my co-founder on Vexpower showed me it. I\u00a0just never thought about getting ChatGPT to write my prompts for me, I\u00a0was already greatful it was doing everything else! If you wanted to learn more about this technique James covers it in our Udemy Course: \"The Complete Prompt Engineering for AI Bootcamp (2023)\"."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Conclusion' for the blog post 'You're the secret sauce: writing original content with AI'"}, {"role": "assistant", "content": "I\u2019ve found this system is capable of writing content that would normally take me more than a day or two in less than an hour. I have infinitely more stories and insights than I have time to write up, so now I can give my audience more of what it wants, and leave the boring, time-consuming parts to ChatGPT.Here's an end-to-end example in ChatGPT: https://chat.openai.com/share/ae77086b-c99d-4216-9618-db877a45ea33If you want to see the finished result, which took really minimal edits (mostly the bullet points section), here's my post on value-based pricing in agencies: https://www.saxifrage.xyz/post/value-based-pricingComparing the final text to what the AI outputted, a human editor (me) deleted 824 characters (8.54%) and inserted 1,016 (10.53%) of the text. Most of this was in the bullet point section in the last section on mitigating risks, which I\u00a0had to rework.There are plenty of techniques out there for using ChatGPT to write blog content for you, but I haven\u2019t seen many like this. I've been battle-testing this for months, doing parts of my work with a mixed bag of these techniques. It was only recently that it all came together. The big unlock was reversing roles and getting the AI to interview me as the expert. Now I know it works, it feels obvious: of course things it writes aren\u2019t meaningful if there\u2019s no human experience to relate it back to. I actually hate editing, so I prefer ChatGPT to do that for me, and all I have to do is answer a few questions. I\u2019ll keep refining this, and I hope you find success with it. If you find anything that works better, tweet at me: @hammer_mt.\u00a0"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'What\u2019s the Prize?' for the blog post 'AIO: Artificial Intelligence Optimization'"}, {"role": "assistant", "content": "With the rise of search engines, we had a corresponding rise in SEO (Search Engine Optimization), the practice of making your content rank higher on Google and other search engines. Now we\u2019re seeing AI chatbots like ChatGPT growing past 100m users as a potential Google competitor, we should expect to see an opportunity in the practice of making your content get mentioned by AI, which I\u2019m calling AIO: Artificial Intelligence Optimization.https://twitter.com/hammer_mt/status/1632869369343606788?s=20This field is a long way off existing, which is why I made the above joke. Having thought about it more, I actually think this is going to be a thing, and it\u2019s worth exploring this area today to establish a few common sense best practices. In this article I\u2019ll cover what makes AIO potentially valuable, and list out some ways you can already curry favor with the current batch of AI tools.I\u2019m interested in this area as a self-proclaimed prompt engineer, the author of an O\u2019Reilly course of Prompt Engineering and also a Udemy course \"The Complete Prompt Engineering for AI Bootcamp (2023)\", and because AI is unexpectedly making the book I\u2019m writing on reverse-engineering creativity a whole lot more interesting.I plan to keep this page updated as the field develops, but everything\u2019s happening so fast I\u2019ll need you to message me with anything I miss: @hammer_mtFirst off, what can AIO do for you? At the time of writing only Google Bard, Microsoft's New Bing, and ChatGPT with the browser plugin have the potential to drive any serious traffic to your website, as most AIs don\u2019t yet provide citations or links. https://beebom.com/chatgpt-plugins-announced/There are early trials with You.com and Perplexity AI, but they\u2019re unlikely to have the volume yet to really make a difference. However people are already reporting increased traffic from Bing, and Google is rearchitecting its entire search results page around AI.https://twitter.com/glenngabe/status/1632820090209959939\u00a0Don't expect AI awareness to always manifest as traffic either; we are already seeing reports of people listing \"ChatGPT\" as a source when filling in a \"How did you hear about us?\" form on checkout. Adding one of these forms to your checkout or registration process with a free text \"Other\" option, using a vendor like Fairing, is a fantastic way to spot new marketing channels, and keep up to date with which AI bots are sending users your way.https://fairing.co/blog/qotd-using-chatgpt-to-shop-for-ecommerce-productsThat means so far AIO is more of a brand marketing play, similar to going viral on TikTok or working with influencers. Being known by the AI is the new \"ranking number 1 on Google\", and brands will no doubt start to compete to find ways to get in the training data. For example how much would Converse, Vans, or Reebok pay to be in the list when you ask where to get the best sneakers? What\u2019s the benefit to Nike for having both their main brand and a sub brand (Jordans) listed? Being included for these types of consumer queries will be golden, especially as ChatGPT gets a mobile app, and AI gets incorporated into more and more products.https://twitter.com/hammer_mt/status/1633207039328493571?s=20\u00a0This is an informational query, which is surely the top prize as it\u2019ll drive the most awareness. However, there will also be a long tail value in simply being known by the AI, when someone looks you up. Just like having your own Wikipedia page, or owning the top slot on Google for your name, being in the AI\u2019s training data will be a status symbol and a form of brand protection. Speaking of protection, it may make sense to start playing defensively right now to protect your good name. If the AI doesn\u2019t know about you, it will surely hallucinate something terrible about you, like this law professor ChatGPT wrongly accused of sexual abuse. Perhaps tools will develop to update the index and fact-check errors, but we all see how well that goes on Wikipedia and Google.https://twitter.com/hammer_mt/status/1538331052300697600?s=20\u00a0If you are already ranking on SEO, investing early in AIO\u00a0might put you in a good position for when mainstream adoption occurs. If people really do start getting all their answers via ChatGPT or without leaving the Google Search page via Bard, you'll see traffic decline. To identify how much of your traffic is disrupt-able by AI, Seer Interactive recommends pulling a report that shows how many of your search terms have an answer box in position #1. Ranking number one on Google Bard might be one day more important than ranking number 1 on Google, but the business models for content companies will need to change as they can't serve ads against these results.https://twitter.com/DataChaz/status/1658458449619963905AI stands to be a valuable research tool. Yes AIs are biased, but they\u2019re really a reflection of our own biases. All it has done is learned our existing associations (those available on the web, anyway). I know from attending a recent conference that social scientists are actively dreaming up ways to do primary research using models like GPT: understanding how the AI sees the world might tell us something about what our society thinks too. It also stands to be a useful tool for brands who want to do research into the zeitgeist, and understand what associations their brand has, that are reflected in the AI, as well as how similar different brands are.https://brxnd.substack.com/p/what-does-ai-know-about-a-brand-brxnd\u00a0Software developers will likely have a harder time than other creators to get value out of being used for AI training data. While tools like GitHub Copilot can already handle a significant amount of the work, there\u2019s usually no attribution back to source, and there have even been cases of leaked passwords and API keys. AI code generators stand to benefit the authors of popular libraries and platforms that are now more accessible than ever, as even inexperienced developers can just tab tab tab to autocomplete what used to be a complicated implementation.https://twitter.com/dannypostmaa/status/1598476315707191296?s=20&t=aePsFjqY7RNaMdnIDMfb5AThis isn\u2019t just limited to Large Language Models (LLMs), Diffusion Models like DALL-E, Midjourney, and Stable Diffusion will also be key. Companies pay hundreds of millions of dollars every year for brand advertising campaigns to reinforce their distinctive brand assets. Now one of those avenues is going to be AI. For example Coke\u2019s brand is so distinctive that when you ask DALL-E for a can of cola, it returns images that are quite clearly of the famous brand. If your visuals become synonymous with your category, expect to get a whole lot of free branding.https://twitter.com/hammer_mt/status/1633207583514173440?s=20\u00a0For individual artists and designers, they stand to go viral from AI art, like the suddenly famous Greg Rutkowski whose magical and otherworldly fantasy style became incredibly popular amongst early Midjourney and Stable Diffusion users. Because these communities are surprisingly massive \u2013 Midjourney has 13m users at the time of writing, up from 1m in just under 7 months \u2013 this can be as impactful as going viral on TikTok is for a musician.Brands and artists will need to figure out their strategy with respect to AI. For some with valuable IP to protect, the answer might be litigation, or for those that can't afford a lawyer, data poisoning. I can\u2019t imagine Disney wanting to allow fan-made Star Wars or Marvel movies, and they have sued for less. We\u2019ll have our Metallica vs Napster moment I\u2019m sure, before platforms are forced to mature and the AI equivalent of Spotify emerges, with a business model that aligns incentives for both sides.However smaller, more enterprising start-ups and creators might be delighted for the exposure, and embrace fan communities that build on and extend their brand. We might even see some brands release open-source fine-tuned models for faithfully replicating the brand\u2019s tone of voice, embedding characters and products, or following the brand style guide. Expect innovation in this space, with early innovators quickly skyrocketing to household names."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How do you get in the training set?' for the blog post 'AIO: Artificial Intelligence Optimization'"}, {"role": "assistant", "content": "Both search engines and chatbots have the same goal: to help you get the information you\u2019re looking for. That means most of the things you\u2019re already doing to optimize for SEO will also be beneficial for AIO. Use natural language and avoid keyword stuffing - AI platforms are becoming more sophisticated in their ability to understand natural language, so focus on creating content that uses natural language instead of stuffing it with keywords.Leverage structured data to help AI platforms better understand the content on your website - Structured data such as schema markup can also help search engines better understand your content and improve your rankings.Optimize for featured snippets by answering common questions in a clear and concise manner - Featured snippets appear at the top of search results pages and can improve your visibility and click-through rates.Use descriptive and engaging meta titles and descriptions to attract clicks and improve click-through rates - This helps improve your rankings and visibility on search engines.Focus on user intent and creating content that meets the needs of your audience - This can help improve engagement, click-through rates, and ultimately, your rankings on search engines.Get backlinks from reputable websites to improve your authority - Backlinks are a key factor in improving your rankings on search engines, and being featured in lots of places online maximizes your chances of being picked up in training the AI.Monitor your website's performance metrics, such as bounce rates and click-through rates, to identify areas for improvement and optimize your content - This helps ensure that your content is meeting the needs of your audience and providing value.Optimize your website's loading speed to improve user experience and reduce bounce rates - A faster loading website can improve engagement and reduce bounce rates, which can in turn improve your rankings.Use header tags (H1, H2, H3, etc.) to organize your content and improve readability - This helps AI platforms and search engines better understand the structure of your content and can improve your rankings.Use multimedia content such as images and videos to make your content more engaging and shareable - This can improve engagement and click-through rates, which can improve your rankings and visibility on search engines, and if you have a unique style you might get featured in AI art communities.It's unclear whether Bing can actually \"read\" the articles it searches on SEO, or if it's using some cached version, or a limited portion of the cache. I\u00a0have seen instances where it seems to have provided answers based on content within the article, for example based on the heading sections. However when you ask, Bing says that it can only read the actual title and meta description from search results, and is unable to visit a specific URL.I've had similar issues with Google, which is also hooked up to the internet and supposed to be able to search in realtime. It frequently hallucinates in a way that is quite funny because it's directionally right, but factually wrong. When I\u00a0asked it to tell me about Vexpower, it hallucinated a co-founder (the brother of someone who created a course on my platform), and that we had raised money (we haven't).https://twitter.com/hammer_mt/status/1638279334208102400As well as being important for AIs that browse the web, search engine datasets such as Google and Bing\u2019s indexes. Simply ranking on SEO is going to be doubly as important, because it'll help for AIO too. Of course there will be people who act to try and bias the index, just like they do with SEO. The open-source CommonCrawl is probably the most important index to be in, because it's already form the bulk of what these AI models are trained on. Google and Microsoft are the biggest players in both search and AI\u00a0(Microsoft bought 49% of OpenAI), and anyone else training a model will start with CommonCrawl. For example the data for Meta\u2019s recently leaked model LLaMA was 67% made up of CommonCrawl.https://scontent.fman4-2.fna.fbcdn.net/v/t39.8562-6/333078981_693988129081760_4712707815225756708_n.pdf?_nc_cat=108&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=drS9b1BkIEkAX-ezdno&_nc_ht=scontent.fman4-2.fna&oh=00_AfDnfhSaf2avetcbI0bTgdlGhb_4lnxboNCjUuI2OnxZbA&oe=640BAD22\u00a0The other obvious place to get yourself inserted is Wikipedia. The open-source encyclopedia is almost always going to be included in anybody\u2019s dataset, because it\u2019s not just high quality and well structured data, it\u2019s also freely available and easy to access. As is the case with SEO, becoming notable in real life is a great way to build authority online too. Coining new terms, publishing books, speaking at events, will all be ways to build your reputation not just with the public, but with AIs too.There's this idea of an ai.txt file, an analogy to the robots.txt file that governs web scrapers for search engines. Honestly I\u00a0think this is a kind of dubious analogy because robots.txt already serves its purpose for webscraping. My bet would be that instead there just becomes an additional convention in robots.txt that dictates whether the data can be used in training and/or in browsing plugins.I think PR is going to see a real boom with this shift in technology. Suddenly being featured in a major publication isn\u2019t just worth it for the exposure: it potentially gets you into the corpus of data they use to train the next model. OpenAI\u2019s ChatGPT is only trained up September 2021 as it stands today, but Bing can look things up on the internet, and it\u2019s likely Google\u2019s Bard will have the same functionality.https://twitter.com/DrJimFan/status/1630595296186220544/photo/2\u00a0For developers making sure your code is on GitHub is likely enough, though answering questions on Stack Overflow should also be a big help. There has never been a better time to write that package or library, because if it gets widely used, it will create a feedback loop where more and more people will get it in autocomplete via CoPilot and ChatGPT. Perhaps we\u2019ll also see libraries and products developed that are optimized for AI, for example using syntax that makes autocomplete easier. I\u2019ve already found that for example CoPilot struggles with React\u2019s nested components.For artists that actually want to appear in open-source datasets, rather than sue the AI companies, having your work available in the public domain, and featured on websites such as ArtStation, is a good way to get noticed: \u201ctrending on Artstation\u201d is a common way to enhance the quality of your generated image. There are also stock photo sites like Unsplash: particularly if it's open source, it's likely to be featured. The communities for AI Art are highly mimetic \u2013 everyone copies what everyone else is doing \u2013 so seeding each Discord and Reddit group with a few stunning examples of your work, replicated or enhanced by AI, can help spread the word, and check you made it into the index on Lexica Art.One non-obvious place to insert yourself is in the prompts you use when working with AI. It\u2019s widely expected that the words we input to tools like ChatGPT and DALL-E will be recorded and used to fine-tune the model. They even have a thumbs up / thumbs down button on the side to get feedback on whether the generation met expectations. It may be the case that simply using your own brand name and correcting the AI might be enough to make it into the next version.Ultimately though, the best way to insert your brand in the conversation has always been to have a strong brand. I'll leave you with this Seth Godin quote:\"If Nike announced that they were opening a hotel, you\u2019d have a good guess what it would be like. \u00a0If Hyatt said that they were going to start making shoes, you would have NO IDEA WHATSOEVER what those shoes would be like. \u00a0Because Nike owns a brand and Hyatt owns real estate.\"https://twitter.com/ehdecker/status/1633545274202136585?s=20"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How can you do Bayesian regression in Python?' for the blog post 'Bayesian Econometrics in Python'"}, {"role": "assistant", "content": "This post is the latest in a series that started with \u2018Econometrics in GSheets\u2019. It was created in partnership with Recast, who wrote the code and published a companion article that goes into more depth. In this post we\u2019ll be building the model in a Google Colab notebook using Python, rather than using GSheets, similar to what I did in the post \u2018Econometrics in Python\u2019. If you\u2019re not already familiar with Econometrics, I recommend you go back and read the first post.Bayesian methods are growing in popularity as the more \u2018modern\u2019 approach to marketing mix modeling... even though Thomas Bayes was born in 1701, almost 300 years before marketers started using Linear Regression. One superpower Bayesian has over traditional methods is that it lets you make prior assumptions about how the model will work! For example, I\u2019m always seeing models that show that marketing drove negative sales (which makes no sense!)There\u2019s no conceivable reason to expect all that money you spent on ads would have decreased sales (it\u2019d have to be a pretty awful ad!). It\u2019s likely that the real reason this is happening is that the variables are correlated with each other, messing up the ability of the algorithm to tell them apart. I can tell you, the client won\u2019t trust your model if you tell them their marketing drove negative sales, no matter how \u2018accurate\u2019 the model looks.So I enlisted the help of Michael Kaminsky formerly of the Marketing Science team at Harry\u2019s, who uses Bayesian methods to automate marketing mix modeling at his new startup, Recast. He shared the following code to demonstrate how you can take advantage of Bayesian methods, without much more effort. If you stick with us to the end, we\u2019ll also go under the hood and explain how and why Bayesian methods work.If you\u2019d like to follow along, here\u2019s the Google Colab Notebook to copy:Bayesian Regression DemoAlso check out the companion article on the Recast blog which goes into more depth.The library we\u2019ll be using is PyMC3, which does all the complex Markov chain Monte Carlo stuff under the hood. Don\u2019t worry if you don\u2019t understand any of this (I didn\u2019t until recently!), bear with us and by the end you should have a bit more intuition for what\u2019s going on. The actual code to run the model looks like this:This creates a model with a few standard assumptions (normally distributed), and iterates 2000 times to map out all the potential values of the coefficients. Then the next step is really just to take an average of those coefficients to get the final result. This example shows 5 hypothetical marketing channels, with one of them being negative.What we just did was replicate the same assumptions and results we\u2019d get from Linear Regression. If you take a look in the code we also ran a Linear Regression the normal way, and got essentially the same coefficients. For example x__5 has a negative coefficient of around -0.86 in both models (there will always be slight differences).Now let\u2019s see what flexibility the Bayesian methods can offer us that Linear Regression can\u2019t. Let\u2019s tell the model we need the marketing coefficients to all be positive. We can do that with just a small change to the model, as you can see below (the highlighted lines).This just changes our prior assumptions going into the model, capping the range of potential coefficients for marketing at zero (lower=0.0). That means when the model simulation runs, we will get more realistic output for our marketing variables based on our knowledge of how marketing works.This is looking much better: the negative coefficient has disappeared and some of the numbers have moved around a bit. But how do we know how accurate this is? Well actually because this is fake data that we generated ourselves, we know what the \u2018truth\u2019 is!As you can see, the last model with marketing coefficients bounded to above zero, did a lot better than the normal OLS Linear Regression. It\u2019s still not perfect, and there are plenty more things you could do to improve the model, but we\u2019re substantially closer just by using some common sense and domain expertise, combined with the Bayesian ability to let us incorporate those techniques.If you\u2019re looking for more information on how this code works, or Bayesian techniques in general, check out the companion post on Recast."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Why should you use Bayesian Regression?' for the blog post 'Bayesian Econometrics in Python'"}, {"role": "assistant", "content": "This method is a little more complicated, and can only really be done with code rather than in Excel, so is it worth it? For most people this might be overkill, or at least over their heads. However if you\u2019re spending six figures or more a month on marketing, it\u2019s really important that you get your model right. The great hope of Bayesian techniques is that if you set your model priors sensibly, the actual modeling can be more reliable, even when automated.\u00a0That\u2019s not too important when you do one model a year with an army of statisticians, like most Fortune 500 brands, but for fast-growing startups who change budgets monthly and strategies weekly, annual planning just won\u2019t cut it. You need to be able to automate the modeling process, so that new variables show up as you change tactics, and coefficients change based on the rapidly evolving landscape of your market. This is something that Recast is solving, having seen it\u2019s effectiveness at Harry\u2019s, and I recommend talking to them if interested.So why weren\u2019t Bayesian techniques adopted before? Well Linear Regression is based on a very efficient mathematical formula, which is relatively cheap to calculate \u2013 this was important in the 1908s when it was adopted and a computer the size of your house had less computing power than the phone in your pocket! Sure it requires a few important assumptions, but in most cases those assumptions hold and data can be manipulated to fit them. However with the lower cost of computing power, more resource-intensive methods like Monte-Carlo Markov Chains (what we just used) have become more accessible."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How do Bayesian techniques work?' for the blog post 'Bayesian Econometrics in Python'"}, {"role": "assistant", "content": "Say you were on the basketball court, and trying to throw the ball through the hoop. Linear Regression would be the equivalent of measuring the distance to the hoop, it\u2019s elevation of the ground, then using Trigonometry to calculate the perfect throw.https://theconversation.com/the-math-behind-the-perfect-free-throw-91727Bayesian sounds complicated, but in practice on the basketball court it\u2019d do what any of us would do: throw the ball lots of times, and adjust until you\u2019re getting it in the basketball hoop more often than not. That\u2019s why it can be resource intensive \u2013 it simulates lots of potential outcomes, i.e. throws the ball lots of times, until it has a good understanding of what throw has the highest probability of making the basket.\u00a0To stretch the analogy further, when we bounded our marketing coefficients to not be zero, that\u2019s the equivalent of telling the bayesian basketball thrower that you can\u2019t throw from behind the net. It saves them some time, and eliminates the chances of them finding some interesting way to reliably score from the bleachers.\u00a0The algorithm we used was called \u2018Markov Chain Monte Carlo\u2019. The Markov Chain part you can imagine as a notepad, where you write down the sequence of actions you took to throw the ball. This helps you keep track of what precise movements are more likely to score a basket (though in reality you do this in your head). The word \u2018Monte Carlo\u2019 refers to the technique of just trying multiple thousand or millions of times with a computer until you find the answer. It was invented by Stanislaw Ulam, one of the scientists behind the Manhattan Project (atomic bomb), when he struggled to derive a function to predict his odds of winning solitaire.Of course it\u2019s more complicated than that in practice, but this should give you a good idea of what\u2019s going on under the hood. It might seem complicated, but thankfully all of the hard math has been worked out for you, and packed into libraries like PyMC3. In fact, as someone who failed math in high school, one of the really appealing things about Bayesian techniques is that it requires very little math! You don\u2019t have to derive or integrate anything, you simply throw a lot of shots and record what works! If you\u2019re interested in learning more then check out Recast\u2019s companion article, and the book Bayesian Methods for Hackers."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How to use ChatGPT in GSheets' for the blog post 'ChatGPT in GSheets'"}, {"role": "assistant", "content": "New AI models from OpenAI and others promise to have a huge impact on marketing, and the pace of innovation is accelerating. Tools like ChatGPT, Copy.ai and Jasper.ai are democratizing access to AI, but I\u2019ve found it hard to incorporate these powerful tools into my own workflow as a marketer, and as a result I\u2019m not leveraging the benefits of AI as much as I should. To make GPT-4 more accessible, it needs to be available where I live, and that\u2019s in Google Sheets. As an update to my previous GPT-3 template, I decided to update the function to support the latest models in the ChatGPT format::> CHATGPT() Function TemplateWhen you visit the template it\u2019ll ask you to make a copy including the Google Apps Script, and if you click ok you\u2019ll have your own version of the Spreadsheet to follow along. This function is a work in progress that I plan to keep updating, but also feel free to modify it for your own use. I\u2019ve used this function in two courses on Vexpower so far, so it might be worth checking those out if you\u2019re trying to learn:Make Me 205 AdsWhat Do Our Customers Think?If you want help learning how to prompt ChatGPT and work together with it, I have partnered up with James Phoenix (who I work with on Vexpower) to build a Prompt Engineering course on Udemy, with over 9 hours of content.In order to use ChatGPT you need an OpenAI account, which you can set up on their website. Check out the latest pricing on the OpenAI website (note: cutting-edge models can cost an order of magnitude more per 1,000 tokens). The tokens count both the text going into the prompt you send ChatGPT, as well as the response you get back. Also whenever you recalculate the spreadsheet, all the prompts will re-run, which can cost you money. When you sign up for a new account you may get free credits, but in my experience the costs are trivial even for heavy usage compared to doing the work yourself manually. Just be careful and monitor your spend.\u00a0Once you have an account you can visit the API keys page to get a secret key related to your account, which you\u2019ll need to copy and paste into the cell B1, which says \u201cAPI KEY HERE\u201d in red text. This is the equivalent of a password, so keep it safe, and don\u2019t share it with anyone, or accidentally leave it in a public facing document. My recommendation is to have a spreadsheet where you do your ideation with ChatGPT, then copy and paste the results into a new sheet to share.Once you have the API key set, running CHATGPT() is the same as running any other function in GSheets: you simply use CHATGPT() with the only required parameter being the prompt you pass ChatGPT. For example when I passed \u201cOnce upon a time\u2026\u201d I got back \u201c a beautiful princess was born.\u201d which is how ChatGPT decided to complete the text.\u00a0The craft of working with AI is called \u201cprompt engineering\u201d, which is a fast moving field with lots of innovation through trial and error. You\u2019ll find ChatGPT does a decent enough job of anything you ask it to do, but sometimes goes off on a tangent or comes back with something weird. I\u2019d still recommend you have a human check the results of any prompt, and edit or rerun any bad responses before you use the output in the real world.\u00a0The other important parameters I\u2019ve implemented in the function are \u201cmax_tokens\u201d, which controls how long the response will be, and \u201ctemperature\u201d, which controls the randomness of the response, as well as the system message, which act as additional instructions for how ChatGPT should behave.. If you\u2019re finding ChatGPT is rambling on for too long, shorten the max_tokens (default: 100), or try to give instructions to respond briefly in the system message. If the results need to be more predictable and less creative, dial down the temperature (default: 1). If you turn on the Show Probabilities setting in the OpenAI Playground in your OpenAI account, you can see what it\u2019s doing: by dialing the temperature up, it\u2019s more likely to pick a lower probability keyword as the next one in the sentence, and by dialing it down it makes more predictable choices."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How does the CHATGPT function code work?' for the blog post 'ChatGPT in GSheets'"}, {"role": "assistant", "content": "If you want to see how the code works for this function, so that you can modify it or build your own custom function, click on Extensions > Apps Script in the navigation bar. That\u2019ll take you to the attached Google Apps Script, which handles talking to OpenAI\u2019s ChatGPT API when the function is used. It reads the API key from the cell A1 in the current sheet, then inserts that into the authorization headers so OpenAI know it\u2019s you.\u00a0The code then makes the API call to OpenAI, with the prompt, max_tokens, and temperature and any other function parameters. If you\u2019re creating your own function, or updating this one, you should know that the comment in green directly above the function at the end is what populates the function help text when a user clicks into the function bar. Stick to this format and it should work for you too. Finally I\u2019ve found the best way to handle defaults is to put them directly in the function parameters, so that the underlying function is always getting a value for each parameter no matter what the user inputs.\u200d"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'The top results are ads' for the blog post 'Why the winner takes all in Content Marketing'"}, {"role": "assistant", "content": "This post is one of a series on my content production system, developed over 10 years and designed to scale content end-to-end in 6 months as an acquisition channel. Here are the other posts in the series:Why the winner takes all in Content Marketing (this post)What everyone gets wrong about Content StrategyBuilding Your Keyword UniverseMinimum Viable Technical SEO AuditRecruiting good Freelance WritersHow to write blog content at scaleGrowth engineering for SEO\u200dLink building for authorityContent Repurposing for Social Promotion ---If you\u2019re writing for fun, my advice is to follow your passion. But if you\u2019re blogging for business, you need a system that can drive results at scale.\u00a0I developed my system while building Ladder into a 50 person growth marketing agency. As well as growing the agency via content marketing (90% of new leads mentioned the blog) we also built and managed blogs for clients like Booking.com, Money Dashboard and Criteo, amongst others. After leaving I also got a chance to test it client-side in the 3 months I was VP Growth for a startup before COVID hit.\u00a0As well as my own experiences I\u2019ve learned a lot by working with some of the best content marketing agencies in the world, like Animalz, Influence&Co, Codeless, The Martec and Growth Machine. As I build my new business, Vexpower, I\u2019m thinking again about content marketing, and wanted to get my thinking down on paper as to why I'm betting solely on this channel.You have multiple channels to choose from as a startup, and many make the mistake of spreading themselves thin across multiple. However if you look at the top startups that succeeded in every industry, they usually saw the majority of their growth from one channel only. For example in travel, Booking.com dominated PPC, Expedia scaled through SEO and AirBnB grew via virality.If you want to win, you have to focus: because there are exponential returns from mastering one of these channels. There are several structural aspects of content marketing that give it increasing returns to scale.\u00a0The first cause is that SEO has to compete with PPC for attention: 5% to 30% of clicks are siphoned off before you get to the organic listings. So only the top listings are visible above the fold."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Most clicks are above the fold' for the blog post 'Why the winner takes all in Content Marketing'"}, {"role": "assistant", "content": "The second is related: because most users click the first listings they see above the fold without scrolling down or going to the second page of results, the vast majority of clicks go to position 1, which gets a 30%+ click through rate, more than double the 2nd place listing, and it drops off further from there. Less than 5% of clicks even make it past the first page."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Most keywords are long tail' for the blog post 'Why the winner takes all in Content Marketing'"}, {"role": "assistant", "content": "The next phenomenon is at the keyword level, where the \u2018long tail\u2019 of keywords adds another layer of winner-take-all dynamics. The top keywords have the highest competition, but they generate the vast majority of traffic. Below the top 20% of keywords, most keywords get less than a handful of clicks a month each. Add all these long tail keywords up and they can be worth a lot in aggregate, but individually they\u2019re not economical to write content for."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Page rank is a popularity contest' for the blog post 'Why the winner takes all in Content Marketing'"}, {"role": "assistant", "content": "The other major bias in SEO towards the big players, comes from the way Google\u2019s search engine is designed: the Page Rank algorithm. It ranks content based on how many links there are to that web page (and domain), as well as the profile of the sites linking to them. So the websites that have the most high quality links, that are the most established, are most likely to rank higher.With all of these natural in-built advantages to whoever is in the number 1 position, SEO demands your full attention. If instead of writing an article you\u2019re optimizing your Facebook ad campaigns, you\u2019re decreasing your chances of ranking on a new keyword. If you\u2019re serious about growth through content, every dollar and your full attention should be on it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'A. Identify a Topic to Target' for the blog post '\u200dHow to write blog content at scale'"}, {"role": "assistant", "content": "This post is one of a series on my content production system, developed over 10 years and designed to scale content end-to-end in 6 months as an acquisition channel. Here are the other posts in the series:Why the winner takes all in Content MarketingWhat everyone gets wrong about Content Strategy\u200dBuilding Your Keyword Universe \u200dMinimum Viable Technical SEO Audit\u200dRecruiting good Freelance Writers \u200dHow to write blog content at scale (this post)\u200dGrowth engineering for SEO\u200dLink building for authorityContent Repurposing for Social Promotion ---The very best content requires domain expertise For example the posts I wrote myself at Ladder often became the most popular, potentially because they were more authentic and showcased deeper expertise. However, that\u2019s an expensive proposition, because we have a lot of other demands on our time. So how do you scale the impact of domain expertise without losing quality?The trick we found was hiring a professional writer to interview the domain expert, much like a journalist would interview you for a news article. So you still get the substance of the post directly from an expert, but the writer professionalizes the post and makes the story more interesting and relatable. We found this worked particularly well for non-native speakers: for example we had a 25 person office in Poland, and this method unlocked a lot of knowledge that otherwise would remain hidden behind a language barrier. Here\u2019s how the process worked:You want a healthy mix between checking off keywords on your targeted list, and being open to serendipity when your domain experts get an idea. Usually the ideas that work best from domain experts are the ones that arise from being asked the same question 3x, and thinking \u201cI really need a post to send to the next person that asks me this\u201d.\u00a0Make sure you still go through the keyword research process to select a primary keyword for the post, ideally within your targeted parameters, for example a post I sent the team on UTM tracking, a popular topic I got asked about all the time, but the keyword \u201curl builder\u201d made more sense to target having more traffic and less competition, so that\u2019s what we went with.If you\u2019re going for virality in order to attract links, look for trending topics with a low killer / filler ratio: where demand has outstripped supply. For example the day before a big announcement - people want to know what's happening, but there's no news yet, so they keep publishing \u2018filler\u2019 content, and are desperate for anything relevant that can fill the space - that\u2019s your opportunity. Grammarly are the masters of this, getting thousands of high quality backlinks before the election with a study showing Trump supporters have worse grammar."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'B. Research What\u2019s Ranking' for the blog post '\u200dHow to write blog content at scale'"}, {"role": "assistant", "content": "Now you\u2019ve got your keyword, it\u2019s research time: have your SEO lead do the research to see what else is ranking for that topic. Typically I\u2019d look in a keyword research tool so I\u2019m not getting biased (Google serves personalised results to each user). Then I\u2019d click through on each result and read it to see what angle they took and how high quality the post is. You might conclude at this stage these posts are too hard to beat, and go back to the drawing board to pick another topic."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'C. Find a Strategic Angle' for the blog post '\u200dHow to write blog content at scale'"}, {"role": "assistant", "content": "After reading each post that currently ranks for your target topic, you should have a good idea of where they\u2019re strong and weak, and be thinking about how you can differentiate. If everyone else's posts are short, can you make yours long? If the others are mostly text, can yours be an image? Could you offer a contrarian opinion? Or is there something else you can change about your approach? For example, for the keyword \u201creddit ads\u201d the main ranking pages are Reddit themselves, and the rest are \u201chow to\u201d guides. So at Ladder we spent $250 on Reddit and shared the results of our campaign: that helped us rank on the first page amongst much more authoritative sites."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'D. Create a Unique Asset' for the blog post '\u200dHow to write blog content at scale'"}, {"role": "assistant", "content": "It's hard as a new company to win head on in SEO against established incumbents. So we have to differentiate to change the game by differentiating our content vs what's already ranking. There are some ideas for assets below:VideoPodcastSimulatorCourseDatasetWhite paperE-BookGuideSpreadsheetProcess docChecklistInfographicIllustrationDiagramAnimated GifsCalculatorQuotesWebinarWorkshopSlide deckThere are lots of different ways you could differentiate, but you typically only want to choose one asset per post. Every additional thing you call attention to dilutes the main message of the post, and gives your reader too much to remember.\u00a0"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'E. Map Idea to a Persona' for the blog post '\u200dHow to write blog content at scale'"}, {"role": "assistant", "content": "What happens immediately before and after someone is in the market for your product? What are the trigger points? When do they drop out of the market and what takes their focus instead? What emotional states are they likely to be in during these trigger moments (they might be in different states at the same trigger point, depending on persona)? Map out these stages and attach emotional states and quotes to them, and decide what stage that keyword and content piece is targeting. This helps significantly in aligning the writer with the audience that they should be writing for, and keeps style consistent across writers."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'F. Select and Brief Writer' for the blog post '\u200dHow to write blog content at scale'"}, {"role": "assistant", "content": "If you\u2019ve followed the recruiting writer advice, you should have no problem building a list of people who you can call on: as a rule of thumb I\u2019d say you need 60% more writers than the number of posts you plan to publish each week, so 5 writers to consistently deliver 3 posts per week. In order to get the best work out of them you need to write a brief. Luckily you have most of what you need already, if you\u2019ve been following along so far.Primary Keyword - traffic, difficultyRanking Pages - links to the relevant pages ranking for that keywordStrategic Angle - how will you differentiate this post from those already ranking?Trigger Phase - what stage of their purchase journey would they search this term?Emotional State - what emotional state do you want to speak to for this persona?It can also be helpful to link to any docs that explain more about your company, how you work and what your style is.About Us - what does your company do, and why?Get / To / By - what are you trying to do with your creative?Tone of Voice - how should your content sound? Give examples.Finally you want to get your domain expert to record a 10 minute video using Loom on the topic, or schedule an interview on Zoom and record it. This is absolutely key because it\u2019s the mechanism through which you make your post add value. Most other posts were written by professional writers with no real expertise in the topic: even 10 minutes of an expert explaining something will give your writer a lot to go on, and make the post more authentic and useful to the readers."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'G. Optimize for Search Engines' for the blog post '\u200dHow to write blog content at scale'"}, {"role": "assistant", "content": "You should always write for humans first, but you can edit for search engines to rank higher. It\u2019s a lot easier to optimize a good piece of writing for Google than it is to take an SEO-optimized post and make it interesting. To optimize a post for SEO you can use a content optimization tool like ClearScope to suggest keywords to include. Alternatively just take a look at what\u2019s already ranking, and see what secondary keywords these posts rank for with a normal keyword research tool like Ahrefs. Then include them wherever natural - in headlines if possible, and sprinkled through the post to match what people search for.Once the post itself is well optimized, think about how it sits within your existing content hierarchy. Internal links are not just a good way for Google to understand what content is related, but also helps keep your users reading by giving them more relevant content to consume. I\u2019ve had people tell me they read one Ladder blog post and end up with a laundry list of 6 other posts to read. One helpful framework is the Hub and Spoke model - connect subtopics to a master \u2018hub\u2019 topic so equity flows from niche pages to the important ones."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'H. Editorial Review of First Draft' for the blog post '\u200dHow to write blog content at scale'"}, {"role": "assistant", "content": "There should be one person or a dedicated team that\u2019s ultimately responsible for what gets published. It\u2019s important for them to feel ownership, establish consistency in the tone of voice and have responsibility over quality. At first that person might be you, but as you expand you can hire a part time editor, eventually building a full time editorial team. Make sure this person or team is bonused in part by actually getting content live and hitting traffic targets however, or the temptation to be perfectionist will slow things down."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'I. Revise, Publish and Promote' for the blog post '\u200dHow to write blog content at scale'"}, {"role": "assistant", "content": "There may be small or major revisions that need to be made before the piece can go live. Once these have been dealt with and the editor is happy, put the post live. But the work doesn\u2019t stop there: make sure to put the post out on your social channels, tailoring each post to what works on that platform. For example go image-heavy on Instagram whereas threads work best on Twitter. Don\u2019t forget direct messaging: your goal here is to send the post directly to people you know who are knowledgeable and influential, asking them to review the post if they have time, in a non-pushy way. Don\u2019t feel like you have to ask for shares: ask for advice on making the post better and if they like it they\u2019ll share."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'J. Review, Remove or Republish' for the blog post '\u200dHow to write blog content at scale'"}, {"role": "assistant", "content": "Just because the post is out there, doesn\u2019t mean the job is done. Schedule a performance review 3 months after the post is published and check how it\u2019s doing. If it didn\u2019t get above a certain traffic threshold, it\u2019s worth just merging it into another better post or deleting it. You want to do this because Google assigns a limited crawl budget to every site, and you don\u2019t want to waste this budget on pages that don\u2019t do well.For posts that do well, it\u2019s worth doubling down - most posts fail so when you find one that hits, don\u2019t just sit back and watch. Rewrite the post from a new angle, make it better than the first time and republish. This can drive significant traffic boosts because Google likes to see frequently updated content."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'K. Topic Dominance' for the blog post '\u200dHow to write blog content at scale'"}, {"role": "assistant", "content": "If you have a post that\u2019s performing, and republishing gave you a boost, why stop there? Keep going until you completely dominate the topic. Take a look at what else is ranking for that post: are there any second-hand SEO opportunities? Pages that rank for the term that you can get into, or get mentioned in. For example Hubspot would look at the top 10 pages ranking for \u201cbest CRM software\u201d and partner with each of them, as part of their \u201csurround sound strategy\u201d. Alternatively if you already rank in a high position for a term, try to take up more real estate with the \u201cP&G approach\u201d. If you look on a supermarket shelf a high percent of the brands are actually all owned by the same company, Procter & Gamble. On your search term try building or buying another brand that takes another slot on the page, to get more traffic on a term you know works and edge out competitors."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Video Transcription' for the blog post 'Content Repurposing for Social Promotion'"}, {"role": "assistant", "content": "This post is one of a series on my content production system, developed over 10 years and designed to scale content end-to-end in 6 months as an acquisition channel.Here are the other posts in the series:Why the winner takes all in Content MarketingWhat everyone gets wrong about Content Strategy\u200dBuilding Your Keyword Universe\u200dMinimum Viable Technical SEO Audit\u200dRecruiting good Freelance Writers\u200dHow to write blog content at scale\u200dGrowth engineering for SEO\u200dLink building for authorityContent Repurposing for Social Promotion (this post)---Most businesses spend all their time and money creating content, and almost none of their time promoting it. Internal targets are set based on publishing cadence \u2013 3 new blog posts, 1 new podcast, 5 new videos \u2013 so you hit publish and pray the algorithm is in your favor.You\u2019ve done all the hard work to create it, so why not repurpose that content into social media posts to promote it? The truth is that it\u2019s hard enough to finish a good piece of content. Half the time you\u2019re not even sure how the piece will turn out. Now that it\u2019s done you just want to take a break and move on, not stress about how to make it \u2018go viral\u2019 on social media. However the benefits of repurposing your video, text, and audio content are massive. I\u2019ve seen even posts get thousands more visitors, sometimes on the fourth or fifth time we posted.\u00a0Most of the difficulty in producing quality content is in coming up with interesting ideas, researching the topic deeply, and developing a unique opinion on it: an investment sometimes totalling thousands of dollars. As Derek Halpern says \u201cIt\u2019s smarter to find another 10,000 people to consume what you\u2019ve already created as opposed to creating more\u201d. Finding a way to generate multiple assets from each piece of content is key to making the economics work.\u00a0As Joel Klettke from Case Study Buddy describes it, you can turn one core asset into a whole campaign with \"progressively deeper assets suited to difference 'appetites' of your leads, prospects, and clients.\"https://twitter.com/JoelKlettke/status/1567173575056199682/photo/1To illustrate an example of how this can be done in practice, I\u2019ll take the example of a video tutorial for Vexpower, an online marketing training business I co-founded.Make this chart look betterThe key to working with video is to transcribe it. Once it\u2019s in text format you can much more easily turn the video into various pieces of content. I use Loom to record my videos, so I get a nice transcript of the video automatically, though I\u2019ve had success with tools like Descript in the past, as well as the various cloud transcription APIs if you\u2019re doing this programmatically."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Quote Extraction' for the blog post 'Content Repurposing for Social Promotion'"}, {"role": "assistant", "content": "Now that you have a transcript, you have something you can work with. Text is the universal format of communication between humans, but also computers. We can either comb through the transcript ourselves for interesting quotes, or ask an AI model like GPT-3 to highlight some for us. This method isn\u2019t foolproof, and it takes some work iterating to get the prompt exactly right, and reliable across a wide variety of content formats.\u00a0This is where you see the value of a good transcription service: the second quote down got things slightly wrong. Once you have clean highlighted quotes can then be used to clip the video at those specific timestamps. With video clips you can post them to Twitter, or TikTok, or upload them to Youtube Shorts, which most people don\u2019t realize is already generating billions of daily views. It\u2019s possible to overlay text on the videos as well as change the text in the post copy or video description. For this you could use GPT-3 again to summarize the quote.This isn\u2019t ready to post as of yet, so we could pass this idea to our social media team to rewrite. However we could actually rely on GPT-3 again to tidy up the response, in effect using GPT-3 to fix its own work! Note that AI responses are not deterministic, so while some responses are genuinely amazing, you don\u2019t get reliable responses every time, and it can help to have a human in the loop, or multiple layers of testing and evaluation of your prompts.From one video you can create multiple social media posts to space out over the next few weeks or months, and you can do that for every new video you create. Now that you have the transcript however you can repurpose it in other ways. For example with some editing it can be turned into a blog post, a presentation to post on Slideshare, or a long form essay posted to LinkedIn or Medium. Once you start repurposing content, it\u2019ll change the way you create content: you\u2019ll start thinking about promotion from the beginning, and new opportunities to repurpose content into different platforms will present themselves.We're working on a tool to do all this automatically for you. If you'd like to test out the Alpha version, you can sign up here: usebuffalo.com"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Myth #1: Best practices exist' for the blog post 'What everyone gets wrong about Content Strategy'"}, {"role": "assistant", "content": "This post is one of a series on my content production system, developed over 10 years and designed to scale content end-to-end in 6 months as an acquisition channel. Here are the other posts in the series:Why the winner takes all in Content MarketingWhat everyone gets wrong about Content Strategy (this post)\u200dBuilding Your Keyword UniverseMinimum Viable Technical SEO AuditRecruiting good Freelance WritersHow to write blog content at scaleGrowth engineering for SEO\u200dLink building for authorityContent Repurposing for Social Promotion ---To become that winner that takes all in SEO, you need a system that will focus you on the right strategy. To understand the system that worked for me, you have to understand three counterintuitive things I\u2019ve learned about content marketing. The system only makes sense if you bust a few myths that almost everyone believes.If best practices exist, they don\u2019t last long. I\u2019ve made money breaking every rule in the content marketing rule book, because let\u2019s face it, this isn\u2019t a scientifically rigorous industry and most \u2018best practices\u2019 are made up to sell consulting. This is a cutthroat competitive environment with unusual transparency due to the prominence of keyword research and link profiling tools, so as soon as a tactic works, everyone copies it and it stops working.When you don\u2019t know what\u2019s going to work, the correct approach is to make lots of small bets and see what hits. Once you find something that works, you double down to take advantage of compounding exponential returns. To win the top spot as a startup, without the history or authority of your competition, you need to do something different. Following \u2018best practices\u2019 makes you a similar but a less well known version of the winners: it\u2019s just about the worst thing you could do for performance."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Myth #2: Write for your target customer' for the blog post 'What everyone gets wrong about Content Strategy'"}, {"role": "assistant", "content": "Content marketing isn\u2019t a direct response channel. Even if someone Google\u2019s a highly commercial term, the fact that they skipped a half page of ads to click on an organic result means they probably aren\u2019t ready to buy. You do get sales and leads from SEO, but they\u2019re side-effects, not the main benefit. Very few regular readers of our blog at Ladder were target customers \u2014 they were other people doing what we do. But when a CMO wants to hire a PPC agency, they turn to a friend or colleague who knows PPC, who happens to read our blog. Guess who they recommend?If you think about content marketing as a brand channel, the economics make more sense. Unlike normal brand campaigns that aim to get a potential customer to remember you when it\u2019s time to buy, content marketing is trying to win space in the mind of whoever is going to influence that decision. So don\u2019t take the common advice to write to \u201cdecision-makers\u201d \u2014 your content will be boring and you\u2019ll have to dumb it down. Write for the people who really know what they\u2019re doing, and convince them you\u2019re competent too."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Myth #3: Only focus on evergreen content' for the blog post 'What everyone gets wrong about Content Strategy'"}, {"role": "assistant", "content": "There\u2019s a tradeoff between short and long term traffic: you can generate short term spikes by following trending topics, but everyone tells you to focus on ranking on keywords that will compound indefinitely (\u201csnowballs\u201d). This is generally sound advice, because most novices don\u2019t think enough about long term growth. However what this recommendation misses is that having relevant content is not enough: you need backlinks to be able to rank.The trick is to do both. It\u2019s an arbitrage game where you turn short term spikes into long term compounding traffic \u2014 viral content gets noticed by other publishers, and forces them to have an opinion: that\u2019s where you can gather links if you\u2019re there first. That increased authority lifts your ranking across the board, including on your longer term evergreen terms. When we published the hiring freeze database at Candor we attracted over 4,000 backlinks, and hundreds of unrelated pages on our blog suddenly started ranking."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Noise & Scale' for the blog post ' Data Anonymization for Realistic Tutorials, Training & Courses'"}, {"role": "assistant", "content": "Note: I built a tool that anonymizes data for you automatically, you can check it out here:> D-Anon Data AnonymizerI\u2019m the co-founder of Vexpower, where I offer simulator-based courses for marketers to learn how to be more data-driven. I\u2019m a self-trained marketer, so everything I learned was on the job, while growing a 50 person marketing agency, working with clients like Booking.com, Monzo Bank, and Time Out Magazine. I made these courses so marketers can learn all the skills they\u2019re currently not getting from their jobs, because their manager doesn\u2019t know how to do it either, or they\u2019re too busy with work to make time for training.Most people fill the gap with online courses like Udemy, or reading blog posts, but there\u2019s one huge advantage on-the-job training has over these methods: everyone in your office is under NDA (Non-Disclosure Agreement). That means you can share sensitive data with each other: the really good stuff that never leaves the walls of the company. It also means they\u2019re willing to be more candid about how things are really getting done, rather than pretending they use some idealized process that sounds impressive in a blog post.My solution was to make up fictional companies \u2013 like GoolyBib, a smart bib that alerts you when your baby is choking \u2013 and get experts to record themselves showing you how they\u2019d do certain tasks for them. The companies are fictional and the data is fake, so nobody is getting fired or sued for breaking their NDAs. However the data still needs to be realistic! If the underlying relationships in the data aren\u2019t preserved, and the numbers don\u2019t look right, students will struggle to learn anything.In this article I\u2019ll show you some of the methods I\u2019ve found useful in creating unique, realistic, anonymous datasets for 68 courses for Vexpower. I hope you find them useful when making your own online courses, writing blog posts, or any other situation where you need to make sensitive data public. I\u2019d argue with all the privacy legislation, consumer backlash, and cybersecurity concerns, it\u2019s already a good idea to anonymize data you share internally too.DISCLAIMER: I would still recommend you tell your boss or client your plans to anonymize their data and share it. Please don\u2019t start dumping sensitive information in the public realm without getting permission. I\u2019ve found that often people are happy to be supportive, so long as steps have been taken to obscure anything sensitive, and they get to review it before it goes live.The dataset we\u2019re using is itself already anonymized, but I\u2019ll use it to showcase how these techniques work. You can download or make a copy of the data here:> Data AnonymizationThe first and most obvious anonymization technique is to \u2018fuzz\u2019 the data somehow, usually by adding random noise and/or changing the scale. Take some arbitrary number and add it to your sensitive revenue data to scale it up or down. Now competitors won\u2019t be able to reverse-engineer any reliable information about your business, which is the number one concern most people have in my experience.\u00a0Even better if you add some Gaussian noise (the \u2018normal\u2019 distribution, you might remember from stats class), so that the numbers are still mostly related but the digits are unrecognizable. One function I\u2019ve found useful in GSheets for doing this is =NORMINV(RAND(),A1+B1,(C1*A1)), where A1 is the value you\u2019re adding noise to, B1 is the number you\u2019re scaling it by, and C1 is the percentage noise you want to add (i.e. 0.05 for 5%)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Entity Replacement' for the blog post ' Data Anonymization for Realistic Tutorials, Training & Courses'"}, {"role": "assistant", "content": "It\u2019s usually fine to say \u201cI grew a client in the automotive space by 50%\u201d or mention \u201cI used to work on the BMW account\u201d, but it\u2019s not ok to put the two together. Share the name OR the numbers, but not both. So long as you stick to this rule, even if someone *thinks* they know where the data came from, there\u2019s plausible deniability. They have no proof, so the data is of limited value to competitors, and the company will be more comfortable with you sharing it.What if you accidentally shared real website referrer data in a blog post? Now anyone can look and see what websites send you traffic. Then it\u2019d be pretty easy to piece together who the data is coming from. You\u2019re basically handing competitors a playbook to steal that traffic! However you can\u2019t just replace these values with something arbitrary: any relationship in the data between referrer and user behavior would vanish, making it useful for you to use in training. The solution is a trick called Entity Replacement, which is replacing the values with a new random value that has no meaning, but it\u2019s the same value every time. Most people do this manually with find/replace, but it\u2019s better and faster with a lookup.With website referrers example, you could replace \u201cbmw.co.jp\u201d with \u201ccars.co.jp\u201d every time it occurs. Now nobody can figure out what website the traffic is coming from, but when you do analysis on conversion rate by referrer, the relationship will still be there. This is useful for lots of fields \u2013 names, credit cards, addresses \u2013 anything that could be used to trace the identity of the company or user. To do this in GSheets, you just need to make a list of all the values that occur in the original data with the UNIQUE() function, then use the mighty VLOOKUP to match that to an arbitrary (deduplicated) replacement value."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Date Series' for the blog post ' Data Anonymization for Realistic Tutorials, Training & Courses'"}, {"role": "assistant", "content": "The other neat trick I\u2019ve been using a lot is date series replacement. We\u2019re famous for our marketing mix modeling training at Vexpower: a privacy-friendly marketing attribution technique that requires time series data. You might be tempted to use entity replacement on dates, but that\u2019d be a mistake. Unlike entities, with dates the order matters. If we replace the date with a randomly selected date in the past or future, we have to make sure that every other date in the series follows on. Otherwise when we\u2019re doing analysis, the models we build will get the timeline mixed up, and won\u2019t be able to make accurate predictions.The simplest way I\u2019ve found to do this in GSheets is to convert the original date into its component parts \u2013 Year, Month, Day \u2013 then piece them back together after, each with a different arbitrary number added or subtracted from it. Those numbers stay consistent for all dates, and so long as you don\u2019t have any formatting issues, your time series relationships will stay maintained. One thing I recommend here is to do your feature engineering first, before anonymization. You need to know if a spike in the data was around a national holiday, so extract seasonal features like that first, and change the names if you have to to maintain secrecy."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Conclusion' for the blog post ' Data Anonymization for Realistic Tutorials, Training & Courses'"}, {"role": "assistant", "content": "Anonymizing data is a complicated topic, one that hasn\u2019t been written enough about. Most people who need to anonymize data, subject themselves to lots of manual find/replace and other manual manipulation. This is one of the big barriers to sharing more content online, creating more courses, and teaching more people. If we can make data anonymization easier, more people will be able to learn how to do a better job, get recruited and promoted. If done well, even very sensitive data can be properly obscured enough to share publicly.As you got this far, I built a tool that anonymizes data for you automatically, and would appreciate any feedback you can give:> D-Anon Data Anonymizer"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'What can Econometric Modelling do?' for the blog post 'Econometrics in GSheets'"}, {"role": "assistant", "content": "You may have heard the term Econometrics or \"Marketing Mix Modeling\" (which is Econometrics applied to Marketing), but most don't know how it works. The World's largest advertisers like Procter & Gamble, Unilever and Coca-Cola use it to measure marketing ROI \u2014 for example calculating how many incremental sales a Superbowl ad drove.This is an entry level post, so if you have heard of MMM and want to dive deeper to learn more, we have a lot of intermediate to advanced marketing mix modeling courses at vexpower.com.I've also built a free point-and-click browser-based tool for MMM that you should check out: https://tools.saxifrage.xyz/linesthttps://tools.saxifrage.xyz/linestThese methods are performed on behalf of large brands by experienced specialists to make life or death decisions on where to allocate multi-million dollar marketing budgets. When done well, Econometrics can answer valuable questions:Is Facebook really responsible for as many sales as they\u2019re reporting?How do I calculate ROI when I invest in less measurable channels like TV?Did my agency actually drive this spike in sales, or was it some other factor?How much more do I sell when I lower my prices, or run a promotion?What would happen to revenue if I increased my marketing budget?These are core strategic questions that every marketing leader must answer, yet many resort to guesswork when making these decisions. There\u2019s a lack of awareness amongst marketers around what Econometrics is, what it can do, and how it works.Given the value of these techniques, and the politics that come with making large-scale budget decisions, most Econometricians are hesitant to share their methods. Thankfully, the core techniques can be easily replicated in Google Sheets, which is what I\u2019ve done here:Econometric Model for Pie SalesThere\u2019s no complex math, and you don\u2019t need a degree in statistics to understand it. This example uses fake data for a fictional company selling pies, but it\u2019s enough to showcase the techniques involved. You can use this template to build your own model, or just follow along to become more informed before working with a professional (get in touch if you need help). If you're familiar with Econometrics and want to learn how to do this in Python, see Econometrics in Python.With the rise of digital advertising and technologies like micro-targeting, methods like Market Mix Modelling began to look old-fashioned vs tracking each user directly to purchase. However with 30% adoption of ad blockers, the roll out of consumer privacy legislation like GDPR and CCPA, and moves against 3rd-party cookies or unique identifiers, expect a shift back to privacy-friendly marketing attribution methods like Econometrics.Econometrics is the practice of applying statistical techniques to economic data to explain the underlying relationships in the data. The common application we\u2019re concerning ourselves with is called Marketing Mix Modelling, which attempts to predict sales based on factors like how much you spent on advertising, what price you set for your products or if it was a sunny day.These factors are input as variables in a multivariate linear regression analysis, which outputs coefficients you can plug into an equation. This is important not just because it\u2019s useful to be able to predict sales, but because knowing how predictive each variable is, tells you the contribution of that factor to revenue. Meaning you can calculate how much revenue you made from marketing, without needing to track your user\u2019s conversion journey\u2019s directly."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'What makes sales go up and down?' for the blog post 'Econometrics in GSheets'"}, {"role": "assistant", "content": "Taking our fictional pie company (data from Jalayer Academy), we can chart our sales over time and see the line moving up and down without explanation. If you go ahead and chart your sales in the same fashion, you\u2019ll see movements up and down unique to your company.The main question we\u2019re trying to answer is \u2018what makes sales go up and down\u2019. If we know that, we can strip out external factors (\u2018do sales go up or down when it\u2019s a holiday?\u2019) and determine what credit internal factors deserve (\u2018how much revenue did my advertising generate?\u2019)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Match spikes and dips to internal and external factors' for the blog post 'Econometrics in GSheets'"}, {"role": "assistant", "content": "If we take just one variable like the average price at which we sold our pies, we can see how much that factor explains the changes in sales. We intuitively expect that a lower price will sell more pies, but our analysis will tell us how much more for each dollar change in price.If we do a simple scatter plot chart and add a trendline, we can see that Price on its own explains only about 19% of the variance in the sales data. There does visually seem to be a downwards trend where the higher the price the lower the sales, which makes sense.Plotting out our predictions based solely on price, we can tell we\u2019re not seeing the full picture here \u2013 our forecast is consistently off by a large enough amount to render our model useless in making predictions on sales. This is reassuring, because if price explained all of the variance, it would be the same as saying our marketing budget had no impact!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Introduce more variables to better fit the line' for the blog post 'Econometrics in GSheets'"}, {"role": "assistant", "content": "The aim of the game is to dig through our data to find the right mix of variables to introduce in our model, so as to explain away more of the movement in sales. As marketers we\u2019re doing this analysis to find out what impact our marketing had on revenue, so let\u2019s add that as a variable.You don\u2019t need a background in statistics to see what\u2019s happening here. The two lines are now much closer together, meaning going from one variable to two seemed to improve our model. It\u2019s not quite ready to bet your job on it, but now you can clearly see advertising made a contribution."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Find an equation that can predict sales' for the blog post 'Econometrics in GSheets'"}, {"role": "assistant", "content": "Our model with just price and advertising budget was doing better than price alone, but was still missing something because it incorporated only factors we had control over. In the real world, we aren\u2019t in full control of the market, and we need to incorporate information about the outside world to have any hope of model accuracy.Here we\u2019ve incorporated a variable denoting if the week was a holiday or not. This is called a binary variable, and it\u2019s used to flag special time periods where conditions were different. For example in your model you might want to add a variable for \u2018in lockdown from a global pandemic\u2019 as a factor to determine what your sales would have been in a world without Coronavirus. We don\u2019t have to use binary variables for external factors \u2013 for example it could be used to note whether your top selling product was in stock, the date you implemented a new marketing strategy, or the presence of a winning ad creative.Amazingly, with just three variables, the two lines are lining up almost perfectly. We shouldn\u2019t expect every analysis we do to be this easy, nor should we plan to capture everything in our model. However we can use this example to illustrate how with a handful of predictive variables we can reveal some valuable insights into what drives sales for our business.Sales = -17 * Price + 16 * Advertising + 89 * Holiday + 415The equation the model gives us, shows what impact each factor had in driving sales. This is where decisions can be made and actions taken once we understand the implications of what this equation is telling us. The figures for sales and advertising budget are in thousands, so we can interpret the model coefficients as follows:Price had a negative impact of -17, meaning we lost $17,000 in sales revenue for every dollar we increased the price of our piesAdvertising drove $16,000 in sales revenue for every thousand dollars spent, or our return on investment (ROI) was 16:1Holidays were good for our pie company, as we made an extra $89,000 in sales for every week where there was a holidayOur intercept was 415 or $415,000 in sales, meaning all things held equal, we\u2019d get about this much in sales without these three variables"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Can we really trust the data?' for the blog post 'Econometrics in GSheets'"}, {"role": "assistant", "content": "All models are a simplification of the real world, so by nature they\u2019re wrong. For example there are thousands of variables that affect sales of pies, including the weather, competitor activity and the quality of your ad creative, none of which are captured here. Just because these three factors have been highly correlated to sales in the past, doesn\u2019t mean that relationship will hold in the future. We might also mix up our correlations \u2013 in this data set adspend is highly correlated with holidays, so missing one of those variables overstates the effect of the other.However this is not a good excuse to go back to making gut decisions. Every decision we make models future outcomes with past data. We expect based on past experience that getting on the number 42 bus at the Tower of London will take us to Liverpool St Station in about 16 minutes. Yet that\u2019s only a prediction, not a guarantee \u2013 there might be traffic, roadworks, or a change of route. Because your past data might be wrong, do you give up estimating travel time entirely?The difference between using your gut (where your brain models future outcomes based on past data) and a spreadsheet like the one we made (where a formula models future outcomes based on past data), is that the spreadsheet is transparent about how it's making those predictions. This means it can more easily be interrogated and improved.\u00a0Ultimately the best test of a model is how well it improves your ability to take the right actions under uncertainty.Try and guess next month\u2019s sales and see how you do versus the spreadsheet. Simple models like this one often reliably outperform humans, so I don\u2019t fancy your chances. Instead I recommend spending that energy brainstorming ways the model might be wrong, and only using your judgement to deviate where you have conviction."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How can you do multivariate regression in GSheets?' for the blog post 'Econometrics in GSheets'"}, {"role": "assistant", "content": "The method I originally found in this video by Jalayer Academy used a Google Sheets add-on package called XLMiner, which was broken by Google\u2019s move to verify apps in December 2019. Instead I adapted the method to use the native\u00a0 LINEST function, which works well for our purposes.LINEST(known_data_y, known_data_x, [calculate_b], [verbose])known_data_y - this is the variable you want to predict, in our case salesknown_data_x - the variable(s) you think can predict y (price, advertising, holiday)[calculate_b] - optional variable to calculate the intercept, default true[verbose] - optional variable to return all descriptive statistics, default falseIn our model it looks like this:\u00a0You can see what these numbers look like if you just incorporate 1 variable, or expand to 2 variables. To adapt to your business simply create your own sheet with the same function but different data and variables and see what results you get. Be aware that for some reason the coefficients come out in backwards order!Once you have the coefficients you can plug them into a formula to be able to predict the number of sales for any combination. In the template we can see the coefficients given by the model in cells D23 through E23, and can put them together to construct our equation.Sales = -17 * Price + 16 * Advertising + 89 * Holiday + 415To get our charts we simply plugged back in the past data we had into this equation to see how close the prediction would be to the number of sales we actually saw. This let\u2019s us determine the accuracy. Ideally you would then test the model by trying this equation on data it hasn\u2019t seen yet, and see how well it does."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Verbose output of descriptive statistics' for the blog post 'Econometrics in GSheets'"}, {"role": "assistant", "content": "You\u2019ll notice further down in the model at rows 25 to 42, we\u2019re seeing what it looks like when you choose the \u2018verbose\u2019 output option with LINEST. Unless you\u2019re working with statistics regularly you probably won\u2019t know what these descriptions mean, but you can get pretty far by Googling each term and reading the Wikipedia page.The output is a little strange especially with the #NA fields, but don\u2019t worry about them. Instead concentrate on the dictionary of descriptions I put together below in yellow. I have linked each value to these descriptions so you can interpret where this would go in your own spreadsheet.\u00a0The main field which is important aside from the coefficients (which you get in the non-verbose version of the function) is the coefficient of determination, or the R-squared. This is the same as what you saw in the scatterplot showing Pie Sales vs Price, but this time it\u2019s showing the variance predicted by the three variables you included in your regression analysis. It tells us that this model explains about 83% of the variance we see in sales \u2013 still some way to go, but pretty predictive considering the simplicity of the model."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '***Disclaimer \u2013 IANAS (I Am Not A Statistician)***' for the blog post 'Econometrics in GSheets'"}, {"role": "assistant", "content": "I did get a Masters degree in Economics, and I\u2019ve used these techniques in my work at Ladder and Saxifrage, but I\u2019m not a professional statistician and there are gross oversimplifications in this post. I\u2019m of the belief that any model is better than no model, so I still recommend you follow along and build your own. However if you\u2019re doing this for any reasonably sized marketing budget ($100k+ per month), contact me and I can help connect you with an expert."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Measuring long-lasting effects with adstocks' for the blog post 'Econometrics in GSheets'"}, {"role": "assistant", "content": "Once you\u2019ve built a simple model, you\u2019ll naturally want to experiment with adding in complexity to see if that improves predictions. One common feature of Marketing Mix Models is a factor called \u2018Adstocks\u2019. The theory goes that some marketing channels like TV have a longer lasting brand advertising effect, so you need some way of incorporating this in your model.In practice the way this is calculated, is by assuming an \u2018adstock rate\u2019, which is the amount of spillover you get across time periods. An adstock rate of 50% from week to week means an effect as large as 50% of the adstock last week, is felt the week after the spend occurred. The formula then decays by 50% a week until the effect disappears.For the first time period, adstock is just equal to the advertising spend. For all other time periods, it equals the advertising budget for that week, plus the adstock rate multiplied by the prior week\u2019s adstocks (which in week 2, would be week 1\u2019s advertising budget). Adstocks is then used as a variable in the regression in place of advertising. Check out the second tab of our model to see how this works.With a relatively low adstock rate like 15%, it has the effect of smoothing out advertising budget, so the impact doesn\u2019t drop off as quickly. In our model the marketing budget was always on, so the effect isn\u2019t as clear as it might be for an advertiser running one-off TV campaigns.With a very high adstock rate like 50%, you can see the effect builds and stays high, which may or may not be realistic depending on the marketing channel and business. The trick is to experiment with multiple adstock rates until you find one that best fits the model. Typically brand advertising channels like TV, radio or PR might have longer effects than direct marketing channels like Google Ads, direct mail or cold email.In our model adstocks doesn\u2019t seem to be a hugely important variable \u2013 with an adstock level of 15% we can increase the R-squared of the model from 0.836 to 0.839, but this is hardly worth including. In other models for other businesses correctly incorporating adstocks is the biggest determinant of model accuracy.---That covers the basics of Econometrics, and we did it all in Google Sheets! To see this same process but in Python instead of GSheets, or to learn about Diminishing Returns, visit the next posts in this series:Econometrics in GSheets (this post)Econometrics in PythonDiminishing ReturnsMeasuring the Halo Effect\u200dWhen Econometrics WorksIn future we plan to cover:Word of Mouth CoefficientTesting Model AccuracyMonte-Carlo SimulationsMachine Learning ModelsData Import from APIsThe Future of EconometricsAny other topics? Tweet @hammer_mt to request\u200dI also highly recommend you check out my marketing mix modeling training simulator."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How can you do multivariate regression in Python?' for the blog post 'Econometrics in Python'"}, {"role": "assistant", "content": "This post is a follow up to my post \u2018Econometrics in GSheets\u2019. In this post I\u2019ll be replicating the same process in a Google Colab notebook using Python, rather than using GSheets. If you\u2019re not already familiar with Econometrics, I recommend you go back and read that post first.My previous post used native LINEST function to run a multivariate regression in Google Sheets. I adapted this method and took the data from this video by Jalayer Academy using a Google Sheets add-on package called XLMiner, which was broken by Google\u2019s move to verify apps in December 2019.\u00a0In this post we\u2019ll be using the exact same data, process and technique \u2013 we\u2019ll even get the same results! We\u2019re just replicating it in Python using a Google Colab notebook (a free, hosted version of a Jupyter Notebook). If you\u2019re familiar with Python you\u2019ll be able to take this code and run it wherever you need it. If you\u2019re new to coding, Colab is probably the easiest way to learn \u2013 you can run each cell inline to see what it does.To follow along, here is the Google Colab notebook for you to copy:Econometric Model for Pie SalesThankfully the scikit-learn (SKLearn) and Pandas libraries make this incredibly easy. Once you have your data in the right format it\u2019s as easy as running this one line of code:model.fit(X, y)model - this is the linear regression model we will initialize with SKLearny - this is the variable you want to predict, in our case salesX - the variable(s) you think can predict y (price, advertising, holiday)Then once your model has been fit, we can get the normal coefficients, R-squared value and make predictions, just as we did with Google Sheets \u2013 in fact, the numbers will match exactly. Then of course you can plot the forecast, which in our model looks like this:"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Why should you do Econometrics in Python?' for the blog post 'Econometrics in Python'"}, {"role": "assistant", "content": "Python is harder to learn than Google Sheets, and less intuitive, especially for non-technical team members who might want to make changes to the model without using a developer or data scientist. So what are the benefits of using Python to build your Marketing Mix Model?The main benefit is reusability \u2013 once you\u2019ve written the script once, you can run it over and over again, and instantly get exactly the same results. As such code is inherently more reliable and scalable than relying on GSheets, which takes a lot of manual effort in formatting each time, and is more prone to human error. Code can also be productized, that means you can build an interface for non-technical users to run the model (hiding complexity from them, and limiting potential mistakes) as well as connecting it into other systems (like automatically making budget changes in your Google or Facebook ad accounts).The other big benefit is flexibility. Libraries like scikit-learn have commoditized algorithms \u2013 without understanding any of the math or even making many changes to your code, you can import a different model like Naive Bayes, Random Forests or XGBoost, and see how it compares in accuracy. This opens up the possibility of using machine learning algorithms, as well as advanced techniques for improving accuracy, like cross validation."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Getting the data in the right format' for the blog post 'Econometrics in Python'"}, {"role": "assistant", "content": "First you want to create your own Google Colab notebook, or make a copy of our model to follow along with your own data. You can find my data here, then download the GSheet as a CSV. The next step is to upload the file into Google Colab, which is in the left hand menu under files, click the upload icon (first one).Now let\u2019s see what we have \u2013 import Pandas (the closest thing Python has to Excel), load the CSV then display the head (first five rows).We\u2019re going to do some cleaning of the data, just dropping the \u2018Week\u2019 column, renaming the other columns, and changing the index to match the week number (indexes start at 0 by default).Great, we\u2019re already at the fun part. Import the linear model from the SKLearn library, define your y (what you want to predict) and X variables (what think is predictive), fit the model and print out the R-squared score.As you can see, SKLearn makes this trivially easy if you know a bit of Python. We simply initialize the model (that\u2019s the `model = linear_model.LinearRegression()` line), and run `model.fit(X, y)`. Then the model is ready to give us the R-squared value, as well as other important information like the coefficients.This cell block is simply printing out the coefficients one by one and labeling them with the column names we chose. Rather than using the coefficients to make predictions like we needed to do with GSheets and LINEST, we can actually just get the predictions directly from the model.Here we assigned the predictions back to be a new column in the Pandas data frame as a \u2018forecast\u2019 column. Here we can eyeball how close it is to the actual sales data, as well as compare it to the data we had in our original GSheet model \u2013 you should see they\u2019re the same!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Visualizing the Forecast Data' for the blog post 'Econometrics in Python'"}, {"role": "assistant", "content": "Creating the line chart isn\u2019t quite as intuitive in Python as it is within GSheets \u2013 we have to use a fairly old library called MatPlotLib. However the benefit of doing this in code is that once you get the right formatting you can get the same results again and again without any further work.The above code uses MatPlotLib to plot a line chart of the sales and forecast data. We have full flexibility over the color of the lines, the size of the figure, as well as the titles, legend and axis labels. We also annotated the chart with the R squared, to see the accuracy at a glance."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Packaging up code for reuse' for the blog post 'Econometrics in Python'"}, {"role": "assistant", "content": "It was a pain to write all this code from scratch \u2013 I had to look up a lot of the functions I hadn\u2019t used in a while, and it took far longer than creating the GSheet. Not to mention the 7 years of evenings and weekends I spent learning to code in the first place! However now we come to the big payoff. Unlike GSheets, we can package this code up in a function or library to use again and again. It just involves taking the same inputs, and generating the same outputs, using exactly the same code, just all put together in a function.You\u2019ll recognize all the various pieces, which all fit into this function rather than individual cells. This is one of the benefits of Jupyter Notebooks and Google Colab \u2013 you can run things line by line in cells to figure out how they work, then package them together in a function to use later. Now we have this function, running another regression with different variables is as easy as `run_econometrics(df, y, X)`. For example if we wanted to test the accuracy of just 2 variables.At this stage we could make just a few modifications and run it on a server, offer it as an API, connect into our analytics account using an ETL, really it\u2019s up to us how we use it. We could schedule it to run once a year, quarter, week, day or hour if we please. We can start testing new variables, engineering new features and testing to see if we can improve accuracy. Google Sheets is great to get started, but if you\u2019re serious about Econometrics, you need code."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Measuring long-lasting effects with adstocks' for the blog post 'Econometrics in Python'"}, {"role": "assistant", "content": "Now we have a function for running this analysis with little effort, we can engineer new features and test them in the model with very little effort. For example in our GSheets model we transformed Advertising Spend into Adstocks, which let us measure carry-over effects from our advertising. We can do this in Python using a technique adapted from Sarbadal Pal.This method loops through the advertising values and calculates the adstocks, just as our GSheets formula did. Check and see that the values exactly match what we had in our GSheets model. Note that this function is not vectorized (meaning it might run slow on larger datasets), but it\u2019s good enough for our purposes.\u00a0Because we packaged up our code, it\u2019s simple to run the same regression analysis but with our newly engineered feature. This is quite a simple model, but you can imagine if you\u2019re doing this type of market mix modeling with huge datasets and thousands of variables, learning how to do this in Python really pays off in time saved.---That covers how to do Econometrics in Python, using Google Colab and the Pandas + Scikit-Learn + MatPlotLib libraries. To see this same process but in GSheets instead of Python (and learn a bit more about Econometrics), visit the previous post in this series or keep reading the next post to learn about Diminishing Returns:Econometrics in GSheetsEconometrics in Python (this post)Diminishing ReturnsMeasuring the Halo Effect\u200dWhen Econometrics WorksIn future we plan to cover:Word of Mouth CoefficientTesting Model AccuracyMonte-Carlo SimulationsMachine Learning ModelsData Import from APIsThe Future of EconometricsAny other topics? Tweet @hammer_mt to request"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'What questions can Econometrics answer?' for the blog post 'When Econometrics Works'"}, {"role": "assistant", "content": "Econometrics or Marketing Mix Modeling (MMM) is a powerful tool for deciding where to spend your marketing budget. It uses Linear Regression to associate spikes and dips in sales back to actual events, for example price increases, changes in the weather and spend on advertising.\u00a0This is an alternative to attribution modeling, which measures at the user level to assign credit for each purchase. For example in Google Analytics you can see how many conversions came from Facebook ads on a \u2018last click\u2019 basis \u2014 that\u2019s attribution modeling. The Econometrics approach would look at increases or decreases in conversions relative to how much you spent on Facebook, taking into account the \u2018halo effect\u2019 not captured with a last click model.So how do you choose whether attribution modeling vs econometrics? No one approach is applicable to every situation, and smart marketers often use them both for different reasons. Econometrics tends to be more useful on the strategic level, but often doesn\u2019t provide much granular insight. Whereas attribution modeling is extremely granular making it useful for optimization, but alone it can lead to over-investment (or under-investment) in certain channels.There are several recurring questions that every marketer eventually faces, where Econometrics has a good chance of getting you an answer.\u00a0"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Why doesn\u2019t Facebook match Google Analytics?' for the blog post 'When Econometrics Works'"}, {"role": "assistant", "content": "This is a classic example of a question that attribution modeling really struggles to answer. Any marketer running ads will quickly realize that what the ad platform is reporting doesn\u2019t match what their own analytics is telling them. Using our example of Facebook ads and Google Analytics, there are several reasons why attribution fails.View Through: Facebook counts conversions that came 24 hours after someone viewed an ad \u2014 Google Analytics doesn\u2019t have access to this view through dataClick Window: Facebook counts all conversions that came within 28 days of a click on an ad (even if they came back to the website via another channel later) \u2014 Google Analytics only gives credit to the last click before a saleDate Assignment: Facebook assigns a conversion back to the day the ad ran \u2014 Google Analytics registers the conversion on the day the conversion happenedAs you can see there are a number of reasons why attribution might not be perfect. Ultimately you\u2019re left trying to decide who to trust, Facebook or Google? Both models are biased in some way based on the incentives of the companies who own them. Facebook probably didn\u2019t drive all of those \u2018view through\u2019 conversions, but we also can\u2019t argue view through has zero value.Econometrics stands apart from platform bias \u2014 you run the analysis on your own data, so you don\u2019t need to rely on Facebook and Google to tell you the truth. It will give a fair assessment of what the incremental impact of Facebook ads actually is. Usually this takes the form of a \u2018multiplier\u2019, for example it\u2019ll tell you that 40% of Facebook\u2019s view-through conversions were incremental. So you can make strategic budgeting decisions by down-weighting Facebook\u2019s ROI by 0.4, and invest accordingly.Note this isn\u2019t just useful for when Facebook ads and Google disagree \u2014 any time a channel might be under or over weighted based on the way it measures performance, Econometrics can help. Examples include retargeting ads (which are targeting people likely to convert anyway), brand keyword campaigns on Google ads (which attract people already familiar with you) and podcast advertising (where users often come months later having forgotten the discount code)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'If I doubled my marketing budget, what would be my ROI?' for the blog post 'When Econometrics Works'"}, {"role": "assistant", "content": "This is a common question, especially in ambitious, fast-growing startups. They want to know if they increased their investment, what would they get for it? You want to check that your marketing goals are realistic, and if you\u2019re wise to the impact of diminishing returns, you\u2019ll want to make sure you aren\u2019t setting yourself up to fail. This can be useful to make the case for more budget, but also to determine which channels should get that budget \u2014 what is the optimum marketing mix for your business to maximize ROI?\u00a0This is something attribution can\u2019t tell you \u2014 it\u2019s focused on telling you how well a channel is performing right now, but can\u2019t easily extrapolate out to the future. Thankfully Econometrics can tell you not just how much your cost per acquisition will increase per $1 of ad spend, but also let you forecast what your cost per acquisition will be at different budget levels to make your decision. As a caveat, I should mention it\u2019s important not to extrapolate out too far without testing at higher spend levels \u2014 the further out you go the more accuracy suffers."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How do I measure the impact of TV?' for the blog post 'When Econometrics Works'"}, {"role": "assistant", "content": "For many data-driven startups, they find the level of control and optimization they\u2019re used to with digital ads just doesn\u2019t exist on TV. There\u2019s no way for the user to \u2018click\u2019 to their website, so in effect everything is \u2018view through\u2019! In addition, TV tends to work more as a branding channel rather than direct response \u2014 it might take months for a sale to happen after viewing a TV ad, rather than minutes, hours or days.Econometrics can tease out these complex non-linear effects, and show you not just how much TV drives your sales, but also over what timeline and payback period. It can even show you how a campaign for one product might impact sales of another product \u2014 an effect that most marketers are positively surprised by. Of course as well as TV, Econometrics is a good solution (often the only solution) for measuring other offline channels, like billboards, radio or press."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'What was the impact of COVID-19 on my business?' for the blog post 'When Econometrics Works'"}, {"role": "assistant", "content": "As marketers, we\u2019d love to think we\u2019re in control of everything that impacts our businesses\u2019 growth. Unfortunately that just isn\u2019t the case \u2014 as all of us were reminded by the impact of COVID-19. For some businesses it was as much as a 90% drop in performance, for others particularly in ecommerce, they saw skyrocketing growth. What is harder to tell is precisely how much positive or negative impact COVID is having \u2014 was it really your agency\u2019s smart maneuvers that led to increased sales or were they just riding a macro-economic wave?Of course COVID-19 isn\u2019t the only external economic impact your business faces. The growth rate of your industry, demographic trends, even weather can make an impact on your sales. Most Econometricians attempt to work these factors in. Another important factor to consider is competitive behavior \u2014 is your biggest rival suddenly spending on TV? It\u2019s often possible to measure or estimate competitive activity and work this into your model to explain dips or spikes that otherwise would have been unexplained in your marketing attribution model."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How do I measure performance when users don't want to be tracked?' for the blog post 'When Econometrics Works'"}, {"role": "assistant", "content": "There is an ongoing privacy backlash against the surveillance capitalism that powers the online advertising industry. Safari and Firefox have removed 3rd-party cookies used for marketing attribution, and even Google Chrome is following suit. Around a third of website visitors use Adblock and Apple is killing the IDFA tracking id that enables marketing attribution on mobile apps. On top of that the GDPR legislation in Europe and CCPA in California put you at risk of a fine if you violate users privacy, even for the purposes of marketing attribution. Thankfully Econometrics can help step into these gaps and give you some way to make strategic budgeting decisions without the user-level data you're missing. Econometrics is fundamentally a privacy-friendly attribution method \u2014 one that will always work even if 100% of your users were anonymous. As the era of big data comes to an end with users increasingly opting out of tracking, companies will need to rely more on Econometrics and Marketing Mix Modeling to determine the effectiveness of their campaigns."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'When does Econometrics not work?' for the blog post 'When Econometrics Works'"}, {"role": "assistant", "content": "Of course Econometrics can\u2019t solve every strategic marketing question for your company. Often you\u2019ll find that the actions you want to take can\u2019t be predicted based on the data you have, and you\u2019re left with attribution modeling or even \u2018gut feel\u2019 to guide you."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'User-level data' for the blog post 'When Econometrics Works'"}, {"role": "assistant", "content": "This is the biggest downside of Econometrics \u2014 because it only uses aggregate data, it can\u2019t tell you about any individual user. With attribution modeling you can pull up a list of users that came from a specific channel and visually inspect the data, send campaigns to them, whatever you need to. With Econometrics you only see a high level view, so it can\u2019t tell you anything about individual users.Of course the usefulness of user-level data is a garbage in, garbage out situation \u2014 unless you\u2019re really confident in your attribution model, your data might not be that actionable. There\u2019s a difference between being precise and being accurate. However if you really do need user level data for whatever reason, then Econometrics isn\u2019t the right tool for the job."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Optimization in real-time' for the blog post 'When Econometrics Works'"}, {"role": "assistant", "content": "Often building an econometric model takes anything from hours to weeks or months. It can be particularly slow for large, complex businesses that have many stakeholders and non-standard data sources. Often just cleaning the data can take 80% of the time allocated to the project, so most practitioners run a model only once or twice a year.Additionally because Econometrics tends to look at things in macro, the big picture, it often finds no significant impact for smaller changes, making it better for strategic rather than tactical decisions. When you change your bids on Facebook ads or update an ad with a different call to action, you aren\u2019t likely to move the needle enough to register in an Econometric model, but these activities can still be very important to driving ROI.\u00a0"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Brand New Activities' for the blog post 'When Econometrics Works'"}, {"role": "assistant", "content": "Econometrics relies on past data to look for patterns on what the future could look like. The past can be surprisingly predictive of the future, even with simple models. However if we\u2019re trying to predict an activity that\u2019s entirely new, we might find that Econometrics doesn\u2019t have much to say about it. For example a new marketing channel might perform very differently from our existing ones, a new creative route might perform far better (or worse) than expected from past creative tests, or increasing ad spend by a considerable amount might lead to rapidly diminishing returns that we hadn\u2019t seen in the data to date.---If you\u2019re interested in getting started with Econometrics, or want to ask a few more questions, don\u2019t hesitate to reach out and ask. @hammer_mtIf you\u2019d like to learn more about Econometrics, check out the rest of the posts in the series:Econometrics in GSheetsEconometrics in PythonDiminishing ReturnsMeasuring the Halo Effect\u200dWhen Econometrics Works (this post)In future we plan to cover:Word of Mouth CoefficientTesting Model AccuracyMonte-Carlo SimulationsMachine Learning ModelsData Import from APIsThe Future of EconometricsAny other topics? Tweet @hammer_mt to request"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '1. Network effects' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "If you plan to use viral growth as a channel, what are your options? There are 7 fundamental types of virality, or flavors, and they're all a little different.Getting just one to work is a multi-million dollar achievement \u2014 chaining multiple methods together puts you among the fastest growing companies in history. Once you know how they work, and who they worked for, you can decide what to test for your business.Social networks like Instagram and Snapchat are only useful when other people are using them. If you loaded up TikTok and there were no videos to watch, it wouldn't be much fun.In fact, Metcalf's Law says the usefulness of a network increases exponentially \u2014 two people can make only 1 connection, five can make 10 connections, and twelve can make 66 connections.With this type of virality, your users invite their friends and colleagues through self-interest. The product gets inherently better for them the more people they invite.Because these platforms are often linked to identity, users are further incentivized to share because of what it says about them, and their relationship with you. Inviting your friend to Clubhouse tells them you're a 'tech insider', and that you think they're worthy too.Products that build network effects can become incredibly valuable, and difficult to compete with. No matter how much you hate Facebook, you can't easily delete your profile, because that's the one platform everyone you know is on.https://www.applicoinc.com/blog/network-effects/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'External' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "This is where there's the opportunity to connect with people outside of your circle of friends or colleagues. Examples in B2C include TikTok, where your videos are show in the feeds of people you don't yet follow, Meetup.com where you can find events and meet people based on your interests, and video games like Fortnite, where you can be paired up with players you don't know. On the business side you have social networks like LinkedIn, in-person events like South-by-Southwest and video call tools like Zoom.https://blog.zoom.us/wordpress/2017/11/14/how-zoom-employees-use-zoom/This is a strong form of virality, because the product just doesn't work if just your friend group or coworkers are using it. Because of this, external virality faces the 'cold start' problem \u2014 in the beginning nobody is using it, so it's not very useful. At scale these products can become near impossible to compete with."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Internal' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "This is when the network is primarily for connecting inside your friend group or company. Examples on the consumer side include messaging apps like Whatsapp, games like online Poker or group experiences like Wine tasting. For B2B you also see messaging apps like Slack, productivity tools like Asana and analytics platforms such as Amplitude.https://www.youtube.com/watch?v=_6iARmVpOrQThese companies tend to 'land and expand' \u2014 growing virally once they enter a group, but with the aid of other growth channels to drive the initial introduction. This is a weaker form of virality because it's limited by group size, but still can drive significant value."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '2. Casual Contact' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "This type of virality occurs when a public-facing aspect of the product exposes new potential users to its functionality or branding. The classic example is Hotmail, which put \"Get your free email at Hotmail\" at the bottom of each email its users sent. With users sending hundreds of emails a month, this served as free advertising. Many companies design this explicitly into their products as a way to engineer virality."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Signature' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "Like the Hotmail example, this is when the product displays their branding as the product is used. For example the bag your jeans come in have the logo of the store, the \"powered by Sumo\" badge you see on email popups, or the Uber or Lyft signs displayed by drivers of the service.https://www.growth-hackers.net/growth-hacking-examples-inspiration/hotmail-growth-hacking-example-ps-i-love-you/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Embedded' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "This is where functionality of the product is 'embedded' in another platform by the user. For example news articles often make use of Twitter's embedded tweets feature, MixMax embeds a calendar in emails the user sends to schedule meetings, and Airtable allows embedding of their spreadsheets in webpages. This is different from simply displaying branding, because some functional, interactive part of the actual product is being used externally.https://productled.com/product-virality/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '3. User-Generated Content' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "This is one of the most powerful forms of virality \u2014 when your users create content which by nature advertises your service on other platforms. Good examples include Yelp, where user's reviews help it rank on Google, Youtube, where the best videos get shared widely across social media and Google Docs, which users create then share via email.https://www.searchenginewatch.com/2016/09/19/yelp-vs-google-vs-facebook-reviews-which-should-you-focus-on-and-why/Because only a small percentage of users on the internet create, this is a very difficult flywheel to get started. Creators don't want to waste their time on a platform that can't bring them attention, whilst you can't bring in users without content. Once turning, this growth loop can lead to exponential growth."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '4. Word of Mouth' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "This is the original marketing channel \u2014 and still the most trustworthy. Before we had mass media or even writing, every new product was communicated via word of mouth.Branding was invented to supercharge word of mouth. If you can encode the identity of your product in a distinctive symbol, it'll be easier to spread with less work \u2014 and they'll remember it better too.This is the dream form of virality for marketers, as it's a sign your product is so good people can't wait to tell their friends about it. Every product has some element of word of mouth, though it can be difficult to track and attribute this behavior."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Social Sharing' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "The most measurable form of word of mouth is online social sharing. When users mention your brand on Facebook, Twitter, LinkedIn, they're doing your marketing for you. What gets people to share on social media? Jonah Berger, author of the book Contagious, lists 6 options:Social Currency \u2013 \u201cWe share things that make us look good\"Triggers \u2013 \u201cTop of mind, tip of tongue\u201dEmotion \u2013 \u201cWhen we care, we share\u201dPublic \u2013 \u201cMaking things more observable, makes them easier to imitate\u201dPractical Value \u2013 \u201cNews you can use\u201dStories \u2013 \u201cInformation travels under the guise of idle chatter\u201dOne valuable tactic for prompting social media sharing is the use of Easter Eggs \u2014 including something unexpected and unadvertised in your product. For example the cookie your hotel gives you on checkin, Google's doodles based on current events, or when you search for flights to Las Vegas on Hipmunk and the text changes to \"Vegas baby!\".https://twitter.com/GoodMarketingHQ/status/1268565226196217857?s=20"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Dark Social' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "The truth is that sharing on public social networks is just the tip of the iceberg. Private sharing on via Whatsapp, Email or Slack account for as much as 69% of traffic according to Alex Madrigal of the Atlantic. We can't easily track this (until now) because these platforms don't pass a marketing source or referrer \u2014 they show up as 'direct' traffic in analytics platforms.https://stackoverflow.com/questions/19778620/provide-an-image-for-whatsapp-link-sharing"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Offline Sharing' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "Like any good advertisement, you want their pitch to be accessible, memorable and emotional \u2014 except unlike an ad, you can't control the script. This is developing a strong brand can help. If they could only say one or two things about you, what would they say? Who would they say it to? If you interview two employees at random and they answer differently, you have a problem. Make sure your visual assets are consistent too \u00a0\u2014 a distinctive color like Monzo's bank cards can grab attention.https://twitter.com/ShingoTamai/status/1057929376728317952/photo/1"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '5. Incentivized' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "Knowing how valuable viral growth can be, many companies attempt to incentivize it. In fact, that's what the entire affiliate marketing and influencer industries are built on! Other popular avenues include discounts for sharing, giveaways and competitions, as well as trading status or access to content or premium features. Primarily these incentives consist of one of 3 categories.Money \u2014 $10 for every friend you sign up, PayPalContent \u2014 Free in-game holiday items, FarmvilleFeatures \u2014 Invite 7 friends for unlimited tracking, MixMaxYou must be careful with incentives, as they can lead to fraudulent behavior or bring in low quality leads. Additionally, don't expect to just add a sharing incentive to make your product go viral. If users aren't already sharing, this isn't likely to get them to start, only motivate them more if they already like your product.https://zyngablog.typepad.com/farmville_2/2019/01/the-winter-workbooth.html"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '6. Public Relations' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "Often when a product seems to have 'gone viral' it's often just being promoted by people or organizations that have large audiences. The art of working with and coordinating with these people (without letting the story get away from you!) is a skill all to itself.PR and influencers rarely exhibit true virality \u2014 where 1 user spreads to 2, who spread to 4, who spread to 8. Instead it usually looks more like a spike, followed by very steep decline, as everyone moves on to the next story."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Media' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "Publishing companies, television shows and newspapers have daily audiences in the millions \u2014 and once a story is picked up in one place, it tends to get syndicated out to other places who don't want to miss out. Hire an expensive PR firm, and you can very easily end up with features in top publications. Or try your hand at PR hacking \u2014 manufacture a story tangential to your business on a slow news day, and you can help time-poor journalists fill their pages.https://www.nytimes.com/2012/07/19/pageoneplus/corrections-july-19.html?_r=3"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Influencers' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "These days many influencers have larger followings than these publications, and can often be more directly incentivized to share (though this can be expensive and hard to track). Mega influencers such as celebrities can generate millions of sales overnight, and companies often contract with them for use of their endorsement for marketing materials in other channels.https://vouchglobal.com/fyre-festival-when-influencer-marketing-goes-wrong/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '7. Freemium' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "If your product isn't inherently viral... release a free product that is! The freemium option has worked for multiple companies in industries as diverse as file-sharing (Dropbox), casual gaming (Clash of Clans) and web analytics (Hotjar).Most inbound or content marketing initiatives could be categorized as freemium \u2014 you're giving away valuable information for free on your blog, because blogs are more easily shareable than your paid product or service. There is also engineering as marketing, such as creating calculators, widgets or other free tools that people share.https://abtestguide.com/calc/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'What's best for my business?' for the blog post 'Flavors of Virality'"}, {"role": "assistant", "content": "Many businesses try at least one flavor of virality, and the majority of successful businesses see a significant number of customers coming at least via word of mouth.Some types of industry or product are better suited to different types of virality. If you're creating a social network and you don't grow virally through invites, then you probably have a problem. Whereas boring corporate B2B software categories might need to lean on freemium products to generate buzz.You may never get to the famed K-Factor of >1 (where each new person brings at least 1 more with them, leading to exponential growth), but any increase at all in virality goes straight to the bottom line. 10% more referral traffic means every channel now works 10% better for you.Even small percentages compound, because virality brings more people, who themselves will share, and so on. So experiment with different options, though be quick to abandon them if you don't see traction \u2014 you can always come back and test it again later when you're better known.\u200d"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How can you build a geo-level marketing mix model?' for the blog post 'Geo Level Models'"}, {"role": "assistant", "content": "*** Note: this is featured in a simulator-based course on Vexpower.com: \"Do I have enough data?\" ***\u200dOne common problem with marketing mix modeling is lack of data. How do you know if you have enough?The rule of thumb is that you need 7-10 observations per variable you include in your model. That means even with 3 years worth of weekly data, you can only support a maximum of 22 variables.\u00a0That\u2019s barely enough to account for the average marketing mix, without even factoring in transformations like Diminishing Returns and Adstocks. If you\u2019re a startup with less than 3 years of relevant data, this can limit your ability to even build an accurate model in the first place.The best way I\u2019ve found to overcome this limitation is to split your data into geographical regions. For example if you\u2019re advertising in the US, suddenly you can have 50 times more data points, one for each state.\u00a0Splitting by geography also helps you improve the accuracy of the model, by giving you more variance \u2013 regression algorithms rely on their being differences in the data, otherwise it can\u2019t easily tease out the underlying patterns.\u00a0For example most marketing channels are correlated (spend tends to increase and decrease at the same time). However if there happened to be differences at the regional level, the model would now be able to tell these effects apart.\u00a0You can even proactively engineer these differences! You can set up a deprivation test by turning off spend in randomly selected regions. There\u2019s also scale testing, which is similar, except you increase spend in different regions to understand where efficiency starts to suffer.Now let\u2019s look at how you would build a geo model, once you have the data. So you can follow along, I\u2019ve included a template with some example data for you to use.Pie Sales by GeoFirst, let\u2019s look at a standard marketing mix model, at the national level. We are using three variables to predict sales: the price of the pies, how much we spent on advertising and whether it was a holiday that week. The accuracy we get as measured by both the R-Squared (R2) and the Normalized Root Mean Square Error (NRMSE), is pretty great.If you have no idea what you\u2019re looking at here, it might make sense to check out the post Econometrics in GSheets, which goes into a bit more detail on the technique. Essentially the model is saying that these three variables predict 94% of the changes in sales (R2), and that on the average day we\u2019re off by 8.8% (NRMSE).\u00a0The coefficients are what explains the impact of each variable on sales, so for example Advertising is driving sales at $17 for every $1 spent, and every time we increase the price by $1, we lose $19,000 in revenue (sales is in $1,000s). However this variable is showing as statistically insignificant (above 0.05), so we wouldn\u2019t be able to rely on these results.One other thing to call out is the margin of error \u2013 these are pretty wide ranges, which should make us uncomfortable. For example, the model is only confident that the impact of advertising is something between -$42 and $77 return on ad spend (ROAS)\u2026 that means we can\u2019t really be that confident in our advertising ROI, which is one of the main reasons we built this model!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'What does geo-level data look like?' for the blog post 'Geo Level Models'"}, {"role": "assistant", "content": "To bring this model down to the geo level, we need to change the way we do our prediction. Previously we were predicting national sales on any given week. Now we need to predict regional sales, for each region, for each week. So for example we\u2019ll go from data that looks like this:To data that is broken down by region, like this:What if you don't have geo-level data available for some channels? Well the simplest way is a type of interpolation (the same technique you use for converting weekly or monthly into daily data). You find out the population of each geo region, the share of the national population they have, then multiply that percentage by the national figures. Of course this is open to bias, so wherever possible you want to try and obtain the actual geographical numbers.In our geo-level model we\u2019re now going to be predicting regional sales, so our coefficients and how we interpret them will change. This is what the new geo model looks like:It\u2019s now saying that Holiday is worth $66k in revenue, whereas previously it was $266k. Well we have 4 regions, so on any given holiday we\u2019d get an additional $66k from each region, which would total\u00a0 $264k in revenue \u2013 not far off what the national model estimated.Note that the R2 actually dropped! If that was your only measure of accuracy, you\u2019d be led to conclude that this model was worse. In fact, even the NRMSE, a standard measure of error, has doubled (which is bad). So far the extra effort of pulling geo-level data doesn\u2019t look like it\u2019s paying off\u2026However the magic of the geo model becomes apparent when you look at the margins of error. It\u2019s now showing advertising as statistically significant, and has zeroed in on the range of $10 to $25 return on ad spend. We still have a similar result for the coefficient of advertising, of $17.88 vs $17.23, but this model is far more confident about the impact of our ad campaigns."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'What was the true accuracy of the geo-level data?' for the blog post 'Geo Level Models'"}, {"role": "assistant", "content": "To illustrate this model I actually generated this data, so we can tell how close these two models got to the truth. I left the data generator in the exercise file so you can take a look at how it works. Note that every time the spreadsheet recalculates it shows different numbers, because it contains several random number functions to generate the data.So what was the truth? How close did we get to the underlying patterns in the data? In this case both the national and geo models were both pretty close! The geo model was much more accurate on Price, getting a coefficient of $4.91 vs $19.03 predicted in the national model. However the rest of the variables are pretty close to the Ground Truth, if you account for the effect of rolling up 4 regions by dividing the national coefficient by 4 (Holiday and Intercept).What you should take away from this analysis is the major improvement in margin of error you can get from going more granular with the data, with a geo level model. The range tightened up considerably and we even proved advertising was a statistically significant variable. Of course in real life you don\u2019t know the ground truth, and can never find out, so it\u2019s margin of error and statistical significance you should pay attention to. There\u2019s also a cautionary tale here: you can\u2019t look only at R2, NRMSE or other measures of accuracy, because it\u2019s not the whole story. Better accuracy is usually a good sign, but a model is only useful if it can explain the underlying behavior driving the numbers \u2013 only then should you be comfortable making decisions."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How to use GPT-3 in GSheets' for the blog post 'GPT3() Function in GSheets'"}, {"role": "assistant", "content": "WARNING: This post is now outdated, as GPT-3 is being deprecated. For the latest ChatGPT model template visit my other post \"ChatGPT in GSheets\".New AI tools like GPT-3 promise to have a huge impact on marketing, and the pace of innovation is accelerating. Tools like Copy.ai and Jasper.ai are democratizing access to AI, but I\u2019ve found it hard to incorporate these powerful tools into my own workflow as a marketer, and as a result I\u2019m not leveraging the benefits of AI as much as I should. To make GPT-3 more accessible, it needs to be available where I live, and that\u2019s in Google Sheets. So inspired by @fabianstelzer I decided to build my own GPT3() function, which you\u2019ll find in this template:> GPT3() Function TemplateWhen you visit the template it\u2019ll ask you to make a copy including the Google Apps Script, and if you click ok you\u2019ll have your own version of the Spreadsheet to follow along. This function is a work in progress that I plan to keep updating, but also feel free to modify it for your own use. I\u2019ve used this function in two courses on Vexpower so far, so it might be worth checking those out if you\u2019re trying to learn:Make Me 205 AdsWhat Do Our Customers Think?If you want help learning how to prompt GPT-3 and work together with it, I've just partnered up with James Phoenix (who I\u00a0work with on Vexpower) to build a Prompt Engineering course on Udemy, with over 4 hours of content.In order to use GPT-3 you need an OpenAI account, which you can set up on their website. As it stands, using the most advanced da-vinci model costs 2 cents per 1k tokens, which is ~750 words in English. Note that the tokens count both the text going into the prompt you send GPT-3, as well as the response you get back. Also whenever you recalculate the spreadsheet, all the prompts will re-run, which can cost you money. When you sign up for a new account you get $18 in free credits, which should be enough to last you for a while, and in my experience the costs are trivial even for heavy usage, but just be careful and monitor your spend.\u00a0Once you have an account you can visit the API keys page to get a secret key related to your account, which you\u2019ll need to copy and paste into the cell B1, which says \u201cAPI KEY HERE\u201d in red text. This is the equivalent of a password, so keep it safe, and don\u2019t share it with anyone, or accidentally leave it in a public facing document. My recommendation is to have a spreadsheet where you do your ideation in GPT-3, then copy and paste the results into a new sheet to share.Once you have the API key set, running GPT is the same as running any other function in GSheets: you simply use GPT3() with the only required parameter being the prompt you pass GPT-3. For example when I passed \u201cOnce upon a time\u2026\u201d I got back \u201c a beautiful princess was born.\u201d which is how GPT-3 decided to complete the text.\u00a0The craft of working with AI is called \u201cprompt engineering\u201d, which is a fast moving field with lots of innovation through trial and error. You\u2019ll find GPT-3 does a decent enough job of anything you ask it to do, but sometimes goes off on a tangent or comes back with something weird. I\u2019d still recommend you have a human check the results of any prompt, and edit or rerun any bad responses before you use the output in the real world.\u00a0The other two parameters I\u2019ve implemented in the function are \u201cmax_tokens\u201d, which controls how long the response will be, and \u201ctemperature\u201d, which controls the randomness of the response. If you\u2019re finding GPT-3 is rambling on for too long, shorten the max_tokens (default: 100), and if the results need to be more predictable and less creative, dial down the temperature (default: 0.7). If you turn on the Show Probabilities setting in the GPT-3 Playground in your OpenAI account, you can see what it\u2019s doing: by dialing the temperature up, it\u2019s more likely to pick a lower probability keyword as the next one in the sentence, and by dialing it down it makes more predictable choices."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How does the GPT3 function code work?' for the blog post 'GPT3() Function in GSheets'"}, {"role": "assistant", "content": "If you want to see how the code works for this function, so that you can modify it or build your own custom function, click on Extensions > Apps Script in the navigation bar. That\u2019ll take you to the attached Google Apps Script, which handles talking to OpenAI\u2019s GPT-3 API when the function is used. It reads the API key from the cell B1 in the current sheet, then inserts that into the authorization headers so OpenAI know it\u2019s you.\u00a0The code then makes the API call to OpenAI, with the prompt, max_tokens, and temperature from the function parameters.If you\u2019re creating your own function, or updating this one, you should know that the comment in green directly above the function at the end is what populates the function help text when a user clicks into the function bar. Stick to this format and it should work for you too. Finally I\u2019ve found the best way to handle defaults is to put them directly in the function parameters, so that the underlying function is always getting a value for each parameter no matter what the user inputs."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'My Growth Engineer Career' for the blog post 'Becoming a Growth Engineer'"}, {"role": "assistant", "content": "This post is the fourth in a series on Growth Engineering:Intro to Growth EngineeringGrowth Engineering ServicesGrowth Engineering Case StudiesBecoming a Growth Engineer (this post)---You may be wondering how to get started as a growth engineer \u2014 maybe you're a marketer learning to code or a developer interested in marketing. I run a community of Growth Engineers and I can\u2019t say anyone has taken the same path, but if I tell you my story, that might help.I was completely enthralled by the Growth Hacking trend, and the promise of applying my economics background and budding interest in coding, to my accidental profession of marketing (I graduated in 2009). I hoped to correct the injustices of \u2018gut\u2019 decisions by technologically and analytically clueless senior managers, and work more with the smarter, untouchable class of developers I admired.For me Excel was a gateway drug \u2014 if you can understand a spreadsheet and formulas you\u2019re actually a lot of the way there towards understanding how and what to code. In my first startup job I was working on large-scale Google ads, where I had to implement hundreds of campaigns and it just wasn\u2019t possible manually. Scale is the key I think \u2014 whenever you\u2019re in a role where it\u2019s impossible (not just improbable) to get your work done without templates, formulas and macros, you\u2019re on the right path.In my next job I learned Google Analytics by telling people I knew Google Analytics then Googling whatever they asked me. I learned basic JavaScript to implement tracking tags for campaigns, rather than waiting 3 months for the IT department. I then put my career on the line by forcing through a $60,000 annual purchase of Optimizely, the A/B testing tool, where after 5 failures, I managed to add $800k in revenue to the bottom line on my 6th experiment.That caught the attention of the CEO, who put me in charge of 4 developers as the \u201cAssociate Product Manager for Marketing\u201d, and started flying me out monthly to Silicon Valley. I worked harder during this period, than almost any other time in my life (the exception was the 1st year of founding Ladder), to the point where I had a bit of a mental breakdown and got myself fired.Fast forward to today, and I\u2019ve been fired another 2 times since, founded a company, gotten married, bought a house and had a baby, but I\u2019ve never lost my passion for what I\u2019d now call \u2018Growth Engineering\u2019. At Ladder, we grew to 50 people surfing the growth hacking wave, and I built the Data Science, Automation and Product teams.\u00a0At Ladder we built an exceptional team of scientific marketers, running over 7,000 experiments across 200+ clients and tens of millions in marketing budget. We delivered growth engineering projects for companies like Booking.com, Monzo Bank and Time Out Magazine, as well as small early stage startups who needed to hack growth with limited resources. I transitioned out of Ladder in February and now work on Growth Engineering as the founder of Saxifrage."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Timeline to Becoming a Growth Engineer' for the blog post 'Becoming a Growth Engineer'"}, {"role": "assistant", "content": "It\u2019s only now, a decade into my career and 7 years since I wrote my first code that I\u2019m billing myself as a professional Growth Engineer. I studied tutorials in evenings and weekends and rarely had an excuse to code in my job until this year. What that did teach me is systems thinking \u2014 learning to code is learning how to solve problems, and has far reaching benefits even if you never build a single production application.\u00a0All in I\u2019d say I averaged about 1,250 hours (4 hours a week for 6 years, or about 8 months full time) before I felt confident enough to charge money for coding. Sometimes this was 20 hours on a weekend, and other weeks I did nothing. Recently I progressed far more rapidly, when 8 \u00bd months ago I started to code 20 hours a week (another 680 hours, or 4 \u00bc months full time). If you add it up I have just over a year\u2019s experience, making me a pretty amateur coder, which is kind of depressing after 7 years of effort.\u00a0The good news however, is that as I secure more freelance contracts my hours of code will approach 40 per week, and maybe beyond (family permitting), and I have 10 years experience in marketing (60 hours a week, so likely over 30,000 hours), so I know exactly what to build! If you\u2019re looking for advice in this domain, my major recommendation is to take on a side project \u2014 I vacillated for years doing endless tutorials and getting nowhere, but nothing pulls you in like releasing a product in the wild and being committed to the customers it attracts."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How to Learn to Code as a Marketer' for the blog post 'Becoming a Growth Engineer'"}, {"role": "assistant", "content": "The first two tutorials I took that got me interested in coding were One Month Rails by Mattan Griffel, and Michael Hartle\u2019s Rails Tutorial. I then switched to Codecademy to learn JavaScript (more useful for tracking and a/b test implementation), and later found FreeCodeCamp to be a fantastic resource I wish I had when I started.\u00a0Finally I switched to Python to learn Data Science and felt at home \u2014 this is now my language of choice. Elite Data Science gave me the process, Dataquest gave me practice and MIT\u2019s Introduction to Computer Science and Introduction to Computational Thinking gave me a challenge. This wasn\u2019t around when I was learning, but Ryan Kulp\u2019s course Founder/Hacker looks great in terms of learning the right mindset, which is more important than syntax."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How to Learn Marketing as a Developer' for the blog post 'Becoming a Growth Engineer'"}, {"role": "assistant", "content": "If you\u2019re a developer, congrats, you have one of the most valuable skill sets in history! Just reverse the advice \u2014 pick up a side project which will force you to do some marketing ~4 hours a week, even if it\u2019s helping out a friend\u2019s business. You\u2019ll find you think more creatively about how to solve problems, and knowing how to code gives you an edge over the non-technical people you\u2019re competing against.\u00a0As a developer you might find marketing a little fuzzier than what you\u2019re used to, but that\u2019s an opportunity \u2014 find any way to decrease uncertainty and you have an edge. Don\u2019t get imposter syndrome from more experienced marketers, because unlike in computer science, very rarely is there a good reason to be that certain about something.If you\u2019re looking to learn more about marketing, then I recommend reading blog post rather than doing tutorials \u2014 despite the valiant efforts of people like Byron Sharp and Binet & Field, marketing is still largely unscientific and hard to measure. For people new to growth here are the foundational posts: after reading these you\u2019ll get a lot of mileage out of just Googling a topic, reading everything that ranks, then reading everything they link to.Growth Reading ListQuant-Based Marketing \u2014 Noah KaganScientific Marketing \u2014 Bryan BalfourFunnel Metrics \u2014 Dave McClureShitty Clickthroughs \u2014 Andrew ChenT-Shaped Marketer \u2014 BufferLessons Learned \u2013 Viral Marketing \u2014 David SkokProduct Market Fit \u2014 Melinda ByerlyOnboarding \u2014 Sam HulickA/B Testing \u2014 Dan SirokerCognitive Biases \u2014 Conversion XLMarketing Worth Sharing \u2014 Tom FishburneStart With Why \u2014 Simon SinekLife Lessons from an Ad Man \u2014 Rory SutherlandBrand Positioning \u2014 Arielle JacksonSocial Virality \u2014 UpworthySEO Case Study \u2014 Growth MachineWeb Analytics \u2014 Avinash KaushikMobile Growth \u2014 Andy CarvelAdvertising Creativity \u2014 Eat 24Link Building \u2014 Backlinko---If you enjoyed this post, check out the rest of the series:Intro to Growth EngineeringGrowth Engineering ServicesGrowth Engineering Case StudiesBecoming a Growth Engineer (this post)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Growth Hacking' for the blog post 'Intro to Growth Engineering'"}, {"role": "assistant", "content": "This post is the first in a series on Growth Engineering:Intro to Growth Engineering (this post)Growth Engineering ServicesGrowth Engineering Case StudiesBecoming a Growth Engineer---In my previous company, a growth marketing agency, we were hiring our first engineer to work on client projects. I thought it\u2019d sound cool to call the role \u2018growth engineer\u2019 (we already had \u2018growth strategists\u2019 and \u2018growth analysts\u2019) \u2014 little did I know this was a legitimate job title with a meetup group totalling 2,600+ members in San Francisco alone.Since Growth Hacking was only coined in 2010 by Sean Ellis, you can be forgiven for not being familiar with Growth Engineering as a discipline. The term encapsulated a trend where engineers at companies like AirBnB, Dropbox and Facebook were being tasked with responsibilities traditionally reserved for the marketing team \u2014 acquiring and retaining users.\u00a0For technical marketers, it was a way of differentiating from traditional marketers \u2014 promising digital ads, conversion optimization and viral loops, rather than TV ads, billboards and brand campaigns. Marketing is a commonly disliked profession, with a bad reputation for convincing people to buy things they don\u2019t need. Business leaders also often look down on marketers, with the CMO having the shortest tenure in the C-Suite, especially startup founders who see marketing as a tax you pay for having a bad product.But the methods of a \u2018Growth Hacker\u2019 were completely different from what you\u2019d get from the typical marketer at the time \u2014 data-driven, digitally-native and tech-fluent; a person, \u201cwhose true north is growth. Everything they do is scrutinized by its potential impact on scalable growth.\u201d The growth team was not a tax, but part of the product: shipping features to generate lasting, sometimes exponential impacts on performance. The whole mindset was different \u2014 these were not guys in suits, but hoodies, with a dislike of authority and respect for science.AirBnB didn\u2019t run superbowl ads, they reverse engineered the Craigslist API to allow cross-posting of listings. Dropbox didn\u2019t hire celebrity sponsors, they built a referral mechanism into the product to incentivise sharing. Facebook didn\u2019t rent billboards, they built an internationalization engine making the site available globally.\u00a0Popular amongst early-stage startups who need massive growth in a short time on small budgets, Andrew Chen pronounced \"Growth Hacker is the new VP Marketing\". It wasn\u2019t long until bigger corporates became curious, as these tech startups became the new Fortune 500. With luminaries like Bryan Balfour, Dave McClure and Noah Kagan providing the operating system for this new discipline, the trend took off amongst ambitious marketers."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Growth Engineering' for the blog post 'Intro to Growth Engineering'"}, {"role": "assistant", "content": "What is Growth Engineering and when is it relevant to a business trying to grow? It\u2019s a broad topic \u2014 essentially any developer tasked with marketing (or marketer writing code) is doing some form of Growth Engineering, even if they might not call it that.\u00a0Although companies vary in terms of preference for automation, and understanding of engineering concepts applied to marketing, there is a specific inflection point where almost all marketing organizations start investing in technology. This comes when you start to hit \u2018diminishing marginal returns\u2019. Meaning you have exhausted the \u2018quick wins\u2019 in a channel, and are starting to see efficiency decline as you increase spend.Decreasing efficiency at scale is inevitable across almost all marketing channels, because by definition you\u2019re targeting the \u2018low hanging fruit\u2019 first. As these easy gains get used up, and you\u2019re reaching all the people most likely to need your product, you have to expand to tactics that bring in less relevant people, and that\u2019s where efficiency decreases.To counteract an exponential decline in performance, you need an exponential increase \u2014 that\u2019s where investing in technology can help. No matter how good your team, they will only ever be able to bring in linear or sub-linear performance gains. With investment in technology you\u2019re rolling the dice on potentially finding an exponential increase, maybe even opening up opportunities that wouldn\u2019t be possible with manual work alone.It\u2019s because of this potential, that the number of software tools available to marketers has exploded in the past 6 years, going from just shy of 1,000 vendors to over 8,000 distinct marketing technology brands in 2020. Even knowing what\u2019s possible with a subset of these tools is a complex task, and despite all this innovation, most off-the-shelf tools don\u2019t suit your business\u2019s unique needs \u2014 especially if you\u2019re a fast-growing startup innovating in your space.Therefore the World\u2019s fastest growing companies have identified the potential of Growth Engineering, and are increasingly embedding developers in the marketing team to configure existing solutions in a unique way, or to invent their own proprietary tools for a sustained competitive advantage. More traditional companies struggle to get headcount approved for developer roles in marketing, as usually engineers are reserved for product initiatives.Even marketing teams with developer head count to fill, struggle to find good quality developers who are experienced with and motivated to work on marketing problems. So many ambitious marketers are learning how to code in evenings and weekends to help solve their own problems. Growth Engineering is the discipline arising from the combination of these forces \u2014 whether a developer in the marketing department, or a marketer who learned to code, the combination of these two functions is what makes a Growth Engineer.---If you enjoyed this post, check out the rest of the series:Intro to Growth Engineering (this post)Growth Engineering ServicesGrowth Engineering Case StudiesBecoming a Growth Engineer\u200d"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Cohort Analysis for Mobile Banking App' for the blog post 'Growth Engineering Case Studies'"}, {"role": "assistant", "content": "This post is the third in a series on Growth Engineering:Intro to Growth EngineeringGrowth Engineering ServicesGrowth Engineering Case Studies (this post)Becoming a Growth Engineer---It's hard sometimes to visualize what Growth Engineering can do for your marketing team. Even if you understand the various Growth Engineering Services, it can still be hard to know what type of results you'd expect from a Growth Engineering project, or how to think about the strategy of approaching one.To clear this up I've put together a master list of the various Growth Engineering projects I've been part of that were deemed successful. In each case study I've included the problem we were trying to solve, what strategy we used to solve it, the services this would relate to and most importantly, the results we achieved. This is anonymized to protect client information, but you should get a good idea of what worked and for what types of company.Problem: It took several weeks for all new users to finish bank account setup, but we needed quicker feedback to optimize \u00a310,000+ spend per day.Strategy: Log performance by campaign over 28-day intervals for cohort analysis, letting us estimate the share of future conversions to predict CPA.Services: API connectors, Cohort analysis, Custom reporting\u00a0Stack: Facebook Ads API, Google Cloud Function, GSheets, Google Data StudioResults: We determined ~30% of conversions happened on day 1, so optimizing daily budgets we could estimate future CPA by dividing by 3.33."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'ML Creative Tagging for a Fortune 500 Travel Company' for the blog post 'Growth Engineering Case Studies'"}, {"role": "assistant", "content": "Problem: Difficulty in understanding what was working at scale, while testing 100s of ad creatives and spending \u20ac100k+ on LinkedIn ads per month.Strategy: Creative analysis using machine learning image classification, to be able to show performance segmented by what was in the images.Services: Image Classification, Custom reportingStack: Google Colab, Google Vision, NLTK, Pandas, GSheets, Google Data StudioResults: Images with \u2018furniture\u2019 tags had a 66% lower CPL than \u2018suitcase\u2019 tags, meaning travel managers in offices outperformed business travelers in airports."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Automated Campaigns for a Global Events & Attractions Publisher' for the blog post 'Growth Engineering Case Studies'"}, {"role": "assistant", "content": "Problem: Writers were responsible for building 100s of Facebook ad campaigns themselves as deals came in, often publishing late with no time to optimize.\u00a0Strategy: Connect to the product feed and automatically build campaigns based on pre-defined templates, turning on and off based on inventory.Services: API connectors, Campaign Builders, Ad OptimizationStack: Facebook Ads API, Google Cloud FunctionResults: 1000s of deals published on Facebook ads per month with no further involvement needed from the publishing team."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Web Scraping for a Seed-Stage Risk Modelling Startup' for the blog post 'Growth Engineering Case Studies'"}, {"role": "assistant", "content": "Problem: Needed to reach PPC agencies that are active content marketers, with a cold email outreach campaign.\u00a0Strategy: Build a web scraper to download a list of 50,000 digital agencies globally with average customer size and focus areas.Services: Web scraping, Data cleaningStack: Google Colab, Beautiful SoupResults: Extracted a list of 3,000 agencies that fit the profile for targeted outreach."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Test Results Meta-Analysis with a Mid-Size Marketing Agency' for the blog post 'Growth Engineering Case Studies'"}, {"role": "assistant", "content": "Problem: The agency had run over 4,500 experiments on behalf of clients, but learnings were siloed and weren\u2019t widely distributed across the team.Strategy: Conduct a meta analysis of experiment documentation to determine what we could learn about odds of success by type of test.Services: Data Cleaning, Exploratory Data Analysis, Natural Language ProcessingStack: Airtable API, N-Gram, Pandas, Jupyter NotebookResults: Identified ~300 unique tactics and ~1,200 properly concluded tests, with a 44% success rate. Organic tactics (+7%), tests needing a developer (+20%) and seed stage / bootstrapped startups (+60%) had higher success rates."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Annual Budgeting for a Billion-Dollar Public AdTech Company' for the blog post 'Growth Engineering Case Studies'"}, {"role": "assistant", "content": "Problem: Needed to build a compelling business case to support a new SMB-focused go to market strategy, and secure a sizeable budget allocation.Strategy: Research performance benchmarks across channels, using Fermi decompositions and Monte-carlo simulations to calculate various scenarios.Services: Monte-carlo simulationsStack: ExcelResults: Modelled $1.2m in annual SMB marketing budget, broken down by channel, activity and vendor, with \u2018what-if\u2019 simulations for potential outcomes."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'E-Commerce Tracking for a Fortune 1000 Fast Food Chain' for the blog post 'Growth Engineering Case Studies'"}, {"role": "assistant", "content": "Problem: No e-commerce analytics tracking set up the night before a major product launch, no in-house expertise available at late notice.Strategy: Implement Google Analytics Enhanced E-Commerce tracking via Google Tag Manager in time for launch.Services: Tag ManagementStack: Google Tag Manager, Google AnalyticsResults: Full tracking implementation done on development server, pushed to production just before midnight."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Dynamic Landing Pages for a Startup Trade Services Marketplace' for the blog post 'Growth Engineering Case Studies'"}, {"role": "assistant", "content": "Problem: Needed to improve conversion rate of traffic sent to landing pages and communicate different value propositions per trade service.Strategy: Build a dynamic landing page script that modified the header and hero text based on the source of the traffic.Services: Conversion optimizationStack: Google OptimizeResults: Decrease of 62% in Cost per Lead due to increased conversion rate."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'GDPR-Compliant Tracking Plan for a New European Mobile Bank' for the blog post 'Growth Engineering Case Studies'"}, {"role": "assistant", "content": "Problem: Launching a new banking app in Europe with incoming GDPR regulation, needed to create a tracking plan including in-depth technical privacy audit.Strategy: Write tracking plan for full Segment tag management setup, providing code snippets and extensive documentation on use cases and technical aspects.Services: Tag ManagementStack: Segment, Mixpanel, AppsFlyer, Adobe Marketing CloudResults: Joined up Appsflyer marketing attribution to Segment tag management. Limited or obfuscated personal identifiable information in Mixpanel, and pushed sensitive data to Adobe Marketing Cloud which had better privacy controls."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Custom Attribution Model for a Fashion Affiliate Startup (Acquired)' for the blog post 'Growth Engineering Case Studies'"}, {"role": "assistant", "content": "Problem: Last click attribution was showing limited ROI from Facebook ads, but when turned off, organic revenue would also decline.Strategy: Build our own multi-touch attribution system using browser cookies to store marketing sources, then injecting into hidden form fields.Services: Tag Management, Exploratory Data Analysis, Attribution ModellingStack: Google Tag Manager, Mailchimp FormsResults: Discovered 40% of conversions had at least one visit from Facebook ads, revolutionizing the companies strategy on the path to acquisition."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Word of Mouth Measurement for a Popular Music E-Commerce Site' for the blog post 'Growth Engineering Case Studies'"}, {"role": "assistant", "content": "Problem: Word of mouth was a significant driver of the service, particularly during the onset of Coronavirus, but there was no way to measure or forecast it.Strategy: Explore historical data from Google Analytics to determine what correlates with direct (word of mouth) traffic, and can be used to predict or identify anomalies in this metric to better plan for goals and optimize performance.Services: Exploratory data analysisStack: GSheets, Google AnalyticsResults: Found a significant correlation (R2=0.97) between returning users and direct traffic, to be used in modeling. Our work on this methodology was published in Reforge."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Hiring Freeze Database for HR Startup' for the blog post 'Growth Engineering Case Studies'"}, {"role": "assistant", "content": "Problem: There was limited daily traffic and a low domain authority for SEO (8/100), so the quality content they were publishing wasn\u2019t getting much reach.Strategy: Build a realtime user-generated database of companies freezing hiring due to Coronavirus. Seed the initial traffic by sharing within groups on social media.Services: Engineering as marketing, Technical SEO, Exploratory data analysisStack: Airtable, Intercom, D3.jsResults: Drove over 1.5 million pageviews and 8,000+ user submissions, as well as a significant increase in brand-related searches. In addition, over 2,200 backlinks were generated which increased domain rank to 60/100 enabling ranking on many key terms."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Viral Link Sharing for Content Blog' for the blog post 'Growth Engineering Case Studies'"}, {"role": "assistant", "content": "Problem: Over 50% of traffic was direct, meaning we didn\u2019t know the marketing source. We knew through interviews that people were sharing the URLs of blog posts, but had no way to track this activity when it was done via \u2018dark social\u2019 channels.Strategy: Add a unique ID to the end of every URL for every user, and track when a new user arrives with an existing user\u2019s tracking link, to properly attribute it to link sharing.Services: Tag Management, ETL Pipelines, Data Warehousing, Attribution modelling, Custom Reporting, Exploratory data analysisStack: Google Tag Manager, Google Cloud Functions, Google Firestore, Google BigQuery, Google Data Studio\u200dResults: Identified that more than 20% of traffic to the blog was due to people sharing URLs via \u2018dark social\u2019 channels, and that some posts had 3-4x the virality of others.---If you enjoyed this post, check out the rest of the series:Intro to Growth EngineeringGrowth Engineering ServicesGrowth Engineering Case Studies (this post)Becoming a Growth Engineer"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Data Engineering:' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "This post is the second in a series on Growth Engineering:Intro to Growth EngineeringGrowth Engineering Services (this post)Growth Engineering Case StudiesBecoming a Growth Engineer---You may have heard the term Growth Engineering, but what do Growth Engineers actually do? This post provides examples of the types of services a Growth Engineer can perform for your business. Though the work Growth Engineers do is fairly non-standardized, there are a set of core tasks and solutions to those problems that come up again and again.This post is a menu of services that you can expect when working with a Growth Engineer \u2014 though of course not every engineer has experience in everything, and many of these problems can be solved to some extent with no-code tools as well. Treat this as a checklist of the various areas where engineering can help your marketing team, and see what's relevant to your specific problems right now.Getting your data in the right place, in the right format.Vendor selectionTag managementAPI connectorsWeb scrapingETL pipelinesData cleaningData warehousing"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Vendor selection' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "With 8,000+ marketing tools to choose from, it can be difficult to know what stack you should be implementing for growth. Based on experience with popular vendors, with some technical ability, it\u2019s possible to save considerable time and money by finding exactly the right tool for the job."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Tag management' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Every tool you use relies on accurate tracking implementation to work \u2014 set your tracking tags up wrong and it\u2019s garbage in, garbage out. Knowing the implementation details of major platforms, ability to translate documentation and experience with writing tracking plans is key."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'API Connectors' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "The majority of popular marketing platforms now offer APIs for marketers to programmatically access their data and make decisions, even automate the execution of campaigns. Best practice with dependencies and ability to understand documentation are both important."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Web scraping' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Many websites don\u2019t offer a public API yet have valuable information available publicly. Web scraping is the ability to pull data from websites programmatically and at a scale impossible for any team of people to replicate manually. If it exists online, there\u2019s some way to scrape it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'ETL pipelines' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Most modern marketing automation requires pulling data from one source and pushing it into another system, consistently and in the right format. Expertise in Extract, Translate and Load tasks helps you ensure that consistency and experience with popular APIs is essential."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Data cleaning' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Wherever you get your marketing data from, it\u2019s unlikely to be in the right format for the analysis or automation task you have planned for it. Data cleaning typically takes up to 50% of the time of a Data Science task, and understanding common methods is important for efficiency."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Data warehousing' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "You have unparalleled access to information as a marketer, particularly if you\u2019ve mastered pulling data from APIs or web scraping. Once you have it, storing that data in a structured database that the right people or programs can access securely becomes important."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Data Science:' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Analyzing your data to find actionable insights.Exploratory data analysisImage classificationNatural language processingRFM analysisCustomer cluster analysisCohort analysisLead scoringChurn risk taggingAttribution modellingMonte-carlo simulation"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Exploratory data analysis' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "You have performance data and are looking for insights to help drive your strategy. The ability to analyze and visualize that data using techniques that scale way past the point where Excel crashes is a foundational skill for any Growth Engineer, and part of almost every project."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Image classification' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Machine learning has advanced significantly in recent years, to the level where it\u2019s able to identify objects within an image with good accuracy. This can be used for a variety of use cases, for example advanced ad creative analysis or competitor monitoring of website changes."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Natural language processing' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "The field of NLP has several tried and tested techniques for modeling text to extract insights. For example pulling out instances of specific keywords or NGrams, calculating the reading level or translating text into a foreign language using machine learning translation algorithms."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'RFM analysis' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "It\u2019s important to segment your customers by purchase behavior to better target your campaigns. The practice of scoring customers based on recency (how long since they bought), frequency (how often do they buy) and monetary value (how much they spent), often proves to be useful."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Customer cluster analysis' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Using techniques like K-Means clustering, you can segment your customers based on behavior into data-driven personas. This is useful for analyzing performance, setting your strategy, and also for building retargeting or CRM campaign audiences.\u00a0"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Cohort analysis' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "The customers you signed up yesterday have had a very different experience to those who signed up a week ago or last year. To hold environmental factors constant and see the true underlying growth trend in your performance data, it\u2019s essential to master cohort analysis."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Lead scoring' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Your marketing campaigns are bringing in leads, but are they all good enough quality? Scoring leads by variables that are predictive of deals that closed, so that you can optimize your marketing campaigns by qualified leads, is essential for any sales-driven organization."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Churn risk tagging' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Every customer you lose needs to be replaced by expensive customer acquisition campaigns. By scoring existing customers by behavior that correlates with churn, you can predict which users are at risk of leaving, and run a CRM campaign to intervene before you lose them."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Attribution modelling' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "It\u2019s important you don\u2019t trust everything your inherently biased analytics vendors and ad platforms are telling you. Building your own attribution model using advanced tag management and econometric techniques is an important way to verify independently what drives sales."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Monte-Carlo simulation' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Before you make major decisions, it\u2019s important that you model out your assumptions and make sure the initiative isn\u2019t doomed to failure before it starts. Monte-carlo is a technique for simulating all potential outcomes of a decision, giving you more confidence and accuracy."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Product Development:' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Building tools to automate repetitive marketing tasks.Custom reportingCompetitor monitoringCampaign buildersAd optimizationAnomaly detectionRecommendation enginesConversion optimizationTechnical SEOEngineering as marketing"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Custom reporting' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Sometimes your analytics tool just doesn\u2019t cut it, and you can\u2019t see the data you need in the format you need to see it. By writing custom scripts to connect APIs and process data in ETL pipelines, it\u2019s possible to build whatever executive dashboard or recurring analysis needed."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Competitor monitoring' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "With use of web scraping and various monitoring and audit tools\u2019 APIs it\u2019s possible to keep tabs on your competitor\u2019s activities like never before. This can help inform your strategy, explain fluctuations in your performance and even be used to make decisions on pricing or optimization."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Campaign builders' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Once marketers get to building hundreds or thousands of campaigns, it becomes impossible for a team of any size or ability to keep up. This is where automated creation of large-scale campaigns from a product feed data can provide a huge competitive advantage."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Ad optimization' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Marketers spend hours every day optimizing their bids and budgets, turning off poor performing campaigns and launching new ad creative. Most of this work can be automated, with smart rules based on data analysis, and timely notifications to keep the marketer in the driving seat."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Anomaly detection' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "Most marketers aren\u2019t able to keep tabs on everything happening across their business and campaigns all the time. Yet getting notified of every fluctuation would be equally distracting. The solution is an anomaly detection system that finds only the most significant changes to alert you."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Recommendation engines' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "It\u2019s one thing to spot a pattern in the data, but quite another to be able to automatically make a decision based on that insight. Recommendation engines can be used to automate decisions on what products to show, what creative to use and what optimization to make."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Conversion optimization' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "This skill set is the bedrock of any growth engineer, and a large part of the work available within product-led companies. Optimizing landing pages, improving the new user experience and driving impact on other key pages is one of the most direct ways to improve performance."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Technical SEO' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "SEO is one of the few channels where, if done well, you can build an evergreen asset that generates new customers over the long term for free. Therefore many growth engineers work on teams that optimize SEO for the core product or freemium products built to drive traffic."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Engineering as marketing' for the blog post 'Growth Engineering Services'"}, {"role": "assistant", "content": "As content marketing becomes saturated and paid ads get more expensive, some companies have found success in offering free widgets or tools as a way to attract potential customers. Done well, these projects can deliver evergreen assets that attract new customers indefinitely.---If you enjoyed this post, check out the rest of the series:Intro to Growth EngineeringGrowth Engineering Services (this post)Growth Engineering Case StudiesBecoming a Growth Engineer\u200d"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Why Doesn\u2019t My Facebook Ads Match Google Analytics?' for the blog post 'Measuring the Halo Effect of Ads'"}, {"role": "assistant", "content": "It can be difficult to understand the impact your Facebook ads (or other paid channels) are having on your overall company growth. Marketing attribution is at the heart of marketing strategy \u2014 you can\u2019t make budget decisions without knowing what\u2019s working.Despite the explosion in tracking and targeting technology, digital ads still aren\u2019t as \u2018measurable\u2019 as you might have been led to believe. No matter what attribution model you use, it can be gamed, and the only channels that have the full customer view from impression to purchase, Facebook and Google, aren\u2019t going to do anything that puts their 70% market share at risk.The default attribution model for Facebook ads is a 1 day impression and 28 day click window. What this means is that they will claim any purchases from people who were shown an ad in the last 24 hours (even if they didn\u2019t click or even notice it) or clicked an ad in the past 4 weeks (even if it wasn\u2019t that click that drove the conversion).\u00a0So theoretically, if you could show an ad to 100% of the population of the United States today, Facebook will claim credit for 100% of your sales for the next 24 hours. It\u2019s obvious that we shouldn\u2019t be giving 100% of the credit to Facebook \u2014 most of those sales would have happened anyway! Yet it\u2019s also not correct to say view-through conversions have no impact \u2014 you don\u2019t \u2018click\u2019 on a TV ad and yet TV advertising is proven to be profitable.This is the number one question I\u2019d get working with startups running paid ads, and now you know the reason why. Let\u2019s look at some scenarios where Facebook ads (which counts view through and uses a click window) wouldn\u2019t line up with Google Analytics (which uses last click, and has no view-through data).I\u2019ve been shopping with this brand for 20 years, and I click on an ad once to buyI see an ad in my feed and ignore it, I get an email later that day and click to buyI browse the news, I don\u2019t even see the ad that loaded, I buy later that dayI click on an ad, decide not to buy, then a week later I buy on referral from a friendI search on Google, visit the site, click a retargeting ad, search again in 3 weeks and buyI click on an ad for one product, later that week I search and buy a different productThese are scenarios that Facebook would claim 100% of the credit, where they don\u2019t deserve it! They are counting conversions up to 1 day after a view, and 28 days after a click, despite what other channels drove that sale. The majority of these conversions would happen anyway if you hadn\u2019t advertised on Facebook \u2014 they weren\u2019t \u2018incremental\u2019. Let\u2019s look at the opposite scenarios, where Facebook might not get the credit they deserve.I see a Facebook ad in my feed, and it reminds me to search their brand nameI leave the site mid purchase, and I see an ad that reminds me to come backI click on an ad on mobile, decide to purchase, but switch over to my laptop to buyI see an ad in my feed, click through to buy, but decide to find a discount code firstI click on an ad, sign up for emails, a few weeks later a deal comes in and I buyI see ads in my feed for months, then I remember the brand when I need to buyThese are all legitimate scenarios where Facebook will count a user but Google Analytics won\u2019t give them credit. In these cases impressions had real value, and Facebook is right (or even conservative) to count view-through conversions with a 1 day attribution window. This is particularly important for businesses where the purchase isn\u2019t immediate \u2014 if it takes more than 24 hours to purchase then you\u2019re potentially seriously undercounting the impact of Facebook."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How do I measure the ROI of digital marketing?' for the blog post 'Measuring the Halo Effect of Ads'"}, {"role": "assistant", "content": "The problem arises despite all the advanced adtech analytics tools out there, because there is a fundamental gap in knowledge between actors \u2014 one that is only likely to widen. For all the talk about surveillance capitalism, this attribution gap exists because Facebook and Google don\u2019t share their user data! You can\u2019t get user level data on who saw ads or clicked on them, until they visit your website.\u00a0All you know about them is what channel they came from and what campaign and ad creative they clicked on. Facebook isn\u2019t likely to make user-level data available, because it invades user privacy and erodes their competitive advantage. Even within Google, there\u2019s no information sharing between Google Ads and Google Analytics, that you can\u2019t get if you install any other analytics platform. With GDPR, CCPA, and Apple\u2019s moves on iOS with the ITP and IDFA, this gap is only likely to widen.So despite all the sophisticated measurement tools, it\u2019s impossible to accurately track user-level behavior one-to-one. So what do marketers do? Well the answer comes from traditional marketing \u2014 I mentioned that TV advertisers can\u2019t rely on \u2018clicks\u2019 or \u2018conversion\u2019 tracking, because nobody \u2018clicks\u2019 on a TV ad\u2026 so how do they do it? The answer is Econometrics, also known as Marketing Mix Modelling or Linear Regression."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Measuring the \u2018Halo Effect\u2019 of Facebook Ads' for the blog post 'Measuring the Halo Effect of Ads'"}, {"role": "assistant", "content": "To follow along with your own analysis, use this template which already comes complete with example data from a past analysis I did. The goal of this exercise will be to see if paid ads have an impact on organic traffic \u2014 specifically in this case, did high spend on Facebook ads lead to any noticeable impact on organic search traffic?\u00a0Our hypothesis is that spending money on Facebook Ads will drive new users who come through organic channels like visiting the website URL directly, or via searching for the brand term. We know that view-through should have some value \u2014 this helps us understand how much value our ads drive that isn\u2019t accounted for on a last click basis.For this analysis we\u2019re simply going to do a linear regression of Facebook ad spend versus organic visits. If we expect that Facebook drives organic users we would expect to see some correlation between days of high spend and high organic traffic. If they are unrelated, we\u2019d expect to see no pattern at all \u2014 high and low spend days don\u2019t line up to high and low organic traffic days."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Pulling data from Facebook ads and Google Analytics' for the blog post 'Measuring the Halo Effect of Ads'"}, {"role": "assistant", "content": "Go to your Facebook ads manager and choose a monthly breakdown. Select a date range that\u2019s as long as possible, by choosing \u2018lifetime\u2019. Click on reports, then \u2018export table data\u2019. Make sure you have the amount spent and impressions, we\u2019re going to ignore conversions for now.Now for Google Analytics; go to Acquisition > All Traffic > Source / Medium report. Then click on segments, add a new segment, and filter for people who have come to your site from \u2018google / organic\u2019 and landed on the homepage.Now select your main conversion metric (for us this is all goals, as each individual goal was a lead). Select as wide a date range as you have (hopefully overlapping as much as possible with what you pulled for Facebook). Finally add a secondary dimension of \u2018Month of Year\u2019 (note: not \u2018Month of the Year\u2019).Note, if you pull the data far enough back, you\u2019ll notice \u2018Users\u2019 disappears due to Google\u2019s rules around user privacy, but don\u2019t worry we only need sessions and conversions. In the bottom right corner there\u2019s the ability to show more data on one page, you want to select enough to show all of your pages.Now scroll up to the top and export the data to CSV or GSheets, ready to copy and paste across into the template.\u00a0The gray column converts the year and month into the right format, so you can more easily join up to other data. In the tab for Google Analytics we have the same, but also another formula which uses INDEX and MATCH to search for the column Amount Spent (USD) from the Facebook ads tab, and join it to this table based on date. If your Amount Spent column is called something different, rename this column so it can be found.The data is then joined together in a pivot table based on the month and year. Note that if your date ranges don\u2019t overlap, only the data that you have in analytics will show here (so you might be missing some Facebook data for months where this analytics profile didn\u2019t have data, like is happening in our template).If you have the opposite problem where you don\u2019t have as much Facebook data as needed to cover your analytics, then consider deleting the date ranges where you there isn\u2019t overlap, in order to improve the fit."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Is there a significant impact on organic traffic from ad spend?' for the blog post 'Measuring the Halo Effect of Ads'"}, {"role": "assistant", "content": "From the data entered into the template, there will be an automatic regression analysis run using the LINEST formula. This is run against sessions as well as goal completions. If your goal is called something different you might need to drag these into the pivot table in the right order, and rename the axes of the charts.So how do we interpret the results of this regression? Well there are a few things to look out for. First look at the chart. Are the dots clustered together close to the line? Or are they spread out? Next look at the R^2 number \u2014 is it higher than 0.5? In our case it\u2019s as low as 0.2, which is an indication of a weak correlation. If it was 1 that would mean 100% of the variance in sessions was related to what we spent on Facebook. You should also look at the slope \u2014 in this case we see a negative slope, which implies sessions were actually lower on high spending days.The same variables are also calculated by the LINEST formula about the chart in the spreadsheet. In our case we can see that we actually lose 0.06 of a session for every dollar more we spent on Facebook. This is a weak correlation with an R^2 of 0.20, so it would be safe to disregard any perceived impact of Facebook ads on organic sessions.But what about goal completions? Spending on Facebook might not cause more organic sessions in a statistically observable way, but potentially people are more likely to buy in months where we spent more money? Unfortunately not \u2014 for goal completions the chart looks worse.This is showing us absolutely no correlation. Even when we spent as much as $5,000 per day we didn\u2019t see any improvement in goal completions. Now this doesn\u2019t necessarily mean there is no effect \u2014 it might be a small effect, or perhaps there\u2019s a confounding variable, something related to both that distorts the data. However my conclusion from looking at this data would be to be extremely distrustful of any incremental view through effect Facebook might be claiming."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Next steps after running a halo effect analysis' for the blog post 'Measuring the Halo Effect of Ads'"}, {"role": "assistant", "content": "There\u2019s never a positive or negative result from analysis \u2014 you either prove there is an effect (and have a new opportunity for growth) or you prove there isn\u2019t (and can save your budget). In this case it was negative, but often I\u2019ve run these analyses and seen positive results, for example in this case study by Orion KCB.Regardless of the results you found, you might be wondering what the next steps are if you believe this phenomenon exists. One option if you think there might be confounding factors, is to run a full Econometric analysis. During this process you\u2019d test out different definitions of variables, add more variables into the model and potentially tease out a real effect.\u00a0The other alternative is what\u2019s called deprivation testing or incrementality tests \u2014 essentially you turn it off (for a randomized selection of the audience if possible) and measure how many conversions still happen. The Facebook platform does allow incrementality tests, but usually there are minimum requirements in ad spend to get a significant test. The unsophisticated way is to just turn it off for a week, on again for a week, off again for a final week, then compare the two weeks on with two weeks off to see any patterns.Whatever method you employ (and smart marketers utilize all of them at various stages), being able to quickly run a regression test in a template like the one we used to analyze whether two variables are correlated, is a useful skill for any data-driven marketer.---Check out the rest of the posts in the series:Econometrics in GSheetsEconometrics in PythonDiminishing ReturnsMeasuring the Halo Effect (this post)When Econometrics WorksIn future we plan to cover:Word of Mouth CoefficientTesting Model AccuracyMonte-Carlo SimulationsMachine Learning ModelsData Import from APIsThe Future of EconometricsAny other topics? Tweet @hammer_mt to request"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '1. Get ready for disruption' for the blog post 'What to tell your boss/client about iOS 14.5'"}, {"role": "assistant", "content": "Photo by Icons8 Team on UnsplashApple confirmed the release of iOS 14.5 will begin next week (w/c April 26th) and people are freaking out. Apple is making tracking opt-in rather than opt-out, which is expected to cut the ability for marketers to track users on iPhones by as much as 90%.Without the ability to track users on iPhone, a lot of stuff breaks. For users that don\u2019t opt in (and why would you?) advertisers won\u2019t be able to tell if those users bought anything after clicking on ads. This is the most significant change to a $325b industry since Facebook launched its ad platform.It also leaves a gaping hole in the ability of Facebook and other advertisers to effectively target the right people. Apple has confirmed that advertisers specifically can\u2019t use email addresses or other PII from users collected on iOS for retargeting or attribution, closing any loopholes vendors were hoping to use to skirt round the restrictions.There has already been upheaval, as advertisers see triple-digit fluctuations in CPM (the cost of buying ads) and ad platforms announce huge changes to the way their products work, for example Facebook killing their analytics product and changing default attribution rules to 7 day click through and 1 day view.So as a marketer, you\u2019re bound to get questions from your boss or client about the roll out. What do you say? I\u2019ve spent over $50m on paid ads in the past 10 years, and built a 50 person digital agency before leaving last February \u2013 this is what I\u2019d say:Don\u2019t expect good performance from your campaigns in the next few months. We\u2019ll all be doing our best to navigate the situation, but this is a battle of the titans between Apple on one side and Facebook, Google, etc on the other. It won\u2019t be pretty, and we\u2019ll have limited ability to influence the outcomes. Everyone on the team will be doing their best, and we\u2019ll get through this period stronger if you approach every problem we run into with that in mind."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '2. This is the end of deterministic attribution' for the blog post 'What to tell your boss/client about iOS 14.5'"}, {"role": "assistant", "content": "This leaves a big, permanent hole in our analytics. We no longer know it was person X who clicked on ad Y and purchased Z. iOS is the most valuable slice of mobile traffic, and without visibility, no analytics tools will work like they used to. We must adopt a \u2018probabilistic\u2019 mindset, using data science techniques like marketing mix modeling to measure what channels, campaigns, audiences and creatives are the most likely to be working."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '3. We need someone in marketing who can code' for the blog post 'What to tell your boss/client about iOS 14.5'"}, {"role": "assistant", "content": "User privacy and analytics tracking are dense, technical topics that are hard to understand even for technical marketers or growth engineers. Vendors are scrambling for solutions which will require a higher degree of technical knowledge to understand. Tracking is no longer a \u2018one and done\u2019 job, it\u2019s something we\u2019ll need to change regularly, and even build custom solutions for, if we want to gain an advantage (or not fall behind)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '4. Our attribution was never that good to begin with' for the blog post 'What to tell your boss/client about iOS 14.5'"}, {"role": "assistant", "content": "Last click or even multi-touch attribution was never as accurate as you hoped. Word of mouth, dark social and offline channels drive the vast majority of sales for most brands, but were completely unaccounted for. The way we assigned credit was taking credit for a lot of sales that would have happened anyway, at the expense of user privacy. GDPR and Adblockers were already chipping away at a broken system \u2013 iOS14.5 is just the final nail in the coffin."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '5. Context and creative are more important than ever' for the blog post 'What to tell your boss/client about iOS 14.5'"}, {"role": "assistant", "content": "Micro-targeting based on demographics & interests isn\u2019t the only form of targeting. Google is less worried than Facebook, because their most valuable targeting is contextual: \u201cwhat did the user search?\u201d. Expect a return to buying ads based on what the user is doing, rather than who they are. The best targeting has always been creative \u2013 every SuperBowl advertiser is buying the same placement, but their ads appeal to different people.What\u2019s next?After some disruption, the industry will be fine. There will be winners and losers, but advertising has always been ~1% of GDP throughout history. The shift from traditional to digital channels won\u2019t be stopped, because there are advantages to buying in a programmatic auction even without targeting and tracking. Digital marketers will need to get better at statistics and creative: maybe it\u2019s time to dust off some traditional marketing books?We\u2019ll need to change our approach and work a little harder to establish the \u2018ground truth\u2019 of what\u2019s performing, and vendors will need to build a new breed of software to support us in that journey. That\u2019s something I\u2019m working on at Vexpower.com, a training simulator to teach you marketing mix modeling. Having solved this problem for a bunch of people in my days at Ladder and seeing this coming for a while, I\u2019m always up for a conversation on Twitter."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'What is a good K-Factor?' for the blog post 'K-Factor Benchmarks'"}, {"role": "assistant", "content": "This is an important metric, and while there's plenty written online about how to model it, measure it or optimize for it, most are secretive about what a good K-Factor actually is.The typical article on virality will tell you the importance of getting to a K-Factor of 1 \u2014 anything less and your growth will decline, even a fraction above one and your growth will be exponential.However this isn't really helpful advice. K-factors > 1 are rare, and any virality at all can contribute thousands of new users. So the question is, what's a 'normal' K-Factor for my product / industry?In order to answer the question, I've trawled through hundreds of blog posts to find instances where people actually shared their K-Factor publicly, so I could gather them all in one place."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'K-Factor Definition' for the blog post 'K-Factor Benchmarks'"}, {"role": "assistant", "content": "K-Factor is a term borrowed from epidemiology, where it's more commonly known as the viral coefficient or R0. Strictly defined it should mean \"the number of cases that are expected to occur on average in a homogeneous population as a result of infection by a single individual\".In marketing terms, it has been adapted to mean the number of new users that are acquired as a function of the number of users that sign up. This is modeled as K = i x c, where K is 'K-Factor', i is 'number of invites sent per user' and c is 'average invite conversion rate'.However these benchmarks are drawn from passing mentions in blog posts with no rigorous academic standards \u2014 we can't know how they measured this metric, so don't take these numbers too seriously. The best benchmark is being better than you were yesterday.https://www.notion.so/d649b9a85c7e42619194dc593345aee3?v=2a1367937cce4585a689268735458b5dNote:If you see any other public K-Factors, or want to share your own, tweet at me: @2michaeltaylor"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Slack - 8.5' for the blog post 'K-Factor Benchmarks'"}, {"role": "assistant", "content": "That figure sounds daunting. Of roughly 220,000 teams that have been created in Slack, upwards of 30,000 are actively using it. \u201cHowever, because one active team has an average of eight or nine members, we have close to 250,000 daily active users. We have more daily active users than teams that were ever created. So we lose a bunch, but the ones that we get to really try it out stick with it.\u201dCategory: B2B CommunicationsSource: https://firstround.com/review/From-0-to-1B-Slacks-Founder-Shares-Their-Epic-Launch-Strategy/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Square - 0.01' for the blog post 'K-Factor Benchmarks'"}, {"role": "assistant", "content": "So once you have a hypothesis, then the next question is, \u201cWell, how do you validate that? How do you test it?\u201d If true, there should be a ratio for every new Square we shipped, and every new customer, and every transaction in the rate of growth. Turns out there was a perfect relationship, it\u2019s exactly 1%. So for 1% of all transactions on let\u2019s say day zero, we have 1% of signups the next day, new signups, and they just were perfectly consistent. This is amazing. We now have an actual viral loop in the real world. We had this observability. We\u2019ve been in the real world that\u2019s causing growth, but it was not at all obvious.Category: Merchant PaymentsSource: https://www.nfx.com/post/how-contrarians-think-with-keith-rabois/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Ladder - 0.73' for the blog post 'K-Factor Benchmarks'"}, {"role": "assistant", "content": "With a K-Factor of 0.73, we did fantastically well overall in terms of virality \u2014 in B2B a viral coefficient of 0.20 is far more common.Category: Info ProductsSource: https://blog.ladder.io/engineering-virality/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Viddy - 1.0' for the blog post 'K-Factor Benchmarks'"}, {"role": "assistant", "content": "For example, let\u2019s says 100 people get an invite per person who imports, then of those, 10% click, and 50% sign up, and of those only 10 to 20% import, you\u2019re going to be at 0.5 - 1.0 K factor, and you\u2019re not going to be viral. A lot of things like Viddy were very good at pumping up stories. They got the factor over 1, which is perfectly doable.Category: Social NetworksSource: https://startupclass.samaltman.com/courses/lec06/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Echosign - 0.2' for the blog post 'K-Factor Benchmarks'"}, {"role": "assistant", "content": "If you are a SaaS company then you are 99.999% unlikely to go viral and it will take a long time to engineer any form of virality. Echosign had a K of 0.2 and had a CT of 8 months.Category: B2B SaaSSource: https://www.alexanderjarvis.com/model-viral-growth-startup/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Jelly Splash - 0.92' for the blog post 'K-Factor Benchmarks'"}, {"role": "assistant", "content": "Soft LaunchStrong Virality: Average K-factor 92%Strong Retention: Minimum Day 1 Retention 50%What We LearnedVirality decayK-factor decreased to 84% / eCPI increased by 28%Increased networks kept CPIs flatCategory: Mobile GamesSource: https://www.slideshare.net/EricSeufert/eric-seufert-gdc-2014-profitably-launching-jelly-splash-to-1-a-marketing-postmortem"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Extole - 0.04' for the blog post 'K-Factor Benchmarks'"}, {"role": "assistant", "content": "We studied the referral programs of 400 customers, and here are the benchmarks we saw:19% of potential advocates become advocates28 Referral Index\u21222 shares per advocate on averageMedian 1 friend click per share13% conversion rate from click to customerUsing those numbers, we have a i = .19 * 2 = .38 and we have c = 1 * .13 = .13. That gives us k = 0.0494.Category: Referral ProgramsSource: https://www.extole.com/blog/how-to-model-non-viral-referral/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Facebook - 7' for the blog post 'K-Factor Benchmarks'"}, {"role": "assistant", "content": "After all the testing, all the iterating, all of this stuff, you know what the single biggest thing we realized? Get any individual to seven friends in 10 days. That was it. You want a keystone? That was our keystone. There's not much more complexity than that.Category: Social NetworksSource: https://www.youtube.com/watch?v=raIUQP71SBU"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Rahul Vohra - 0.2' for the blog post 'K-Factor Benchmarks'"}, {"role": "assistant", "content": "From discussions with other entrepreneurs, investors, and growth hackers, I've learnt the following: for a consumer internet product, a sustainable viral factor of 0.15 to 0.25 is good, 0.4 is great, and around 0.7 is outstanding.Category: Consumer Internet ProductsSource: https://www.linkedin.com/pulse/20121002124206-18876785-how-to-model-viral-growth-the-hybrid-model/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Adjust - 0.45' for the blog post 'K-Factor Benchmarks'"}, {"role": "assistant", "content": "What we ultimately found is that while K-Factor definitely exists, it doesn\u2019t apply to the majority of apps on the marketplace.30% of our sample had K-factor. For this 30%, our data team established that the median K-factor was .45. This means that (looking at apps performing in the middle of our sample) for every 100 paid installs, you would receive an additional 45 organic ones.We also had a deeper look at how K-factor differed by app vertical. We started by looking at games, and (of our sample), we found that K-factor affected 22.5% of them (470 apps), while for non-Games (871 apps) it\u2019s 33.6%. So, here, gaming apps are less affected by K-factor. In fact, it\u2019s ecommerce apps (158 of them) that have a higher percentage of K-factor existence: 38.6 percent, while non-shopping apps have a 28.5% likelihood of K-factor by comparison.Category: Mobile AppsSource: https://www.adjust.com/blog/measuring-k-factor/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'COVID-19 - 2.63' for the blog post 'K-Factor Benchmarks'"}, {"role": "assistant", "content": "Estimates of the R0 of SARS-CoV-2 vary widely. Figure 5 shows nine estimates, all from studies in China or South Korea. The mean estimate of R0 is 2.63 (95% CI = 1.85,3.41). From a wider survey of 16 published estimates, the mean estimate is 2.65 (1.97, 3.09). In both cases, the range is 0.4-4.6.Reproduction numbers for virusesCategory: Actual VirusesSource: https://www.cebm.net/covid-19/when-will-it-be-over-an-introduction-to-viral-reproduction-numbers-r0-and-re/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Things to Keep in Mind' for the blog post 'K-Factor Benchmarks'"}, {"role": "assistant", "content": "True viral growth is incredibly rare - even many real viruses don't reach K > 1Even a K-factor of 0.2 is good - this means 1 free signup for every 5 you drive!Don't blindly optimize for K-factor - you'll spam users, harming long-term growthRetention is king - viral apps will rapidly decline if you can't retain new usersK-factor isn't static - it changes with your product, user cohorts and audience size\u200d"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'A. Owned Keywords' for the blog post 'Building Your Keyword Universe'"}, {"role": "assistant", "content": "This post is one of a series on my content production system, developed over 10 years and designed to scale content end-to-end in 6 months as an acquisition channel. Here are the other posts in the series:Why the winner takes all in Content MarketingWhat everyone gets wrong about Content Strategy\u200dBuilding Your Keyword Universe (this post)\u200dMinimum Viable Technical SEO Audit\u200dRecruiting good Freelance WritersHow to write blog content at scaleGrowth engineering for SEO\u200dLink building for authorityContent Repurposing for Social Promotion ---If you want to be successful on search, you need to know what people are searching for. Buy access to a keyword research tool like Ahrefs, SEMRush or SpyFu - you'll use one of these tools almost every day if you're serious about focusing on content as a channel. You can also use Google Keyword Planner for free if you set up a Google Ads account, at least to start with. The goal is to understand what keywords exist in the space and categorize them into buckets, so you know what to go after and in which order.\u00a0If you want to scope out the size of the opportunity in SEO, you can get estimated traffic for competitors\u2019 keywords, from which you can assume a conversion rate. If your industry just doesn\u2019t have a lot of search volume it might make sense to bet on a different channel. However don\u2019t plan on just doing keyword research once: this is something you\u2019ll be doing on demand each week, adding a few keywords at a time, increasing your TAM as you dominate your initial niche and expand.\u00a0Choose one or two keywords to own. This has to be a keyword that\u2019s unique enough to your product that you can reliably claim a thought leadership position. That means it\u2019ll probably be low volume and that\u2019s ok: this is a keyword you\u2019re going to build demand for with the rest of your marketing, and when it gets big, the rising tide will lift your boat.\u00a0For Ladder this was \u201cgrowth hacking\u201d because at the time there weren\u2019t many agencies that offered it. Eventually it outgrew us, but we rode that keyword all the way up. It can help to actually coin a term (e.g. Bryan Dean\u2019s \u201cskyscraper technique\u201d), or take something you\u2019re better than competitors at ( or modify an existing phrase (e.g. for Vexpower it\u2019s \u201csimulator-based courses\u201d). You want to write thought leadership content primarily here: an opinion piece, beginners guide or overview of the topic will work well.\u00a0"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'B. Trending Keywords' for the blog post 'Building Your Keyword Universe'"}, {"role": "assistant", "content": "These are keywords that cover interesting topics that are trending or have the potential to trend. For inspiration here it's better to look to social media more than traditional keyword tools \u2014 by the time they show up the trend is over. Also look at Reddit and any niche forums: one memorable example was using Google translate to read Chinese forum posts about working in Silicon Valley. Remember the goal of creating content for these keywords is to quickly ride the wave so you get shares and hopefully backlinks.\u00a0You don\u2019t have to create the trend but these things grow up unexpectedly, and by being the first serious source on the trend you\u2019ll get all the references. The content you write here should start off as social posts: most trends flop, so only graduate the keyword to a blog post if it starts to take off. In some cases you can find a keyword that will reliably trend at predictable intervals: news organizations take full advantage of these types of keywords: for example they have pre-written obituaries for all major celebrities ready to publish in the event of their death."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'C. Target Keywords' for the blog post 'Building Your Keyword Universe'"}, {"role": "assistant", "content": "Most people in your industry don\u2019t regularly look at SERP rankings, so there are usually keywords with a low difficulty / competition and high enough traffic. On Ahrefs (or similar tools) if you search for a keyword then select \u2018related keywords\u2019, you get a big list of relevant terms. Filter it down by selecting a keyword difficulty of less than 40, and at least 1,000 searches per month (less if you\u2019re B2B), and you\u2019ll find plenty of hidden gems.These numbers flex as you grow: there\u2019s no shame in targeting keywords with 100 searches and <10 difficulty when you\u2019re a new site: everything makes a difference! For example at ShopStyle, we made lots of money on \u2018Flapper dresses\u2019 (think Great Gatsby), while most of the big fashion publications were writing about what celebrities wore to the Oscars. The content format that works best here is an atomic essay: 500 words on the topic, with a single shareable asset: a template, image or insight."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'D. Head Keywords' for the blog post 'Building Your Keyword Universe'"}, {"role": "assistant", "content": "There are keywords that everyone in the market wants to own. There\u2019s a power law to keyword traffic so 90% of your traffic will come from 10% of your keywords. At Travelzoo we had 25% of our revenue coming from a single keyword: \u201ccheap flights\u201d \u2014 we weren\u2019t even ranked number 1: we were 4th! You can find these keywords quickly by using a keyword research tool (Ahrefs, SEMRush, SpyFu) to see the biggest terms sending your competitors traffic. It\u2019s not worth going after these keywords until you\u2019ve written something good on your owned term, and hit all the low hanging fruit with targeted keywords: head terms are very hard to rank for. When you do go after them, build a comprehensive \u2018hub\u2019 page, with your atomic essays on relevant targeted keywords acting as the \u2018spokes\u2019 all interconnected with internal links to show relations."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'E. Long Tail Keywords' for the blog post 'Building Your Keyword Universe'"}, {"role": "assistant", "content": "This should be the final bucket you optimize for, because it\u2019s hard to do it right. Of course you will be ranking for some long tail keywords at this point, because every page ranks for multiple keywords, not just the ones you targeted. But to really hit long tail keywords at scale, you\u2019re going to need to build products. This is very difficult to do as an SEO team, because usually you don\u2019t get developer resource. That means when you pull it off, it can be a great moat that\u2019s hard for competitors to replicate. "}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Mentions' for the blog post 'Link building for authority'"}, {"role": "assistant", "content": "This post is one of a series on my content production system, developed over 10 years and designed to scale content end-to-end in 6 months as an acquisition channel.Here are the other posts in the series:Why the winner takes all in Content MarketingWhat everyone gets wrong about Content Strategy\u200dBuilding Your Keyword Universe\u200dMinimum Viable Technical SEO Audit\u200dRecruiting good Freelance Writers\u200dHow to write blog content at scale\u200dGrowth engineering for SEO\u200dLink building for authority (this post)Content Repurposing for Social Promotion---Most content marketers spend all of their time creating new content. They post new articles on social media when they\u2019re live, almost as an afterthought, then they wonder why 91% of indexed pages get no organic traffic from Google! Instead you should be spending 80% of your time promoting content, and only 20% writing it, as Derek Halpern recommends. If you want that content to be seen by anyone, it needs to rank on the first page of search results. As Brian Clark says \u201cThe Best Place To Hide A Dead Body Is The Second Page Of Google\u201d. How do you rank on the first page of Google for a keyword?\u00a0Google\u2019s success as a search engine was predicated on their patented PageRank algorithm. It works by counting the number and determining the quality of links to a page to estimate how authoritative the website is. It\u2019s a popularity contest: websites that get lots of links from other websites (who themselves get lots of links) will be seen as more important, and rank higher on Google. It\u2019s not the only algorithm that Google uses, but it\u2019s obvious that links are still very important. By some measures your link profile contributes 15% to the rank you achieve.As a rule of thumb, you should aim to get at least 1 link to each blog post you publish to put it \u2018on the map\u2019, and multiple authoritative links to any page you\u2019re trying to rank for a competitive keyword. Links should be from a diverse range of sources: if they all come from the same website or type of website, that\u2019s a sign to Google that you\u2019re trying to game the system. The keywords used when someone links to you, the anchor text, are important too: they are a sign of what topics you\u2019re relevant for. You want these to be natural too: using the same words again and again looks spammy.So how do people actually build links? What link building tactics and strategies are available, and what are their relative strengths and weaknesses? I put them into three buckets:Mentions: Build a relationship with a writer and get linked to from their content.Guest Posts: Write content for a publisher and link back to your own product.Linkbait: Develop assets that attract a lot of high quality inbound links naturally.They\u2019re in order of ascending cost and risk, but also reward. Linkbait tactics are the most expensive and least likely to succeed, but when they do you can build an entire business off the back of one success. Alternatively mentions are relatively straightforward to get \u2014 it\u2019s a numbers game \u2014 but the value of these links is usually relatively low or even negative, if the link is low quality. In the middle is guest posting, a technique that always works and almost anyone can do for a reasonable cost, with results that scale linearly with effort.The quickest and easiest way to increase your authority is to contact people with higher authority websites than you, and convince them to link to you. At its worst this is what motivates a lot of cold email spam cluttering up every webmaster\u2019s inbox. At its best you build genuine relationships with influential people in your industry, and they think of you whenever they publish something relevant. This is the category PR (Public Relations) falls under, although I won\u2019t cover that in this post because it\u2019s not something you can easily do yourself. Here are some of the tactics I\u2019ve found to work in this space:Link Love: Partner up with non-competitive products in a similar space and exchange links.HARO: a platform called Help A Reporter Out where journalists look for experts to quote.Roundups: look for posts listing multiple competitors and email them to ask to be included.Brand Mentions: find places your brand has been mentioned without a link and contact them.Directories: get listed on various websites which list other websites for various reasons.Resource Pages: find pages that provide resources on related topics and email to get listed.Broken Links: find relevant links that are 404s and contact the author to ask them to swap it.To execute on these tactics you likely need access to an SEO tool like Ahrefs or SEMRush. They will help you identify opportunities where websites are linking to your competitors but not to you. For example I can see who links to CXL.com but not vexpower.com in Ahrefs link intersection tool.From there I can see what pages on CXL.com rank best, who links to those pages, and if any of those links are broken. SEO is unique in that it\u2019s easy to reverse-engineer a competitor's strategy and figure out how to compete. Licenses for these tools aren\u2019t cheap, but most SEO specialists will find themselves using it every day.\u00a0Another way to find these opportunities is advanced search operators (thanks James Phoenix for sharing this technique). You search for your topic plus various keywords in order to find relevant resource pages, hubs or directories.If you are using cold email outreach you will also need a tool to send the emails and schedule follow ups like Lemlist, but personally I\u2019ve had better results going for warmer outreach from my own email, rather than cold emailing at scale. Quality beats quantity and you maximize your chances of building a relationship with someone important to the industry, while minimizing your chance of building too many low value or toxic links that actually hurt your ranking."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Guest Posts' for the blog post 'Link building for authority'"}, {"role": "assistant", "content": "The tactic that almost everyone uses at scale is guest posting. This is what most SEO agencies, for example Skale (thanks Jake Stainer for contributing to this section!) and Growth Machine, will do for you if they offer link building. The trick is to build up a list of websites in your target niche that accept guest posts. You\u2019d be surprised how many even premium publications accept external content: the economics of online publishing make it so they can\u2019t always afford to pay writers, and so long as the post isn\u2019t overly advertorial they\u2019re happy for you to link back to your website.\u00a0I prefer to sort publications into tiers so we know what level we\u2019re targeting, as a link from an authoritative website is worth 100 links from smaller publications. Usually the barrier to entry is higher the better the publication: they will insist on higher quality and it makes sense to craft the post you write for them in the house style, so it\u2019s more likely to get approved by the editor. Usually it\u2019s worth the extra effort, because readers will also expect that style and will be more receptive to your message also. Here is an example of tiers from my last company Ladder.io, a growth marketing agency.Tier 1: Mainstream publications that have high domain authority and broad reach..Business Insider, Entrepreneur, Inc, Fast Company, Forbes, HBR, TechCrunchTier 2: Popular industry publications with good topic relevance and authority.Hubspot, Marketo, Salesforce, Adweek, Mashable, CMO.com, Reforge, CXLTier 3: Smaller sites with low to medium authority but strong topic relevance..IndieHackers, SmallBizTechnology, DuctTapeMarketing, GrowthMentor, DataboxTier 1 websites are very hard to get into unless you know people, pay a PR person who knows people, or have something genuinely newsworthy happen, like a funding round or major news story. Tier 2 is more achievable, though you should expect to work hard to get your pitch approved, and produce a very high quality piece. The name of the game is respect: you should feel lucky to get an opportunity in one of these publications, and do your best to make the interaction valuable for the publisher in order to build an ongoing relationship. Getting a good article in one of these publications can literally put your website on the map in terms of ranking, and can bring direct traffic to your site and build awareness of your product as an added benefit.Usually you want to start with Tier 3 websites because these are growing publications: they\u2019re more keen for fresh content, and as they increase their own rank their links will be worth more to you. It also costs less in terms of time and effort to get published on these websites, though they do all have their own guidelines.\u00a0There are a lot of websites below Tier 3, and I haven\u2019t bothered listing them because they\u2019re usually fairly low quality. When you buy backlinks from a service like Legiit, or outsource backlink building to someone on Upwork or Fiverr, these low quality websites are usually what you get: and it can actually be harmful. I\u2019d try to avoid these \u2018black hat\u2019 techniques. A good proxy for whether a backlink is valuable, is how much referral traffic the link sends you. If people aren\u2019t clicking through from that link, there probably isn\u2019t anyone actually reading the post, and that\u2019s a sign of danger.This is where investment in a good SEO tool can help, because you can check any potential websites you might want to get a link from before you go to the effort. This is especially important if you\u2019re outsourcing the discovery of link opportunities to a freelancer: you want to make sure that they\u2019re not bringing you garbage. Look for sites that have strong topical relevance (a link from a dentist\u2019s website is just going to confuse Google if you sell shoes). The site should have a decent Domain Authority: they should have at least 100-200 domains linking to them or you don\u2019t want a link from them. It\u2019s also a good sign if they are growing their own organic traffic over time, because the link will appreciate in value."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Linkbait' for the blog post 'Link building for authority'"}, {"role": "assistant", "content": "This is my favorite strategy but it\u2019s also the hardest to pull off. That\u2019s what makes it valuable: because tactics for getting mentions are well publicized and anybody can do guest posting, those strategies are saturated. Better to go big with something unique that nobody else in the market has the resources, motivation and creativity to pull off. When it works, it works well. You can build an entire business off one success. When you do create something that taps into the zeitgeist and \u2018goes viral\u2019 the results can be felt immediately. We were lucky enough to achieve this with our Hiring Freeze guide at Candor at the start of COVID, and got over 3,000 backlinks in the course of a few days. That individual page got hundreds of thousands of hits from social media, but more importantly, the increased authority from all of those links meant all of our content suddenly started ranking. We went from a few hundred visits from SEO per week to tens of thousands, a long lasting effect that continues to this day.In some respects it\u2019s hard to suggest tactics for this strategy, because by definition you\u2019re trying to build something unique. However there are certain patterns in terms of what assets tend to attract links.Newsjacking: write about a topic before it trends to get quoted as a source.Coining: invent a new term and attract links from everyone who talks about it.Skyscraper Technique: find something with lots of links and make a better version.Templates / Tools: build small free products or templates that will get linked to.Datasets: build up a unique dataset and present it in a way to attract backlinks.Graphics: create a nicely designed visual chart or infographic for a specific topic.Programmatic SEO: build out lots of automated long tail pages to attract links.Particularly if you\u2019re a small brand, it can be hard to compete on the main terms in your industry. Big incumbents always have huge link profiles built up over years. So if you can\u2019t beat them on old terms, you have to be first to new ones. If you get there first on a trending term you\u2019ll earn links by being quoted as a source, and be able to rank on a SERP with far less competition. As a startup you can often be more flexible and move faster, so use that to your advantage. But how do you find terms with potential to blow up?"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Topic Selection' for the blog post 'Link building for authority'"}, {"role": "assistant", "content": "Find a topic where demand outpaces supply \u2014 where there\u2019s a lot of \u2018filler\u2019 content being published because there\u2019s lots of demand but no actual news. Think of if you tune into a football match 30 mins before it starts: they have to show you something relevant to the game, but it hasn\u2019t started yet. You get random fan interviews, reporters on location, pundits talking about what will happen, etc. This is exactly the time to insert yourself in the conversation, before the action starts to happen. You can identify these scenarios by the following:a) Increase in google searches / social activity (shows audience interest)b) Increase in pages published (shows demand to write about topic)c) Most content is 'filler' not 'breaking news' (opinion pieces, no new info)d) There is soon to be news (the jobs report is coming out in 2 days)Breaking newsSeasonalTrendsPersonal Intereste) You have space to credibly play (journalists will believe you have the inside scoop)One great example of this is from Nik Baron, formerly at Grammarly (who deserves the credit for this strategy). When interest in Donald Trump\u2019s rise was at its highest and publications where desperate for any commentary on the unprecedented situation, Grammarly released some custom analysis that showed Trump fans had worse grammar: it was immediately covered by every major publication.I had some of my own success with this technique in the niche world of marketing attribution. iOS14 had a huge impact on Facebook ads performance and everyone was wondering how Facebook would respond. I jumped on a niche webinar about their new marketing attribution tool, Robyn, and live tweeted it: getting over 800,000 impressions as people were highly interested in the moves Facebook was making. I then followed that up with a new course for Vexpower on how to use Facebook\u2019s new tool, which to this day is our most popular course.\u00a0"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Story Development' for the blog post 'Link building for authority'"}, {"role": "assistant", "content": "The difference between the right words and the right words can be enormous. Often the same story repositioned can find 1000x the traction. The key is to find a more tribal angle on a topic or shine a light on a taboo that everyone already thinks but isn't saying \u2014 for example:a) A Taboo topic that people won't or can't talk to (diversity, political correctness, religion)b) Can split the population by identity (location, politics, wealth, schools, companies)c) Will confirm existing biases and social constructs (I knew it and this is proof)d) Uses some unique inside information (data, survey, quotes, analysis, facts)e) Spend time on the headline, making it easy to spread virally (emotion, clickbait)The more cynical among you might look down on this type of spin, but it works. The way that we decide what to pay attention to is hardwired biologically and hasn\u2019t changed in 10,000 years. We still care about what tribes we\u2019re in, and share content that speaks to our identity. Some \u2018memes\u2019 get us going more than others. This type of memetic engineering can be used for good or evil, and sometimes the story can get away from you, so use with caution."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Distribution & Conversion' for the blog post 'Link building for authority'"}, {"role": "assistant", "content": "Once something is working organically, you want to throw gasoline on the fire. Push the story out to relevant publications in order to convert interest into column inches. It\u2019s important that you move quickly and are respectful. It helps if you have already been building relationships with influential people or have a PR team in place to help you coordinate.:a) Use tools like Cision, Meltwater, JustReachOut to build lists of journalistsb) Personalize outreach the top most relevant journalists on the listc) Mass mail merge to the rest of the journalists on the list (in a semi-personal way)d) Email capture and links on the website to capture interest and commercialize ite) Choose the page you promote carefully, to maximize value of backlinksThese techniques require prescience and good PR-sense. You have to think about what story busy journalists and industry commentators are actually going to promote and link to. It can take several failed attempts to get this working, and it requires a huge investment in time. When it does work, get ready to drop everything and put your full attention to contributing to the momentum and making the most of the opportunity."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Build or Buy?' for the blog post 'Link building for authority'"}, {"role": "assistant", "content": "Most of these techniques require a sizable commitment in terms of budget. There\u2019s often an exponential return: a slightly better design, or longer post, or bigger database could get 10x the links of something average. So the incentive is to massively over invest in production. However that can be scary because there\u2019s a high risk it won\u2019t pay off. You have to remember that\u2019s precisely why this strategy works: the returns at the top are enormous, but nobody has the stomach to invest enough to get there.Of course if you want to avoid the risk of sinking a lot of budget into something that doesn\u2019t pay off, you can buy your way to success. Many failed startups or unmaintained side projects built up strong link profiles over time that they\u2019re now doing nothing with. If you can purchase the assets from the founder for a few thousand dollars you can redirect those links to your website and improve your ranking overnight. If you\u2019re really lucky you might find a lapsed domain the owner forgot to renew \u2014 register the domain quickly before anyone notices and you can pick up very high value links for next to nothing."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'What should my link building strategy look like?' for the blog post 'Link building for authority'"}, {"role": "assistant", "content": "Even if you do nothing, you\u2019ll still attract links naturally. This is the safest and least resource intensive way to do it. Write good content and good things happen. Most of the best writers on the web have never given a single thought to link building. Your default link building strategy should be to do nothing. Not until you have enough content on your site and are in a good cadence in terms of how often you publish high quality posts. However that\u2019s also the slow way, and if you\u2019re really depending on SEO as a growth channel for your business, you\u2019re going to need to speed things up a bit.I find it helps to approach link building like an investment portfolio. You don\u2019t want all of your eggs in one basket, because that is risky and looks unnatural to Google. You also can\u2019t easily know what\u2019s going to work ahead of time, so it pays to experiment. Because of the relative cost and risk associated with each tactic, I\u2019d usually recommend you only test one big Linkbait idea per quarter: then if something hits it makes sense to double down.\u00a0Guest posting is something that everyone should do on a weekly or at least monthly basis: get started early and you\u2019ll be surprised how quickly the links pile up. Finally I find it easier to batch a bunch of mention tactics together into big projects: once one thing works try to find other similar opportunities and keep doing them until they\u2019re exhausted. This is a numbers game so defining a good process that can work at large scale is useful in terms of making the economics work.Whatever link building strategies you\u2019re using, quality control should be your overriding concern. Remember that links will build naturally over time, and it\u2019s better to not build a new link than to attract something spammy. It\u2019s also useful to remember that you almost always make money from investments in link building, but you don\u2019t control the timeline. Some links might take years to pay off, and sometimes a tactic pays off handsomely overnight. Generally speaking the bolder you can be, the bigger the reward.\u200d"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Meme Engineering' for the blog post 'Marketing Memetics'"}, {"role": "assistant", "content": "***This post is being turned into a book. Get notified at launch ->\u200d-----\u201cExamples of memes are tunes, ideas, catchphrases, clothes fashions, ways of making pots or of building arches. Just as genes propagate themselves in the gene pool by leaping from body to body via sperms or eggs, so memes propagate themselves in the meme pool by leaping from brain to brain via a process which, in the broad sense, can be called imitation.\u201d- Richard Dawkins, The Selfish GeneIn The Selfish Gene, Dawkins coined the word \u201cmeme\u201d, to mean a \u201cunit of cultural information spread by imitation\u201d. An idea gets stuck in your head, sometimes remixed with a random mutation, and then you spread it to others \u2013 think of it as a \u2018virus of the mind\u2019.\u00a0Unlike genes, memes replicate by jumping from brain to brain; but \u2018survival of the fittest\u2019 still applies: if an idea doesn\u2019t reproduce, it dies out (gets forgotten). In marketing we\u2019re in the business of spreading ideas, so it\u2019s important to know how the mechanism works.Every marketing campaign can be broken down into its component parts, or memes. What adcopy, creative or targeting techniques did they use? If you do this enough, you\u2019ll start to notice patterns: tactics that work again and again, across multiple campaigns.Breakdown of a creative into its component parts (memes)Most marketers try what worked for them before, or what they heard worked elsewhere. They either get lucky, or they get it wrong. Natural selection happens over millennia: but you can cheat \u2013 systematically test your way to a winning combination of memes.The good news: although a lot has changed, our brains still operate the same as they did in the Stone Age, implying the list of dominant memes is finite, and it\u2019s possible to learn them all. For that you need a system \u2013 use mine and save yourself 10 years and $50m.Here\u2019s how it works: 1) collect a swipefile of campaigns, 2) break them down into their memes, 3) identify what patterns work best, 4) always be testing new combinations. In short: do more of what works, less of what doesn\u2019t... simple, but not easy.In memetics terms, a successful brand is a \u201cmemeplex\u201d \u2013 a collection of memes that have evolved into a symbiotic relationship. The competitors in your space have (intentionally or accidentally) found a combination of memes that successfully replicate in customer\u2019s minds.You need to learn what works, then choose where you\u2019ll differentiate. Customers are already conditioned to expect certain memes in a category, so you can\u2019t innovate on everything. Instead the goal is to find a handful of distinctive, memorable assets that you can own."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '1) Swipefile' for the blog post 'Marketing Memetics'"}, {"role": "assistant", "content": "Collect examples of competitor campaigns, and save them centrally to a folder. The larger the swipefile you build, the better you will be able to spot patterns in the designs, writing and placements used. Include campaigns from other industries you think might work in yours."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '2) Memes' for the blog post 'Marketing Memetics'"}, {"role": "assistant", "content": "Review the assets in your Swipefile and break each down to its component parts. Tag any creative, copy and targeting tactics that you identify. Build a reference dictionary of these tags so you can collaborate with your team to correctly categorize campaigns.\u00a0"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '3) Patterns' for the blog post 'Marketing Memetics'"}, {"role": "assistant", "content": "https://www.theatlantic.com/technology/archive/2014/01/how-netflix-reverse-engineered-hollywood/282679/Like genes, successful memes replicate \u2013 are any patterns showing up consistently over time or across the industry? Formalize the definitions and categories of the tactics you\u2019re seeing. Quantify which memes are more popular than others."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '4) Testing' for the blog post 'Marketing Memetics'"}, {"role": "assistant", "content": "https://mobiledevmemo.com/mobile-ad-creative-how-to-produce-test-and-deploy-advertising-creative-at-scale/Develop a testing strategy from your analysis of what memes are working. What memes will you copy to meet expectations, and where will you differentiate to win? Systematically test memes going from high-level concepts, down to smaller variations on successful themes."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Modern Memetics' for the blog post 'Marketing Memetics'"}, {"role": "assistant", "content": "None of this is new! Roll back to the 1960s and you\u2019d find Marketers keeping \u2018Swipefiles\u2019 of successful campaigns, studying trends in popular culture with Semiotics, and Ogilvy saying \u201cNever stop testing, and your advertising will never stop improving\u201d.What\u2019s new is our ability to collect, analyze and categorize campaign data at scale. Advances in machine learning let us automate identifying creative memes, and we can test new ideas with instant feedback on digital channels, and eventually in VR.Download every competitor campaign with Web scraping and APIs. Automatically tag assets with OCR, image recognition and NLP. Identify patterns then systematically test and learn what works. Good luck: brain space is limited and there\u2019s a war for attention.\u201cWho controls the memes,controls the Universe\u201d\u200d- Elon Musk, Twitter"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'What is the Woke Mind Virus?' for the blog post 'Practical Tips for Defeating the Woke Mind Virus'"}, {"role": "assistant", "content": "The man who made reusable rockets, electric cars, and brain-computer interfaces happen, and is supposed to be taking us to Mars, has a new overriding concern. The woke \u2018mind virus\u2019.https://twitter.com/elonmusk/status/1602278477234728960?s=20&t=i0ZISrSkqP9G3hz3avQ5lgI was interested to see such a public reference to \u2018mind viruses\u2019, because it\u2019s central to the topic of my book: \u201cMarketing Memetics\u201d. Most people won\u2019t get the reference, and almost certainly won\u2019t know that memetic engineering gives us tools for dealing with the problem. I thought I\u2019d write an explainer post that gives a high level overview.The term \u2018woke\u2019 was originally a left-wing compliment, and has now turned into a right-wing insult. It simply means being aware of and actively attentive to important societal facts and issues (especially issues of racial and social justice), which in and of itself, is a good thing.The anti-woke movement began as a response to \u2018cancel culture\u2019, where social pressure has been used to ostracize perceived violators of left-leaning orthodoxy. The concern from free-speech absolutists like Musk, is that mob rule on social media is a form of censorship, disproportionately enforcing leftist political viewpoints and banning valid discussion. This may be a slippery slope towards a dystopian future, where independent thought is illegal. Musk laments that wokeness is \"at its heart, divisive, exclusionary, and hateful\".Depending on where you fall on the issue, cancel culture can be construed as valid criticism of those who have spoken or acted in an unacceptable manner, or as cynical virtue-signalling to increase one\u2019s social status, at great risk to free society. For the purposes of this article we\u2019ll assume the latter, but the methods we discuss are morally neutral.The reference to a \u2018mind virus\u2019 is likely from Neal Stephenson\u2019s \u201cSnow Crash\u201d, which featured a literal mind virus \u2013 a drug, religion and computer virus all in one \u2013 \u201dWhat\u2019s the difference?\u201d asks one of the characters.In the influential 1992 cyberpunk sci-fi novel \u2013 which also gave us Avatars, Google Earth, and the Metaverse \u2013 the central premise is that ideas are \u2018viruses of the mind\u2019, that can infect our brains and affect our behavior, causing us to act against our self-interest. This idea dates back to evolutionary biologist Richard Dawkins, who coined the term \u2018meme\u2019 as an analogy to biological genes. He was describing the way ideas, behaviors, or styles evolve through natural selection.\u201cJust as genes propagate themselves in the gene pool by leaping from body to body via sperms or eggs, so memes propagate themselves in the meme pool by leaping from brain to brain.\u201d\u2013 Richard Dawkins, The Selfish Gene, 1976Dawkins' work became the foundation of the field of Memetics. If ideas evolve like genes, perhaps we can direct their evolution to our benefit, like we do in genetics. The study of Memetics is still more \u2018pseudo-\u2019\u00a0 than science, as there is no generally accepted way to measure where a meme begins and ends, which limits progress.\u00a0Memetics is missing its Gregor Mendel, the 19th century monk who meticulously crossbred 29,000 pea plants to establish the gene as the unit of heredity. It also lacks a Fischer character to formalize the mathematics, and has yet to find its version of Watson and Crick, who discovered the underlying structure of genetics in DNA. Perhaps with advancements in Artificial Intelligence, Neuroimaging, and Brain-Computer Interfaces we\u2019ll get there soon.In the meantime, fringe internet commentators have reportedly used memetic engineering to great effect; claiming victories such as the GameStop short squeeze, the proliferation of Q-Anon, and the election of Donald Trump. We know the U.S. Military has studied Memetics, Taiwan is using memetic engineering to stop disinformation, and we can see evidence of memetic tactics\u00a0 deployed by both sides of the Ukraine-Russia war.Furthermore, it may provide the solution to Elon\u2019s issue, which he calls one of the biggest threats to the existence of humanity. These tools we\u2019re about to discuss are general purpose, and can be adapted and used to counter any \u2018mind-virus\u2019: though the morality of what constitutes a \u2018toxic\u2019 meme versus a beneficial one, is up to you.\u201cWho controls the memes,controls the Universe\u201d\u2013 Elon Musk"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Memetic Engineering' for the blog post 'Practical Tips for Defeating the Woke Mind Virus'"}, {"role": "assistant", "content": "In Internet discussion forums in the early 90s, Mike Godwin saw debates frequently getting out of hand. Potentially fruitful conversations about difficult topics would escalate until predictably, someone made a comparison to the Nazis. Claiming the other side\u2019s ideas were \u2018Nazi-like\u2019 or saying they were \u201cjust like Hitler\u201d ruined any hope for productive dialogue. So he decided to do something about it: in the first noted use of memetic engineering, he created the first \u2018counter-meme\u2019.\u00a0Godwin\u2019s law stated \u201cas an online discussion grows longer, the probability of a comparison involving Nazis or Hitler approaches one\u201d. He seeded this law in discussions to show participants they were \u201cacting as vectors to a particularly silly and offensive meme\u201d. It worked: others started repeating the meme and mutating it, and comparing someone to a Nazi in an online discussion now acts more to weaken your own position, than that of your intended target.Godwin\u2019s counter-meme spread because it was memorable: it\u2019s easy to recall, and when you\u2019re familiar with the concept, you see it everywhere. Just like viruses die out if they fail to infect enough people, memes only persist if they\u2019re remembered long enough, and shared with others. Memes have different strategies for doing this: \u2018catchy\u2019 songs get stuck in your head, funny stories get told at dinner parties, useful information gets written down in books. Quoting Godwin made people feel smart, and helped them win arguments, so it continues to be remembered.What made it effective was its sense of humor. It\u2019s suggested that humor evolved to help us break free of rigid classifications, by testing boundaries and playing with social norms. Calling someone a Nazi works to shut down discussion because Nazi-ism is taboo. In daring to poke fun at those who mis-use that label, Godwin gives us a cathartic release, stealing away the power of the accuser."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'The Vaccine for Memes' for the blog post 'Practical Tips for Defeating the Woke Mind Virus'"}, {"role": "assistant", "content": "In studying the spread of misinformation, researchers have indeed found methods that echo Godwin\u2019s methods, to be an effective way to inoculate people against fake news. In medical vaccines, a virus is weakened so it doesn\u2019t make you sick, but will trigger antibodies to fight future infections. Meme vaccines work the same way, inoculating people against misinformation. Forewarned is forearmed: studies show that being warned that someone will intentionally try to mislead you on a topic, and being presented facts and arguments to \u201cpre-bunk\u201d the misinformation, has been proven to diminish the effects of malicious memes.Prevention is better than cure: once someone is exposed, debunking has little effect, and fact-checking spreads slower on social media than misinformation. The same actions you\u2019d take to protect the public from a pandemic are effective against mind viruses too: quarantine those spreading the virus (social media ban), protect the most vulnerable (public education), and treat the infected (mental health support). Be careful with this technique: one of the \u2018conspiracy theories\u2019 the study successfully inoculated people against \u2013 the \u201clab leak hypothesis\u201d \u2013 later became a more generally accepted theory."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Fighting Smoke with Fire' for the blog post 'Practical Tips for Defeating the Woke Mind Virus'"}, {"role": "assistant", "content": "We\u2019re social animals, and we\u2019re prone to gossip. It helps us enforce social norms and punish indiscretions by ostracizing victims, as well as signaling commitment to the in-group. To our prehistoric ancestors being expelled from our tribe was as good as a death sentence, and biologically we still react as if that\u2019s at risk of happening. Shame is what keeps us in line, and the scapegoat mechanism provides an outlet for social tensions. When this machinery goes haywire and selects the wrong victim, it can cause real-world harm.To make good gossip that spreads virally, you need a plausible story which is distorted in 3 directions. The story must be leveled of important details, because we have more capacity to believe if there\u2019s no easy way to verify. The remaining details in the story must then be sharpened \u2013 made more specific \u2013 to make it memorable or the rumor won\u2019t be passed on. Finally the rumor must be assimilated into the group: adapted to make sense to those spreading the story.\u00a0To dispel a maladapted meme, you need to put this mechanism into reverse. First, realize that it\u2019s no use denying the rumor: receiving contradictory evidence only serves to strengthen beliefs, and everybody suspects there's no smoke without fire. Instead you must offer a new, better story in return: give them fire in place of smoke. Confess to the \u2018real\u2019 story, with enough embarrassing details to make it credible. Catharsis relieves the burden of repressing taboo topics, and gives the crowd something new to discuss. Inject too many details into the new story, to take all the fun out of it: it\u2019ll fizzle out instead of becoming something new to dispel."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'The Social Benefits of Bad Beliefs' for the blog post 'Practical Tips for Defeating the Woke Mind Virus'"}, {"role": "assistant", "content": "Whenever you find people believing something unlikely or unusual, there are usually group social dynamics at play. If some group has adopted you as their target, the attacks won\u2019t stop until the group is disbanded or they pick a new target. The first and best strategy is Aposematism: signaling that it\u2019ll be unprofitable to attack you. Frogs do this with bright colors signaling their toxins, and honey badgers do it with their aggressive behavior. One strategy on social media is \u2018shit posting\u2019 \u2013 deliberatively being provocative \u2013 which tells opposing groups you can take it.If that doesn\u2019t work, because you\u2019re too juicy a target, you have to hit back at the group itself. We are predominately preoccupied with identifying how our beliefs will be interpreted by others, rather than examining if they\u2019re true. In fact the more the belief differs from our model of reality, the more important it becomes to group cohesion, because it becomes a costly signifier that you\u2019re \u201cone of us\u201d. We likely wouldn\u2019t believe these things in isolation, but maintaining good relations with your spouse, family, tribe, church, military unit, political party, or workplace can easily outweigh other considerations. The key insight is that everyone is part of multiple tribes: if being a member of one tribe starts hurting your status in another, there will be a tipping point where you\u2019d start to distance yourself from them.We\u2019ve already established that providing evidence to counter beliefs is a losing strategy, so do the opposite. People who argue against your belief are not in your tribe, and therefore can be safely ignored. What can't be ignored is someone agreeing in a way that\u2019s embarrassing, or taking things further than you wanted. They make you look bad by association, to the other tribes you\u2019re part of. Every group has a tiny minority of fundamentalists, and by moving towards their position, rather than away, it\u2019ll force them to a more radical higher ground. You may succeed in knocking them out of the Overton window \u2013 the range of policies politically acceptable to the mainstream population \u2013 into a no-man\u2019s land that devastates group retention and recruitment."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Evolutionary Design Thinking' for the blog post 'Practical Tips for Defeating the Woke Mind Virus'"}, {"role": "assistant", "content": "For evolution to arise in a system, you need just 3 things: replication, variation, and selection. In any system where traits can be inherited (directly or through imitation), more agents are produced than are able to survive, and agents with more favorable traits stand a higher chance of survival, you\u2019ll get natural selection. Any such system, given enough time, will produce agents that are extremely well optimized for their environment. If we don\u2019t take this into account, it\u2019s easy to accidentally design a system in a way that creates monsters.Say you run a social network, and you have a bot problem. Intuitively you may think it makes sense to enact a penalty for anyone who breaks the rules. However you just unknowingly introduced selection pressure to your system. The barrier to entry will give malicious agents a lucrative puzzle to solve. They\u2019ll explore questions like \u201cWhat bots don\u2019t get detected?\u201d, \u201cIn what conditions are the risks of a penalty tolerable?\u201d. Given enough time, a \u201cgenius corrupter\u201d will emerge: what Bret Weinstein calls an entity that has evolved to test the limits of a system without getting caught. In extreme cases an agent may corrupt the system itself, hijacking the enforcement mechanism for its own benefit. Rather than solve the bot problem, you\u2019ve only made them stronger. You can find the solution by reversing the famous phrase \u201cwhat doesn\u2019t kill me, makes me stronger\u201d. Going nuclear on bad behavior makes it no longer worth it to play the game. The evolutionary process grinds to a halt, because every attempt goes extinct.\u00a0Another protection against corruption is decentralization: if you need 51% approval for a bad idea to pass, you\u2019re subject to the tyranny of a small majority. However in a decentralized system, bad ideas are unevenly distributed \u2013 some groups might be 80% sold on a bad idea, others only 20% \u2013 there will be safe enclaves where the bad idea couldn\u2019t reach a majority. When the inevitable consequences arrive, everyone can jump ship to the group that got it right. More of the problem space is explored collectively, by everyone making decisions in their self interest individually, building redundancy against bad decisions."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Conclusion' for the blog post 'Practical Tips for Defeating the Woke Mind Virus'"}, {"role": "assistant", "content": "Most people are aware of the term meme, but are unaware of its broader pre-internet definition. Bad actors are already using memetic engineering against us, and studies show that warning you about this ahead of time will help inoculate you against its effects. Whatever you think about Elon Musk and his anti-woke crusade, and whether you\u2019re left or right leaning, studying memetics can help level the playing field. If only one side of an argument is using these techniques, we\u2019re unlikely to make the necessary trade-offs to arrive collectively at the right answer. If you\u2019re interested in learning more about memetics, you can read essays from my book at marketingmemetics.com."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Watch the Video' for the blog post 'Marketing Mix Modeling: What\u2019s the difference between a $500, $5,000 and a $50,000+ Project?'"}, {"role": "assistant", "content": "The number one question I get when talking to people about Marketing Mix Modeling (as the Founder of Vexpower.com), is \u201cwhat does the actual output look like?\u201d.\u00a0I never like to say \u201cit depends\u201d, so I\u2019ve taken to giving people a whirlwind tour of what the output looks like at each budget level \u2013 I\u2019m publishing it now, so I can just point people here when I next get that question.In modeling the currency is \u2018accuracy\u2019: a simple model done with Excel in an afternoon could get you 60% or 70% of the way there, but who can risk being 40% off target? In the Fortune 500 you might employ a team of 4 people for 6 months once a year, to build a more accurate model that you can use for annual budget planning.Putting more hours (and ultimately money) into MMM can get you closer, as well as give you unique insights into the mechanics of your business, but is it worth the extra investment? What is appropriate to spend for your business? And how do you know it\u2019ll work?So how much does a Marketing Mix Model cost? I usually break it down into 3 price points, $500, $5,000 and $50,000+. Let\u2019s see what each model might look like, and along the way I\u2019ll tell you what you get for your money.I put together a short video that explains how this works, with additional information not covered in the blog post below. I recommend watching the video first then continuing with the post."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'The $500 Model' for the blog post 'Marketing Mix Modeling: What\u2019s the difference between a $500, $5,000 and a $50,000+ Project?'"}, {"role": "assistant", "content": "If you\u2019ve got someone on your team who has a spare afternoon and is decent with Excel / GSheets, you can build a reasonable Marketing Mix Model to help you make a decision.Of course if you say that to a statistician they\u2019ll recoil in horror, but you don\u2019t go to a chemist for cooking advice \u2013 we\u2019re running a business not a laboratory and there\u2019s a big difference between theory and practice.You can do a surprising amount in spreadsheets, from measuring the halo effect of ads, to determining the impact of word of mouth and forecasting your diminishing returns at scale, and it\u2019s not uncommon for me to build simple ~10 variable models that predict sales to 60-80% accuracy.Given the simplicity, speed and low cost, even if you are planning to work with a more sophisticated solution, I recommend starting with an Excel model so you can play around and understand the mechanics of what\u2019s going on. It can only help.Use this template and read my post on econometrics in gsheets to get started."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'The $5,000 Model' for the blog post 'Marketing Mix Modeling: What\u2019s the difference between a $500, $5,000 and a $50,000+ Project?'"}, {"role": "assistant", "content": "If you\u2019re not building a model yourself, you\u2019re going to be hard-pressed to find anyone who will build you a model for less than a few thousand dollars. For a serious practitioner it might be closer to $10k, depending on the complexity.Modeling experts are in high demand, because they can usually earn a lot more in the Finance industry (some of us do it for the love of marketing, or because we graduated in 2009 at the peak of the Great Recession, and there were no jobs in finance so we stumbled into a marketing career\u2026)You need someone who can gather data from multiple stakeholders, get it into the right format (collecting and cleaning data is 80% of the job!), build complex statistical models and then present it back in a way that business executives can understand\u2026 know many people like that? Didn\u2019t think so.It\u2019s usually not economical to hire someone to do MMM full time, but it\u2019s perfectly viable as a task to give to your data science team. They might not be fully up on all the older statistical techniques, so it might take some light reading to round out their knowledge.Code takes longer up front, but once you have your data cleaned and scripts written you can run it again and again as much as you like. In fact, it\u2019s common practice to run thousands of potential model combinations (which can take anything from a few minutes to a couple hours) and automatically return the most accurate result.If you\u2019re going down this path, check out my Python scripts, or Facebook\u2019s open source \u2018Robyn\u2019 scripts in R, or contact me as I take on the occasional project."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'The $50,000 Model' for the blog post 'Marketing Mix Modeling: What\u2019s the difference between a $500, $5,000 and a $50,000+ Project?'"}, {"role": "assistant", "content": "What\u2019s the difference between a $5k model and a $50k model? Well to be honest the output usually looks about the same! Sure the model will be more accurate (or at least less likely to be wrong). But the general rule is that companies that can afford it, tend to get charged more \u2013 the joys of enterprise pricing.\u00a0If you\u2019re spending $100m a year on marketing, $100k is just 0.1% of your spend, and if it helps you optimize your spend even a little it can easily be worth it. However for someone spending $1m a year you can\u2019t afford to blow a whole month\u2019s budget on attribution! Even if your model is amazing and took $100k+ of work, only big companies can justify that cost.Bigger businesses are often more complex, so there definitely is an increased workload between $5k and $50k projects, but it\u2019s not 10x more work. The majority of the increase in cost is explained by admin \u2013 it\u2019s just far more expensive to sell to and work with the Fortune 500, so every vendor that works with them bumps up their price to accommodate.For example I once worked with a Fortune 500 client who took 8 months to sign off on a 3 month project, and then took 18 months to pay us. I counted 57 meetings total. You can bet I charged more the next time we landed an enterprise client.There is one interesting difference with the work: marketing tends to be a much weaker effect for larger, more established businesses. Startups that aren\u2019t well known yet can just switch on Facebook ads and immediately see a spike: you don\u2019t even need a model to tell you it\u2019s working. When you\u2019re Coca Cola or Nike people buy you for their long term exposure to your brand, not because of anything you did in marketing this year.If you want to see an example of how MMM presentations usually look, you can check out module 4 of the vexpower.com MMM training simulator (free)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Participation Rate' for the blog post 'Modeling Viral Growth'"}, {"role": "assistant", "content": "When you're growing virally or planning to, one of the hardest things to get right is forecasting into the future. Of course everyone expects to grow exponentially with a Viral Coefficient of more than 1, but that's rarely realistic.Even if you do achieve a strong viral growth rate early on, you can't expect to extrapolate out that same growth rate indefinitely \u2014 eventually you'll saturate your audience. Before you can forecast growth, you need to understand how virality works, or your model is worthless. So how do you build a model that works?First let's go through each metric you need, and roll everything together at the end into a working model like the one above. We'll be using the example of a social network where upon signing up you invite your friends. For the purposes of this exercise, we'll be using the example from our post on Viral Growth Loops.How many new users invite friends or colleagues to sign up? Note this is not how many people do they get to sign up (that's next), it's how many participate in sending invitations at all.If 75% of users participate in sharing with friends and we have 100 new users, then 100 x 0.75 = 75 of them will invite friends."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Branching Factor' for the blog post 'Modeling Viral Growth'"}, {"role": "assistant", "content": "When a new user invites friends and colleagues, how many invites do they send on average? For Facebook it was 7 friends in 10 days, but the average will be different for each business.If every user that participates in sharing, invites 7 people on average, with 75 people inviting friends, then 75 x 7 = 525 people will receive invites."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Clickthrough Rate' for the blog post 'Modeling Viral Growth'"}, {"role": "assistant", "content": "How many people click through to the website or app after receiving an invitation? This number is governed by both how compelling the value proposition is, and if they trust the sender.If we assume a 50% clickthrough rate, for 525 invites, we'll generate 525 x 0.5 = 263 clicks, or new visitors."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Conversion Rate' for the blog post 'Modeling Viral Growth'"}, {"role": "assistant", "content": "What percentage of new visitors to your website or app do you convert to new users? This can be optimized by removing friction or increasing motivation to sign up.If we take a 40% conversion rate for our social network, from the 263 new visitors we drove through invites, we would expect to sign up 263 x 0.4 = 105 new users."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Viral Coefficient' for the blog post 'Modeling Viral Growth'"}, {"role": "assistant", "content": "The primary measure of virality, also called K-Factor (or in epidemiology, R0 or R-naught). This is a measure of how many new users you get through sharing, for every new user you acquire.You can calculate this metric by multiplying all previous metrics. So in our model 0.75 x 7 x 0.5 x 0.4 = 1.05 is our viral coefficient."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Modeling Viral Coefficient' for the blog post 'Modeling Viral Growth'"}, {"role": "assistant", "content": "To model the viral coefficient or K-Factor, we just need to multiply each step together in Excel or GSheets. This should give us a spreadsheet like this:Now we have the number of users after one cycle (viral coefficient x new users), we need to be able to predict the number of users at any cycle in the future.The formula is initial users x (viral coefficient ^ (cycle + 1) - 1) / (viral coefficient - 1). So for our viral coefficient of 1.05, to see 10 cycles into the future this would work out to be 100 x (1.05 ^ (10 + 1) - 1) / (viral coefficient - 1) = 1421 total users. We can model it out like so:Once you have the virality cycles modeled out, you're most of the way there. You just need two more assumptions to make a working model \u2014 cycle time and carrying capacity."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Cycle Time' for the blog post 'Modeling Viral Growth'"}, {"role": "assistant", "content": "We've dictated that new users invite 7 friends, but we didn't specify how long it takes them \u2014 this is the cycle time. \u00a0For Facebook it was 7 friends in 10 days, so we'll use that.Once we have the cycle time, we can plug that into our model to estimate the number of users in any given date in the future, which makes the model far easier to understand.The model now takes the cycle time and translates it into dates, by working out the Total Cycles by that point in time. This let's us forecast out by 12 months and see how many users we'd have."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Carrying Capacity' for the blog post 'Modeling Viral Growth'"}, {"role": "assistant", "content": "Viral growth can't go on indefinitely \u2014 if you keep extrapolating the function out ten years and you'll have signed up 112 billion users... which is more people than have ever lived. As your product gains more users, there are less people to convert.For example Facebook has signed up the majority of North America by now, so new users have less people to invite, and the people they invite are less likely to accept, because they're already on the platform or not interested.To account for this into the model, we use carrying capacity, which is simply the size of the audience that could use your product. With a large carrying capacity the impact of saturation won't be felt, but with a limited audience your viral coefficient will quickly fall below 1.To work this into our calculations, we assume that for every percentage of saturation that occurs, your initial viral coefficient drops by the same amount. So if you've signed up 10% of your audience, you need to decrease your viral coefficient by 10% \u2014 if you're 90% saturated, viral coefficient needs to come down by 90%.Let's choose a relatively small audience of 20,000 to see how it impacts the model.Now we have a realistic model that starts with the famous 'hockey stick' growth curve, and flattens out. When plotted visually this will form an S-shape or sigmoid, which tells us we're on the right track \u2014 you see the same curve in everything from the adoption of new technology to the spread of an actual virus."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Get the full model' for the blog post 'Modeling Viral Growth'"}, {"role": "assistant", "content": "To see all of the assumptions we made, and make changes to the model for yourself, you can find the full thing here:https://docs.google.com/spreadsheets/d/1hgQs-wDXk2tOHAwaP47r4rytCtH_NXtpUesDNpIoMBU/edit#gid=0For reference, this model was built using a combination of factors from Andrew Chen's \"Facebook viral marketing: When and why do apps \u201cjump the shark?\u201d and David Skok's Startup Lessons Learned: Viral Marketing. I highly recommend you check these out if you're interested in the topic.\u200d"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'The unreasonable effectiveness of micro-targeting' for the blog post 'No More Microtargeting'"}, {"role": "assistant", "content": "Micro-targeting is the practice of running tailored ads to niche audiences at scale, using unique information about each group to increase the effectiveness of your ads.For example if I have 10,000 people on my website browsing an inventory of 100 unique products, I can automatically generate a unique ad for every single individual person, and measure what they purchase after seeing or clicking on an ad.Everything you buy feeds back into prediction models, which also use 1,000s of other variables like what pages you viewed online, the contents of your social posts, chat messages and emails, the location of your phone\u2026 everything you do online is used to show you ads.\"The best minds of my generation are thinking about how to make people click ads\"- Jeffrey Hammerbacker, Early Facebook EmployeeMicro-targeting is so effective it became a \u2018threat to democracy\u2019, responsible for getting Trump elected, russian hacking and the Brexit vote. It\u2019s possible with this method to predict you\u2019re pregnant (before your parents know), know if you\u2019re falling in love and predicting your personality traits better than friends and family.Two of the most valuable companies in the history of the World, Google and Facebook, with a combined $1.7 trillion market cap, owe their 70% market share to this technology, which they provide freely to advertisers. Beginner-level developers are able to use off-the-shelf, open-source algorithms to implement the basics of this technique \u2014 you can even replicate it in Microsoft Excel.\u201cI was able to go from not doing machine learning to knowing what I need to know in one week. That\u2019s all it took.\u201d\u200d- Aleksandr Kogan, Cambridge Analytica researcher"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'The surveillance economy is unravelling' for the blog post 'No More Microtargeting'"}, {"role": "assistant", "content": "Micro-targeting is under threat \u2014 as part of the fallout of the above listed scandals, wide reaching consumer privacy protections have been enacted, such as GDPR in Europe and CCPA in California. This has made data collection far harder, and riskier.Consumers have been fighting back too \u2014 annoyed at \u2018creepy\u2019 ads and worried about the implications of surveillance capitalism, there has been a backlash against targeted ads. About 1/3rd of the internet use AdBlockers and companies are starting to take notice.Apple, one of the few tech companies that doesn\u2019t rely on targeted advertising revenue, has made moves to ban 3rd-party cookies (used for tracking user behavior) from Safari, and is killing the IDFA, the unique identifier that let\u2019s advertisers track behavior across mobile apps. Even Google plans to kill 3rd-party cookies in Chrome.The impact of this privacy backlash is predicted to be catastrophic \u2014 untracked ads are worth so little Facebook doesn\u2019t even show app install ads to the 30% of US iPhone users who have already opted out of IDFA. Google conducted a study that found a 52% drop in revenue from removing cookie tracking. The ICO found that they lost the ability to track 90% of users when implementing their own best practice consent form for GDPR compliance.\u00a0\u201cHe\u2019s making a listHe\u2019s checking it twiceHe\u2019s gonna find out who\u2019s naughty or niceSanta Claus is in contravention of article 4 of the General Data Protection Regulation (EU) 2016/679\u201d-\u00a0joe (@mutablejoe) May 20, 2018"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Advertising doesn\u2019t work that way' for the blog post 'No More Microtargeting'"}, {"role": "assistant", "content": "There will be winners and losers from this massive shift in technology and behavior, but marketing will be broadly fine. Before the rise of the internet and micro-targeting, you bought advertising on TV, the radio or in the newspaper. Guess what \u2014 from then to now, despite all the changes, advertising has continued to be a stable 1% of GDP since the 1920s.That\u2019s because advertising works primarily by building long term brands and reinforcing memory structures. If you\u2019re walking down the grocery aisle, and you recognize one brand over another, making you slightly more likely to pick it up and buy it, the marketers did their job.\u00a0Despite common objections, we don\u2019t buy brands because we\u2019re brainwashed into a decision we didn\u2019t want to make. Instead we typically care very little about the brands we buy, and by eliminating other choices the decision is made easier, helping us move on with our lives.\u00a0Advertising does it\u2019s best work in public, via cultural imprinting where costly signalling indicates that a product is reliable (otherwise how could they afford to invest in ads?). This is the same mechanism as how a peacock finds a mate it\u2019s ability to divert resources to growing elaborate feathers is an impossible to fake signal that it\u2019s healthy.\u201cA flower is a weed with an advertising budget.\u201d\u200d- Rory Sutherland, Ogilvy"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Does micro-targeting actually work?\u00a0' for the blog post 'No More Microtargeting'"}, {"role": "assistant", "content": "Big advertisers like P&G, Mars and Unilever have all started to reduce reliance on targeting online ads and shift back to traditional methods and measurement methods like Econometrics, where performance can be independently attributed without reliance on potentially biased measurements coming from Facebook and Google themselves. Even performance marketers are following suit, with even famously data-driven Zynga shifting strategies to broad audience targeting rather than pursuing a handful of \u2018whales\u2019 or high spenders.\u00a0There are challenges to claims that Cambridge Analytica\u2019s methods even worked, and only ~30% of conversions claimed by retargeting ads are incremental (i.e, wouldn\u2019t have happened anyway, had you not run the ad). Despite seemingly better measurement methods compared to traditional channels like TV, online attribution methods can be gamed. Facebook claims all conversions that happen within 28 days of an ad being clicked and 24 hours of it being shown \u2014 show an ad to everyone in the World and Facebook will implausibly claim to be responsible for 100% of your sales. When 56% of display ads aren\u2019t even seen by a human, keeping micro-targeting looks less important.I\u2019m very sure there is a lot of real effectiveness in these methods \u2014 I\u2019ve personally worked with hundreds of small startups who owe at least some of their growth to methods like these. I\u2019ve seen major quantitative differences in the cost per acquisition between Facebook\u2019s ad platform and it\u2019s less advanced rivals. Despite issues with incrementality, even by the strictest attribution models, retargeting often performs. Despite my economics background, in the past 10 years I've found myself shifting focus away from targeting and optimization towards creative testing. On clients I\u00a0typically get results not by micro-targeting, but by regularly testing hundreds of ad variations until I find one that works. When I do find the best performing ad for a niche audience, it usually turns out to be the best ad for every audience I add it to.The truth is that by far the biggest impact on performance in my experience is creative testing \u2014 creative quality is the biggest factor responsible for 49% of campaign performance compared to just 9% for targeting. There I think lies the culprit \u2014 the performance marketers who were doing micro-targeting were also simultaneously running thousands of creative variations, which may have been what boosted performance.\u201cObviously, it is not big data analytics that wins the election,\u201d he wrote back. \u201cCandidates do. We don\u2019t know how much his victory was helped by big data analytics.\u201d- Michal Kosinski, a Stanford professor"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Marketing is going back to broadcast\u00a0' for the blog post 'No More Microtargeting'"}, {"role": "assistant", "content": "Contextual targeting, which is showing ads based on the context of where they\u2019re placed (rather than the behavior of the user, never really went away, but is now due for a rise in prominence. If we take the average CPM on Google Search (where ads are placed based on what keyword the user searched for), vs Facebook Ads (primarily based on micro-targeting), the CPMs (how much it costs to show 1,000 ads) are still almost double \u2014 $22.94 on Google vs $12.79 on Facebook. So it\u2019s clearly possible that what the user is doing right now (searching for a product) can be worth more than who the user is (demographics, behavioral).\u00a0With the onset of GDPR, the main Dutch public broadcaster dropped personalized ads altogether and saw revenue go up! They built their own ad server for contextual ads, cutting out the more than 50% of ad revenue that goes to the middlemen. Contrary to Google\u2019s findings on the topic, an independent study found that removing cookies only decreased publisher revenue by 4%.\u00a0Buying digital ads will start to resemble how TV ads are bought \u2014 against content that\u2019s most relevant to their products. Shoe brands advertising on sports sites; fitness apps during Youtube workout videos; and airlines on travel blogs. Data-hungry marketers will migrate to subscription businesses, where enforced logging in will ensure users opt into tracking. Some marketers will pivot away from paid ads all together, towards organic channels like Virality. Other marketers will compete on creative \u2014 like super bowl ads, segmentation will be done with the content of the ad, rather than the targeting of the placement. New innovations in AI will enable mass generation of creative ideas for large scale testing. If the right customer sees the right message at the right time, if the targeting fits with the content, and privacy is respected, ads have a chance to become more impactful than ever.\u201cFacebook now talks less about targeting, preferring to emphasize the sheer numbers of consumers that it can help brands to reach. It is investing in video capabilities and is encouraging its clients to make short films. After years of telling clients TV is wasteful, it is now doing a good job of imitating it.\u201d- Ian Leslie, Advertising Strategist\u200d"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Cookies' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": "I'm finding it becoming a recurring theme in my writing and consulting that there is a growing privacy backlash against the 'surveillance capitalism' that powers digital advertising. I'm finding it hard to track all the places I've seen this mentioned and I wanted one single place to link clients to that references everything important on the various related threads. Since that place didn't exist, I decided to create it! This post is broken up by major topic, and sorted in reverse chronological order (latest first). Tweet at me if you know of anything I should include: @hammer_mt"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'The use of third-party tracking cookies is going away in browsers.' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": "\"It would threaten to substantially disrupt much of the infrastructure of today's internet without providing any viable alternative, and it may choke off the economic oxygen from advertising that startups and emerging companies need to survive,\" \u2014 Marketing Dive, Jan 2020\"we plan to phase out support for third-party cookies in Chrome. Our intention is to do this within two years\" \u2014 Chromium Blog, Jan 2020\"we\u2019ve added so many restrictions to ITP since its initial release in 2017 that we are now at a place where most third-party cookies are already blocked in Safari\" \u2014 WebKit, Mar 2020\"We observedthat for the top 500 global publishers, average revenue in the treatment group decreased by 52%, with a1median per-publisher decline of 64%\" \u2014 Google, Aug 2019\"Firefox will now block thousands of web trackers by default, protecting users from many websites, analytics companies, and advertisers that want to follow their paths across the web. The change should speed up the browser and keep users\u2019 web habits more private, while nudging advertisers toward less invasive practices.\" \u2014 The Verge, Jun 2019\"Chrome\u2019s upcoming cross-site cookie clampdown and fight against fingerprinting will likely be felt by marketers to varying degrees. In some cases, the effects could be significant.\" \u2014 Econsultancy, May 2019"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'ITP' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": ""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Apple limiting the ability to track users within the Safari browser.' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": "\"Facebook Ads announced today it\u2019s retiring its 28-day attribution window option. After they do, the longest remaining attribution window will be their already-existing 7-day option.\" \u2014 Search Engine Journal, Sep 2020\"While many non-Apple browsers like Brave and Firefox already have built-in anti-tracking features, this new update also affects the world\u2019s most popular browser, Google\u2019s Chrome. While Apple is still working through some kinks that have allowed third-party cookies to work in some instances when the feature is switched on, all browsers on iOS and iPad OS will have ITP switched on by the end of the year.\" \u2014 Digiday, Sep 2020\"CPMs for Safari users have fallen off by around 60% since ITP was introduced in 2017, according to ad tech firm Index Exchange.\" \u2014 Digiday, Sep 2020\"Across all iOS and iPadOS browsers, the new setting \u201cAllow Cross-Website Tracking\u201d is toggled off. This means that all these browsers are now implementing the full scale of WebKit\u2019s Intelligent Tracking Prevention mechanisms.\" \u2014 Simo Ahava, Sept 2020\"Later this year \u2014 at a so-far unspecified date \u2014 Apple is also expected to put the kibosh on a technique some publishers and ad tech companies used as an ITP workaround. Called CNAME cloaking, the technique was a way for vendors such as Criteo and Adobe to get around Apple treating them as third-party trackers. Instead, those vendors are afforded more persistent cookies that aren\u2019t capped by ITP to a week.\" \u2014 Digiday, Sep 2020\"\u201cCookies for cross-site resources are now blocked by default across the board. This is a significant improvement for privacy since it removes any sense of exceptions or \u2018a little bit of cross-site tracking is allowed,\u2019\u201d Wilander notes in the announcement post on the blog for WebKit, which is Apple\u2019s in-house browser engine that powers many of its features under the hood.\" \u2014 The Verge, Mar 2020\"we\u2019ve concluded that the cumulative impact is a significant 8% loss of marketing attribution for Safari mobile searches\" \u2014 Econsultancy, Jan 2020\"One result: The cost of reaching Safari users has fallen over 60% in the past two years, according to data from ad tech firm Rubicon Project.\" \u2014 The Information, Dec 2019\"If Safari sees that a company that it classifies as a cross-site tracker has decorated the link that a person clicks to visit another website, then it will delete all the non-cookie-based website data for that website from the person\u2019s browser after seven days in which the person has continued to use Safari but not visited the site since clicking that link.\" \u2014 Digiday, Sep 2019\"Instead of decorating the link by attaching the ID data to the destination site\u2019s URL, some companies were decorating their own URLs that get passed to the destination site as a referrer. Apple has picked up on this and will only let the destination site access the top-level domain information when checking for the referrer data. That is, instead of the destination site being able to read the full URL \u201chttp://example.com?id=1234,\u201d the site will only receive \u201chttp://example.com.\u201d\" \u2014 Digiday, Sep 2019\"If Safari sees that a company that it classifies as a cross-site tracker has decorated the link that a person clicks to visit another website, then it will delete all the non-cookie-based website data for that website from the person\u2019s browser after seven days in which the person has continued to use Safari but not visited the site since clicking that link.\" \u2014 Digiday, Sep 2019\"We find that when a user\u2019s cookie is available publisher\u2019s revenue increases by only about 4%\" \u2014 Marotta, Abhishek, Acquisti, May 2019\"ITP 2.2 cuts the first-party cookie\u2019s lifespan from seven days to one day. As a result, the first-party cookies that Facebook and Google have introduced in order to continue measuring site traffic and attributing ads will be deleted after 24 hours. As a result, if a person clicks on an ad for a product on Friday and decides to take the weekend to think about buying, then the cookie wouldn\u2019t be around on Monday to register when the person returns directly to the site to buy the product.\" \u2013 Digiday, May 2019\"In previous filings we provided estimates of ITP\u2019s negative impact on Criteo\u2019s Revenueex-TAC: $1 million and $25 million in the fiscal quarters ending on September 30, 2017and December 31, 2017 respectively.\" \u2014 Criteo, Oct 2018"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'IDFA' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": ""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Apple is making users opt out by default from cross-app tracking.' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": "\"But DMG\u2019s Clarke says the move will hit his company, even if it\u2019s small compared to the giants. \u201cUntargeted ads are basically worthless,\u201d he says. Clarke says he thinks the revenue his company\u2019s iOS app users generate could drop by 75 percent, which could prompt him to abandon the app altogether and ask his readers to read the Daily Mail on the web instead.\" \u2014 \u00a0Recode, Sep 2020\"Notably, Facebook has declined to even show app install advertisements to the 30% of U.S. iPhone users that turned off their IDFA of their own accord \u2014 and now it is opt-in, instead of opt-out.\" \u2014 Stratechery, Aug 2020\"Facebook\u2019s own ad business will be mostly fine, since your profile and activity on its apps contain data way more useful than a simple device ID. But the company says that a lot of its advertising clients will suffer.\" \u2014 The Verge, Aug 2020\"Audience Network revenue could drop as much as 50%, the company said. Facebook is considering eliminating the service altogether for iOS 14 users.\" \u2014 Bloomberg, Aug 2020\"my sense was that most people believed that Facebook could find a way \u2014 using its sophisticated infrastructure and massive data set \u2014 to maintain the device-centric status quo on mobile. What Facebook\u2019s announcement last week reveals is that it can\u2019t: it is fully embracing the SKAdNetwork measurement framework and is excising the IDFA completely from its advertising machinery.\" \u2014 Mobile Dev Memo, Aug 2020\"if the person who installed that app eventually signs up for an account and takes a ride share, Lyft knows where and how to attribute the results of that marketing effort, and connect it to the ad spend that initiated it. Even better, from Lyft\u2019s perspective, it can use the IDFA to tell mobile ad networks essentially: I like users like this; go find me more. All of that is going away with iOS 14.\" \u2014 Forbes, Jun 2020\"Apps will basically have to:Disclose in detail what type of data collection goes on.Provide an opt-in mechanism to the collection of user and usage data.Not put up consent walls (allow the user to access content only if they give consent to tracking).Implement an opt-out mechanism as well, where if the user withdraws consent, their data should be purged.\" \u2014 Simo Ahava, Sept 2020"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'GDPR' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": ""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'The European privacy legislation limits the tracking of personal data.' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": "\"The ICO\u2019s Cookie Consent Rate Dropped 90 Percent After Implementing its Own Best Practices\" \u2014 Video Ad News, Nov 2019\u201cPersonal data shall be processed in a manner that ensures appropriate security of the personal data, including protection against unauthorised or unlawful processing and against accidental loss, destruction or damage, using appropriate technical or organisational measures (\u2018integrity and confidentiality\u2019).\u201d \u2014 Brave, Sep 2019\"\u201cPersonal data shall be processed lawfully, fairly and in a transparent manner in relation to the data subject (\u2018lawfulness, fairness and transparency\u2019); Personal data shall be collected for specified, explicit and legitimate purposes and not further processed in a manner that is incompatible with those purposes; further processing for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes shall, in accordance with Article 89(1), not be considered to be incompatible with the initial purposes (\u2018purpose limitation\u2019);\u201d \u2014 Brave, Sep 2019"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'CCPA' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": ""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'The California privacy legislation is similar to GDPR.' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": "\"These situations may arise from instances where their \u201cnon-encrypted or non-redacted personal information\u201d is breached, regardless of the harm done to the data. Under the CCPA, consumers can collect between $100 and $750 for each event.\" \u2014 Security Boulevard, Aug 2019"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Adblockers' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": ""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Users are fighting back by blocking ads on desktop and mobile.' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": "\"The average global adblocking rate in early 2018 was estimated at 27 percent.\" \u2014 Statista, Oct 2019\"The percentage of people who have switched Limit Ad Tracking (LAT) on has doubled on iPhone over the last four years in the United States.\" \u2014 Singular, Mar 2020"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Fraud' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": ""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'No attribution model is perfect, they can all be manipulated.' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": "\"Every common attribution model can be easily gamed.\" \u2014 Admend, Nov 2017"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Elections' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": ""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Examples of tracking having an impact on political elections.' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": "Facebook advertisements and targeting information gathered by Italian transparency group Openpolis found that the neo-fascist Brothers of Italy party ran a Facebook ad targeting Italian adults who are interested in the paramilitary police force, the carabinieri. \u2014 The Guardian, Mar 2019\"Surveillance capitalism\u2019s \u201cmeans of behavioral modification\u201d at scale erodes democracy from within because, without autonomy in action and in thought, we have little capacity for the moral judgment and critical thinking necessary for a democratic society.\" \u2014 Shoshana Zuboff, Mar 2019\"Cambridge Analytica, the data-driven analytics firm that specialized in psychographic profiling or \u201cPSYOPS,\u201d was hired by the Trump campaign in June of 2016 to lead its digital ops up to the November election and has boasted they have up to 5,000 data points on every adult in the US.\" \u2014 Towards Data Science, Oct 2018\u201cWe exploited Facebook to harvest millions of people\u2019s profiles. And built models to exploit what we knew about them and target their inner demons. That was the basis the entire company was built on.\u201d \u2014 The Guardian, Mar 2018\"The Russians were using the same techniques as some of the most successful startups in the world \u2013 tactics that I use every day and have done for a decade.\" \u2014 Wired, Mar 2018\"The Russians are also accused of working to suppress turnout among ethnic minority voters. They allegedly created an Instagram account posing as \u201cWoke Blacks\u201d and railed against the notion that African Americans should choose Clinton as \u201cthe lesser of two devils\u201d against Trump.\" \u2014 The Guardian, Feb 2018\"Parscale said the Trump campaign used Facebook to reach clusters of rural voters, such as \u201c15 people in the Florida Panhandle that I would never buy a TV commercial for\u201d. \u201cI started making ads that showed the bridge crumbling,\u201d he said. \u201cI can find the 1,500 people in one town that care about infrastructure. Now, that might be a voter that normally votes Democrat.\u201d\" \u2014 The Guardian, Oct 2017\"Canter explained how he used the AfD\u2019s 300,000 Facebook likes to target millions of other Germans who might be receptive to the party\u2019s message. \u201cWe took that 300,000, and Facebook created a model of them and used their lookalike audiences to find the closest 1 percent of German people to match that audience,\u201d he said. That process generated a new group of 310,000 people who were most similar to AfD fans.\" \u2014 Bloomberg, Sep 2017\"The office implemented the winning message in ~125 million leaflets and nearly a billion targeted digital adverts regardless of all complaints.\" \u2014 The Spectator, Jan 2017\"In the official 10 week campaign we served about one billion targeted digital adverts, mostly via Facebook and strongly weighted to the period around postal voting and the last 10 days of the campaign.\" \u2014 Dominic Cummings, Oct 2016\u200d\"The campaign was sending more than 100,000 uniquely tweaked ads to targeted voters each day. In the end, the richest person ever elected president, whose fundraising effort was rightly ridiculed at the beginning of the year, raised more than $250 million in four months--mostly from small donors.\" \u2014 Forbes, Nov 2016"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Brands' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": ""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Examples of companies moving away from targeted ads.' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": "\"The boycott, called #StopHateForProfit by the civil rights groups that organized it, urged companies to stop paying for ads on Facebook in July to protest the platform\u2019s handling of hate speech and misinformation. More than 1,000 advertisers publicly joined, out of a total pool of more than 9 million, while others quietly scaled back their spending.\" \u2014 New York Times, Aug 2020\"Rollic\u2019s method is to chase extremely low-cost CPIs by running user acquisition campaigns against broad, largely untargeted audiences. It\u2019s not unlike the age and demo targeting that advertisers do on traditional linear TV, said Bernard Kim, Zynga\u2019s president of publishing.\" \u2014 Ad Exchanger, Aug 2020\"In January 2020, when NPO switched from tracking-based targeting to contextual targeting, revenue increased 61 per cent more than January 2019. In February, revenue increased 76 per cent over the previous year,\" \u2014 The Register, Jul 2020\"Procter & Gamble Co. PG 0.45% , the biggest advertising spender in the world, will move away from ads on Facebook that target specific consumers, concluding that the practice has limited effectiveness.\" \u2014 Wall St Journal, Aug 2016"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Creepiness' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": ""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Examples of the creepy things people can find out about you with tracking.' for the blog post 'Privacy Backlash'"}, {"role": "assistant", "content": "\"Some 81% of the public say that the potential risks they face because of data collection by companies outweigh the benefits, and 66% say the same about government data collection.\" \u2014 Pew, Nov 2019\"Every time a person visits a website that uses RTB, data about them is broadcast to tens or hundreds of tracking companies, who let advertisers compete for the opportunity to show them an ad. The data can include the category of what they are reading \u2013 which can reveal their sexual orientation,[4] political views,[5] their religion,[6] and health conditions including AIDS,[7] STDs,[8] and depression.[9] It includes what the person is reading, watching, and listening to. It includes their location. And it includes unique, pseudonymous ID codes that are specific to that person,[10] so that all of this data can be tied to you, continually, over time.\" \u2014 Brave, Sep 2019\"Overall, a 2014 survey found that 91% of Americans \u201cagree\u201d or \u201cstrongly agree\u201d that people have lost control over how personal information is collected and used by all kinds of entities. Some 80% of social media users said they were concerned about advertisers and businesses accessing the data they share on social media platforms, and 64% said the government should do more to regulate advertisers.\" \u2014 Pew, Mar 2019\"Another survey last year found that just 9% of social media users were \u201cvery confident\u201d that social media companies would protect their data. About half of users were not at all or not too confident their data were in safe hands.\" \u2014 Pew, Mar 2019\"After plugins and plugin-provided information, we believe that the HTML5 Canvas is the single largest fingerprinting threat browsers face today. Studiesshow that the Canvas can provide an easy-access fingerprinting target: The adversary simply renders WebGL, font, and named color data to a Canvas element, extracts the image buffer, and computes a hash of that image data. Subtle differences in the video card, font packs, and even font and graphics library versions allow the adversary to produce a stable, simple, high-entropy fingerprint of a computer. In fact, the hash of the rendered image can be used almost identically to a tracking cookie by the web server.\" \u2014 Tor, Jun 2018\"Approximately 100 days before changing their status to \u201cIn a relationship,\u201c users are more likely to use the words \u201dlove,\u201c \u201csweet,\u201d and \u201dhappy\" in messages and publish something on the walls of their crushes \u2014 an average of 2 posts per 12 days. When publishing something, they tend toward positive news.\" \u2014 Brightside, Oct 2017\"We observe that the distribution of our fingerprint contains at least 18.1 bits of entropy, meaning that if we pick abrowser at random, at best we expect that only one in 286,777 otherbrowsers will share its fingerprint.\" \u2014 EFF, May 2010\u200d"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Example Task' for the blog post 'Prompt Optimization'"}, {"role": "assistant", "content": "For 99% of people, prompt engineering amounts to trying a few different prompts, manually reviewing the responses, and making changes until it seems like it's working.To be honest, that's probably good enough if the task isn't that important, or if you're not likely to revisit the task again. The problem starts when you start relying on that prompt to do your work, perhaps even putting it into production in a tool or template, without some sort of system for testing what works (or doesn't).This is a blind spot for AI engineers because they get excited by fine-tuning or evaluating different models, rather than writing better prompts. For example, did you know the default summarization prompt langchain uses under the hood is just \"`Write a concise summary of the following: <text>`\"? The Twitter gurus you see sharing ChatGPT templates all fail in the other direction, writing prompts as if they are some ancient wizard casting spells for conjuring up desired behavior from a malevolent AI.\u00a0https://www.digitaltrends.com/computing/what-is-dan-prompt-chatgpt/\u00a0This notion that AI is magic is harmful, because it implies these systems can\u2019t be controlled or aligned towards our goals. Imagine if we gave up on all of management science, economics, and psychology just because humans are unpredictable! The great benefit of working with artificial intelligence over human intelligence is that it\u2019s far easier to run experiments: they never get tired of hearing the same question 50 times, and retain no memory in between trials.True prompt engineering is scientifically testing and learning which inputs lead to useful or desired outputs, reliably at scale. It may be overkill for most throwaway tasks, but for prompts you plan to use hundreds or thousands of times, it's essential. The process looks like this:1. Metrics \u2013 Establish how you'll measure the performance of the responses from the AI.2. Hypothesis \u2013 Design one or more prompts that may work, based on the latest research.3. Testing \u2013 Generate responses for your different prompts against multiple test cases.4. Analysis \u2013 Evaluate the performance of your prompts and use them to inform the next test.If you're technical and you want to follow along in code, here's the notebook and text examples I used for this experiment: https://github.com/hammer-mt/prompt_optimization_blogBefore I started working full time on prompt engineering, much of my time was spent writing blogs on technical marketing topics. I noticed early on while experimenting with AI content writing, that ChatGPT\u2019s informative and inoffensive tone was easy to recognize, and therefore I spent a bunch of time figuring out\u00a0 a prompt for rewriting text in my own writing style. The prompt that I have works well enough, and I got there through crude trial and error:```Rewrite the article in the following style:- Concise and to the point- Professional and knowledgeable tone- Relatable and accessible language- Uses storytelling to convey ideas- Relies on examples and case studies- Mixes personal anecdotes with industry insights- Provides actionable advice and tips- Uses subheadings and bullet points for easy readability```Now that I\u2019m using this prompt more often, and I\u2019m finding no noticeable improvement from continued trial and error, it\u2019s the right time to level up to prompt optimization. If I can A/B test different approaches with an objective measure of performance, I can be more certain my changes are helping rather than harming results."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '1. Metrics' for the blog post 'Prompt Optimization'"}, {"role": "assistant", "content": "The first thing we need to decide on is how we\u2019re going to measure performance. When we\u2019re just running the prompt 2-3 times we can manually review the responses, but that gets tedious and unreliable when we\u2019re running it 20-30 times.The key is defining a programmatic definition of success, something we can run in a script to compare the relative performance of multiple samples at once. The open-source library Langchain has a number of standard evaluators for you to use, including the capacity for you to build and apply your own.In this case we\u2019ll use the `embedding_distance` evaluator which gives us a measure of similarity between two sets of text (lower is similar, higher is different). For this experiment I asked GPT-4 \u201cExplain value based pricing\u201d, which is a topic I have written about. We\u2019ll use this as the Input text, and then we\u2019ll ask GPT-4 to rewrite it in my style. I personally rewrote that text and saved it as a reference example, or ground truth, which we\u2019ll compare using the embedding distance."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '2. Hypothesis' for the blog post 'Prompt Optimization'"}, {"role": "assistant", "content": "One commonly used prompt engineering technique is few-shot prompting, meaning providing a number of examples of the task being done correctly, inserted into the prompt. This is one of my five principles of prompting, and is always one of the first things I try. The evidence in the literature (Lilian Weng provides a good summary) shows that few-shot prompting can have a huge impact on performance, although the results can be unstable and biased in some cases.https://arxiv.org/pdf/2102.09690.pdf\u00a0We don\u2019t just want to start inserting example text into our prompts and blindly trusting that it\u2019ll help. Adding examples comes at a cost, both in terms of extra tokens, and the cost of finding and inserting relevant examples each time we want to use this prompt. If we\u2019re guaranteed a step-change in performance it\u2019s worth it, but if the difference is less than 5%, or it causes instability or bias in our results, we\u2019ll stick with what we already have.In this case, I\u2019ll take some of my writing from another post to provide as an example, and insert that alongside the existing prompt. The prompt in this case goes in the System message (a place for giving instructions on how the AI should perform), and we\u2019ll add the writing example as the first message in the queue, with a follow up message formatted as an AI response, in order to \u2018trick\u2019 into thinking the user submitted and it responded already:```System: You will be provided with the sample text.Your task is to rewrite the text into a different writing style.The writing style is:- Concise and to the point- Professional and knowledgeable tone- Relatable and accessible language- Uses storytelling to convey ideas- Relies on examples and case studies- Mixes personal anecdotes with industry insights- Provides actionable advice and tips- Uses subheadings and bullet points for easy readabilityHuman: Here is an example of the writing style:{writing_style}AI: Thank you for the example of the writing style. Now please provide the sample text.Human: {input_text}```\u00a0"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '3. Testing' for the blog post 'Prompt Optimization'"}, {"role": "assistant", "content": "Now we\u2019re ready to run the test and generate our samples. Rather than just running both prompts once and comparing the results, we\u2019re going to run them 20 times each. That will give us a better understanding of how reliable the results are at scale, and how often they deviate significantly from our reference text. We can then average the score that we get from our evaluation metric, and see overall if one prompt is better than the other.This will already be far better than what the average ChatGPT guru does, because it\u2019s more systematic and will surface problems that would only appear at scale. However, this is still far from scientific, and we\u2019d want to see how well the prompts do across multiple test cases if we were putting it into production. The prompt might do well on this value-based pricing example, but fail miserably on other topics or in other scenarios. You\u2019d also want to test different methods for retrieving the relevant example text, for example querying a vector database, because that can make a big difference.In my experiment I\u2019m using Langchain to initialize the LLM and to create the prompt template, as it minimizes the potential for errors, and makes my code more reusable. If we want to swap out GPT-4 for a different model, or use a different evaluation metric, we only need to change a handful of lines. Langchain also comes with all the necessary retry logic, and using `tracing_v2_enabled` it\u2019s simple to log the results to a file or to a platform like LangSmith for further analysis."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section '4. Analysis' for the blog post 'Prompt Optimization'"}, {"role": "assistant", "content": "In measuring the results, what we\u2019re looking for is how close we can get to the text that I personally rewrote. If we can get closer to my actual writing style when translating AI-generated text, it\u2019ll save me a lot of time rewriting that text manually. When we\u2019re comparing embedding distance the lower the better, so we\u2019re looking for what prompt gets us a consistently lower score. We should also be on the lookout for variance: a prompt that scores well on average may still be a problem if on occasion it goes disastrously off course.Even just running my first prompt itself 20 times is revealing, because we can see just how often it\u2019s off the mark. The embedding difference on average is 0.65, but it ranges from as low as 0.05 (good), to as high as 0.096 (bad). Knowing this variance we can build in more protection against anomalous results, for example by not just running it once but taking the best of three runs. As we have a programmatic definition of success, embedding distance, we can calculate that on the fly in order to automatically select the \u2018best\u2019 of each batch.The end result of the A/B test is that the change to the prompt didn\u2019t perform any better: the average distance was exactly the same at 0.065. Even though it can be disappointing to get a negative test result, this is actually a huge win: we might have blindly added these examples to our prompt going forward, costing us an extra ~500 tokens per example for no gain. At current GPT-4 pricing that\u2019s only 1.5 cents per run, but if this is being run thousands of times a day as part of a product, that cost can quickly add up to hundreds of dollars a month. It also greatly simplifies our app design knowing we don\u2019t have to ask the user for samples of their other writing, making for a better user experience.From here we can go in a different direction for our next test, for example:Discovering different ways to define our writing style.Trying another technique from the scientific literature, like self-evaluation.\u200dAttempt to replicate these results using GPT-3.5-turbo, which is 10x cheaper and less rate-limited.Conduct a manual rating evaluation, to sense check that embedding distance is reliable.Define a different evaluation metric, for example asking GPT-4 to rate the similarity.Dial up the number of examples to 3, 5, or 10 see what happens.Use a model with a larger context window and throw 100 examples in there.Fine-tuning a model based on our data (which tends to beat prompt engineering at ~100 examples).\u00a0Whatever direction we decide to take, we have now established what \u2018good\u2019 performance looks like, and have evidence we can provide to our boss or other stakeholders to justify our decisions. This is the difference between prompt engineering and blind prompting, and as the field of AI professionalism, this will become standard practice. In the meantime however, there\u2019s a tonne of low-hanging fruit to pick, because almost nobody is being rigorous with their prompts!Update: I ran further experiments on this prompt which you might be interested in. Read the post \"AI Writing Style Experiment\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'A. Read Ranking Content' for the blog post 'Recruiting good Freelance Writers'"}, {"role": "assistant", "content": "This post is one of a series on my content production system, developed over 10 years and designed to scale content end-to-end in 6 months as an acquisition channel. Here are the other posts in the series:Why the winner takes all in Content MarketingWhat everyone gets wrong about Content Strategy\u200dBuilding Your Keyword Universe \u200dMinimum Viable Technical SEO Audit\u200dRecruiting good Freelance Writers (this post)\u200dHow to write blog content at scaleGrowth engineering for SEO\u200dLink building for authorityContent Repurposing for Social Promotion ---Writers are the lifeblood of any content marketing effort - you can't do it without them, but good freelancers are hard to find. There are three kinds of writers, and you\u2019ll use all of them for different things. Freelance writers usually don\u2019t have domain expertise but can write on most topics. They often live in Western countries, so they will charge between 15 and 50 cents per word. Domain experts who learned to write are the most expensive, costing in many cases over $1 per word. There are also low cost writers that live in poorer countries, and can be as low as 5-10 cents per word, or used for virtual assistant-type tasks like research or data-entry.\u00a0Domain Experts - $1+ per wordProfessional Writers - $0.15-0.25 per wordVirtual Assistants - $0.05-0.10 per wordThere\u2019s no playbook for attracting domain experts: you have to be lucky and well networked. Low cost virtual assistants are in high supply, but need a lot of instruction, so you\u2019ll typically only want to use them for structured tasks, long tail copy and gathering research. It\u2019s the first group, professional freelance writers who you can build a recruiting system around, so that\u2019s what we\u2019ll focus on. This is a simple but time-consuming process, but it got me an 80% success rate (from initial outreach to content published) in finding good quality new writers.Let the market do your vetting for you: read posts that have already ranked on the keywords you\u2019re targeting, and note down the authors of the posts you like. This will help to give you an idea of what the competition is like, and also act as a source of leads for writers to contact."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'B. Find Authors on Social' for the blog post 'Recruiting good Freelance Writers'"}, {"role": "assistant", "content": "Nowadays it\u2019s pretty easy to find people online, particularly writers, because if they\u2019re freelance they want to help new clients to find them. Even if you can\u2019t tell from the blog post or author page, the vast majority of writers don\u2019t work full time at the place you found their post, and are willing to be contacted via DM on Twitter, LinkedIn or Instagram."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'C. Offer a 1 Post Trial' for the blog post 'Recruiting good Freelance Writers'"}, {"role": "assistant", "content": "Even if the writer does work full time at the place you found their post, the chances are they\u2019re up for some moonlighting so long as you\u2019re not a direct competitor. Most people can carve out an evening or some time on the weekend to earn some extra cash, in particular if you can work with them remotely and without strict deadlines. Supply them with 3x topic ideas within their area of expertise and set a fixed number of words, say 500, that you want the post to be. Ask them to quote you a fixed or per word price for the piece, and give them full latitude to set their own deadline up front. If the post is low quality or they miss their own deadline, do what you can with what they send you, but just pay them and move on. If they do a good job, make a point of publishing and paying as soon as possible, and send them the link with clear permission given to use in their portfolio."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'BONUS: Hiring an Agency' for the blog post 'Recruiting good Freelance Writers'"}, {"role": "assistant", "content": "If you want to get going quickly with minimal management overhead and have built in quality control, then hiring an agency can be a good option - they'll do all this for you (for a price). You should understand the economics of how an agency works so you\u2019re going in with your eyes open: expect a 100% markup on the cost of producing the content with freelancers, because you\u2019re paying for convenience. Model out the potential cost differences by taking the length and number of articles they\u2019re committing to publishing on your behalf, vs your own costs to doing the same. Even if they won't give exact numbers, you can usually get a 'typical range' out of them and estimate the rest, particularly if you say it's a procurement requirement to close the deal.Content Agency Modeling TemplateOf course you also need to calculate the cost of management overhead, which in many cases can be a 50-100% multiplier on the gross cost of the content published: that\u2019s why agencies need to charge so much. If you decide the economics work for you and you want to go down this route, I suggest you try and hear pitches from 3-5 different agencies. For the ones you like, get references from existing or past clients - search them out through google or via your network, it\u2019s a waste of time talking to anyone they recommend you to talk to. "}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'What is Marketing Mix Modeling?' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "*** Note: this is featured in a simulator-based course on Vexpower.com: \"Can we try Facebook Robyn?\" ***\u200dI recently had a thread go viral on Twitter with 170k impressions and 35k likes/comments. What got people so excited? Statistics. Specifically Facebook\u2019s use of statistics to solve a tracking problem. Facebook\u2019s Robyn is an open-source project from their marketing science team that automates Marketing Mix Modeling (MMM), and I was live tweeting an obscure webinar about it.Marketing Mix Modeling (MMM) is a technique from the 1960s that's still used to this day to attribute TV and offline spending by most of the Fortune 500. It\u2019s being reinvented for the digital age by startups like Harry\u2019s, ThirdLove and Monday.com, who are solving for the high cost, slow speed and human bias you get with traditional methods. So why are Facebook interested?"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Why is Facebook using MMM?' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "Because it doesn\u2019t rely on user-level data, MMM is a potential holy grail: completely future proof to whatever happens with privacy legislation, ad blockers or Apple\u2019s tracking policies. So while Google had already been publishing papers on MMM, it\u2019s a big vote of confidence that Facebook is getting in the game. The fact that it\u2019s open source increases trust\u00a0"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'What happened to click tracking?' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "There had been cracks forming in click-based attribution methods for a while. We knew last-click attribution had flaws, we successfully ignored the rise of adblockers, but when startups grew up and expanded to offline channels and TV, there was no \u2018click\u2019 to track. So when iOS14.5 made it easy to opt out of tracking, it was the beginning of the end for digital attribution."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How do I use MMM?' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "Most of the people interested in Robyn from that Twitter thread were overwhelmed. They came for a solution to a problem, not a statistics lesson. If you\u2019re spending less than $100k per year on ads across 1 or 2 digital channels, you likely don\u2019t need Robyn. You can build a marketing mix model in an afternoon with Excel / GSheets, as I detailed in my Econometrics guide. To keep learning about MMM, head to my simulator-based courses on Vexpower."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Should I use Robyn?' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "If you are a larger advertiser spending $100k+ per month, across 3 or more channels, especially offline channels, then you should consider Robyn. Even if you\u2019re already using a marketing mix model built in-house or with a vendor, you can compare the results to your own. It\u2019s free apart from the time your analysts spend on it, which will be negligible if you send them this guide!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'How do I run Robyn?' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "I\u2019ve been coding for 6 years (JavaScript & Python), and spent last year building vexpower.com, so I\u2019m technical: yet it still took me over half a day to get it running on my Windows machine. So I decided to put this guide out there to help you get started. If you\u2019re on a Mac the steps are the same but the instructions should be slightly easier.*** Disclaimer: there\u2019s all sorts of advanced computer stuff going on here that I don\u2019t understand. I could be giving you bad advice that could lead to your computer being hacked. If you get stuck, Google around or ask a friendly IT person, then let me know so I can update this. ***"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Install Anaconda' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "This isn\u2019t strictly needed to run Robyn, and it is a pretty large download, but it\u2019s useful for lots of things. I use it regularly for running Jupyter Notebooks, which is great for showing your work when completing data science tasks in Python. We\u2019re going to use it to create a virtual environment for R to run Python in (don\u2019t ask - we\u2019ll get to this later).> Download Anaconda"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Install R' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "R is a programming language used primarily by statisticians and data scientists. It\u2019s the coding language most marketing mix modeling experts use if they aren\u2019t just using Excel. I have no idea how it works, and you don\u2019t have to either. Don\u2019t get confused by the \u2018CRAN mirror\u2019 wording: they just mean download the package from somewhere it\u2019s hosted that\u2019s near you.> Download R"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Install R-Studio' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "R-Studio is an IDE (Integrated Development Environment) that lets you write code in R and run it. You need it to run the Robyn script and you can actually get it from inside Anaconda... BUT that didn\u2019t work for me, so I recommend you download it directly.> Download R-Studio"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Check R Version' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "Something small to check off the todo list: make sure you\u2019re using the right version of R (and run your first R code!). In the console of R-Studio, type the word \u2018version\u2019 and hit enter. That should be a number like 4.0.0 or above, which tells you you did the last two parts correctly.```version```"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Install Robyn' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "This part is actually really easy. In R-Studio just add the lines below in the script window, select the code you just copy and pasted, and press \u2018Run\u2019 (or Ctrl + Enter keys). This part used to be a lot harder but they packaged the code up in this library as part of their version 3 release.```install.packages('remotes')remotes::install_github(\"facebookexperimental/Robyn/R\")```"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Install Nevergrad' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "Ok this is where it gets tricky. This is what had me stuck for half a day (a fate you can hopefully avoid, especially if you have a mac). Nevergrad is an optimization library that uses an derivative-free, evolutionary approach, which makes it useful for more things. First complication: Nevergrad is a Python library (yay!) that Robyn needs to run in R (boo!)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Install Nevergrad Step 1: Install Reticulate' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "This part is easy. You install and load reticulate, which is an R library that lets you run Python libraries from your R code. As we did with the Robyn package, copy these lines into R-Studio and run them.```install.packages(\u2018reticulate\u2019)library(reticulate)```"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Install Nevergrad Step 2: Conda Install' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "This is where we use Anaconda. If you want to use pip, there\u2019s an alternative method listed in the Robyn quickstart docs that you can try (didn\u2019t work for me). We run the below lines, again in R-Studio. The first line creates a virtual environment called \u2018r-reticulate\u2019, the second line uses that environment to install nevergrad, then the third line lets us use it going forward.```conda_create(\"r-reticulate\") # must run this line onceconda_install(\"r-reticulate\", \"nevergrad\", pip=TRUE)use_condaenv(\"r-reticulate\")```If that worked the first time, consider yourself lucky! You can skip the next step. Otherwise fear not, I\u2019ve been down this rabbit hole, and I can guide you through it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Install Nevergrad Step 3/4/5/6/n: It\u2019s Not Working!?' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "The first thing to try is what the Robyn team suggests \u2013 locate your Python file then run this line:```use_python(\"~/this/is/your/path/to/python\")```Ok, but stupid question, how do you locate your Python file? Well you open the terminal for the environment you want to know this for, and then type the following command:```where python```This is what it looks like on my windows terminal, which I can get access to by searching my start menu for \u2018terminal\u2019.\u00a0If you\u2019re on windows, remember to replace the slashes with two backslashes. So for example:```use_python(\"~\\\\python\")```However if you\u2019re using Anaconda, you might want to go with that one.```use_python(\"~\\\\Hammer\\\\anaconda3\\\\python\")```You\u2019ll know it\u2019s working when you can run the following lines without it failing:```conda_install(\"r-reticulate\", \"nevergrad\", pip=TRUE)use_condaenv(\"r-reticulate\")```If that doesn\u2019t work, or you don\u2019t see the Anaconda one in your Terminal, don\u2019t worry, you can open up a terminal for any environment you like, which is kind of nice. Choose your environment (in the screenshot I have selected the \u2018r-reticulate\u2019 one we created from R-Studio) and click Launch for the \u2018CMD.exe Prompt\u2019 app.Now you have a terminal open just for that environment, and you can type the same `where` command again to check where your version of Python is.```where python```You would enter that first one in R-Studio as.```use_python(\"~\\\\Hammer\\\\anaconda3\\\\envs\\\\r-reticulate\\\\python\")```Oh and while you\u2019re here, you might also just want to try installing Nevergrad directly. So for example you can do:```pip install nevergrad```Then you can skip the first and second lines in R-Studio and just try the following line before moving on to test the demo code.```use_condaenv(\"r-reticulate\")```Why am I giving you so many options? Because I tried everything and honestly I\u2019m not 100% sure what worked! Perhaps someone smarter than me can chime in and tell me which was the right one. In any event, this wasn\u2019t enough, because I also had to fix the SSL issue.\u00a0This is where things got a little scary. If you have a Mac, you almost definitely don\u2019t have this problem (and if you do I can\u2019t help you). Brave Windows users, read on. Linux users\u2026 I don\u2019t know why you\u2019re reading this guide, you already know more than me.\u00a0Still with me? If you read this Robyn quickstart doc it sends you here (dead end) and to this stack overflow comment, which takes you to this guide, which leads you to\u2026 ok take a deep breath and look at this website.I know, it feels like we\u2019re getting hacked just looking at it. Well my solution requires you to actually download some software from this website. If you\u2019re uncomfortable with this, now is the time to run crying to IT support.\u00a0For those of you left, I want you to say the words \u201cmaximum effort\u201d in the mirror and click the EXE link next to where it says Win64 OpenSSL v1.1.1L. This is what I clicked and I haven\u2019t been hackedski so farski \u041a\u0442\u043e \u043c\u043e\u0436\u0435\u0442 \u044d\u0442\u043e \u043f\u0440\u043e\u0447\u0438\u0442\u0430\u0442\u044c \u041e\u0431\u043e\u0436\u0430\u044e \u0412\u043b\u0430\u0434\u0438\u043c\u0438\u0440\u0430 \u041f\u0443\u0442\u0438\u043d\u0430!If you survived that part, double click on what you just downloaded to run the installer. When it asks you, tell it to install it outside the system directory. Remember where you installed it, and then follow this handy guide to add that to your user path. If that doesn\u2019t work for you, then I don\u2019t know what to tell you: Silicon Valley developers don\u2019t care about Windows users."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Run The Demo' for the blog post 'Running Robyn in R'"}, {"role": "assistant", "content": "Hooray! You made it here either as an embattled but victorious Windows user, or a Mac user that got to skip the hard part. Either way, this is where the fun begins. The Robyn team made a nicely commented demo script for us with demo data so we can run it and see how it works. Just visit this link and copy and paste the whole contents into R-Studio.> Demo ScriptYou\u2019ll want to go through this line by line (that\u2019s actually one of the nice things about R-Studio), so you can see what\u2019s happening and what you might need to modify when you run it yourself. As you run each line the output will show up in the console, and as you define them, variables will appear in the environment window on the right.I recommend you go through and read the comments (in green) before you run anything, and then read them again to follow the instructions as you run each line. Once you get to line ~280, step 3, you\u2019re actually running the model! The bad news is that it takes about an hour or so to run (depending on your computer, and what you modified).Once Robyn is finished, you get the results in your parent directory (regardless of what working directory you set) called something like `2021-10-06 23.23 init`. This provides a one page summary of each chosen model saved as a PNG, as well as a number of other files detailing the models it ran and which ones it deemed best. Note that Robyn runs thousands of models and then narrows that down for you to about a hundred that fit the data best. From there you have to pick the one you think best represents your business (a topic for another time!).Congratulations! If you made it this far, you\u2019ve managed to get Robyn running. As you may have noticed (particularly if you followed me deep into Nevergrad step 3) that I don\u2019t think this software is particularly\u2026 accessible in its current form. The vast majority of marketers can\u2019t be depended on to set up development environments or run R code (Python version please! \ud83d\ude4f).\u00a0However the Robyn team are making improvements and their commitment to open source is commendable: they could have easily kept this as a proprietary tool for their big clients and instead it\u2019s out there for us to use for free. This was a smart strategic move, because who\u2019s going to trust a black box modeling tool that says \u201cspend more on Facebook\u201d.\u00a0However because it\u2019s open source, however challenging it is to use, I hope my guide inspires you to play with the tool, learn from it, maybe even contribute improvements to it. If we can bring marketing mix modeling to the modern age by automating it and removing human bias, then that\u2019ll be a huge help to all marketers, who are just trying to prove the value of their campaigns.\u200dIf you want to learn a bit more about how to intepret the model, the best place is my simulator-based course on Vexpower.com: \"Can we try Facebook Robyn?\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'A. User Generated Content' for the blog post 'Growth engineering for SEO'"}, {"role": "assistant", "content": "This post is one of a series on my content production system, developed over 10 years and designed to scale content end-to-end in 6 months as an acquisition channel. Here are the other posts in the series:Why the winner takes all in Content MarketingWhat everyone gets wrong about Content Strategy\u200dBuilding Your Keyword Universe \u200dMinimum Viable Technical SEO Audit\u200dRecruiting good Freelance Writers \u200dHow to write blog content at scale \u200dGrowth engineering for SEO (this post)\u200dLink building for authorityContent Repurposing for Social Promotion ---If you really want to scale content, you can\u2019t do it by human effort alone - you need engineering resource. There are two major strategies for generating content at scale for SEO: user generated and machine generated content.UGC is the easiest to build (from a technical perspective) but it can be very hard to get traction. Fundamentally you need to find a creative way to convince users to do data entry for you. If you can get them to submit content to the site, and structure that data so it ranks, you\u2019ll be able to explode your SEO. For example, Thumbtack asks questions like \u201cwhat makes your service stand out\u201d during onboarding, and uses the answers on profile pages.\u00a0"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'B. Machine Generated Content' for the blog post 'Growth engineering for SEO'"}, {"role": "assistant", "content": "It\u2019s hard to motivate users to do data entry for you, so many go the machine generated route: use web scraping or build a unique dataset and display the structured data as pages. At Candor we built a site with all 11k+ recruiters who work in tech, and started ranking when people searched recruiter\u2019s names. Tools like GPT-3 are opening up more possibilities in this area. However you can start small, with simple rules that enrich your existing content with target keywords."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'A/B Testing SEO' for the blog post 'Growth engineering for SEO'"}, {"role": "assistant", "content": "It can be incredibly difficult to be scientific in content marketing, because it\u2019s impossible to run a controlled experiment. Google serves personalised search results for every user, and we have severely limited control over what is shown. They also don\u2019t like it when you serve different content on a page to different users (cloaking). This is one more reason why the winner takes all in this market: if you get enough traffic to run statistically significant tests, you can learn faster than the competition."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'A. Correlation Analysis' for the blog post 'Growth engineering for SEO'"}, {"role": "assistant", "content": "When you don\u2019t have enough data for scientific testing, you need to look at correlations and make some educated guesses at what to do. You can look at your own data around what seems to rank highly on your site or in your industry, but it probably makes sense to look at overall ranking factor studies for the big picture."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'B. Trend Analysis' for the blog post 'Growth engineering for SEO'"}, {"role": "assistant", "content": "It might not feel very scientific, but switching something on or off then looking at the trend is one very common and effective way to estimate the impact on SEO. If something really worked you\u2019ll see a huge spike, and you won\u2019t really need statistical significance to prove the case. It\u2019s important to keep notes on when changes were made in order to go back and annotate your analytics charts and see where the timing lined up.Going one step further with this method: it can help to establish the existing seasonal trend in order to do a proper analysis. You don\u2019t have to run a full causal effect model, but even something as simple as overlaying the average hourly traffic before and after can be enough to tease out the effect of your change."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'C. Split Testing' for the blog post 'Growth engineering for SEO'"}, {"role": "assistant", "content": "Although we can\u2019t truly scientifically A/B test with SEO, we can get close enough. The method was developed at Pinterest and later productised by Search Pilot, and it consists of splitting your pages by type of page, then making changes to 50% of the pages in that category. For example adding a \u2018related interests\u2019 bar to your Board pages to see if that drives more traffic."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Benefits of Server-Side' for the blog post 'Server-Side Tracking'"}, {"role": "assistant", "content": "You can no longer trust your numbers. Whether it\u2019s Apple limiting cookies to 7 days, GDPR/CCPA forcing annoying cookie notices or some 27% of people surfing the web with ad blockers, the ongoing privacy backlash is poking holes in our ability to track user behavior. Of course as an industry we brought a lot of this on ourselves, but now the effects are spilling over even to legitimate use cases from well behaved companies.\u00a0For example if I simply want to track how many people come back each week to read my blog, I can\u2019t get an accurate measure of returning users. If it has been more than 7 days since they read the blog on their iPhone, they\u2019ll show up as a \u2018new\u2019 user \u2013 if they\u2019re using an ad blocker they might not show up at all! As a fledgling business, the numbers are extremely important to me. It\u2019s how I tell if I\u2019m doing a good job at writing content people want to read. I agree we need to dial down the creepiness of tracking people across the web, but can you imagine trying to run a store if you couldn\u2019t see when people walk in the door?Thankfully this arms race between tech giants is also producing heaps of innovation in the space, with the biggest change being the advent of Server-Side tracking. Google announced in January a new form of Google Tag Manager container that lives on the server, Facebook started pushing it\u2019s Conversions API, and Shopify announced a native integration to push ecommerce sales to Facebook server-side, with surely more platforms to follow. Server-side tracking means your tracking scripts don\u2019t run in the browser where they can be easily blocked \u2013 they move to the cloud running in a server you control, which can also extend the life of your cookies!One of the main reasons these companies are moving to server-side implementations, is to get back visibility into tracking which users converted on the website after viewing or clicking on an ad. Without this visibility online advertising channels won\u2019t work as well, and that means billions of lost revenue for Facebook, Google, Shopify and the small businesses that rely on them.\u00a0However there are more benefits to server-side tracking than just visibility on ad performance. If anything it gives us more control to deliver on user privacy, and even improve user experience.Speed \u2013 Fewer measurement tags on your website means less code to run client-side, which should increase page load speed (good for conversion rate and SEO!).Security \u2013 With no 3rd-party vendor\u2019s scripts on your website, that\u2019s one less attack vector. They can\u2019t inject content into your site or track anything you don\u2019t want them to.Control \u2013 Now you can decide what data gets stored and sent. I don\u2019t recommend using this to abuse user\u2019s right to privacy, but instead to track key events anonymouslyThere are myriad benefits to moving your tracking server-side, and of course with more power becomes more potential for abuse. I wouldn\u2019t be surprised if we see companies having to hand over the keys to their servers to be audited by Apple or the EU to ensure they aren\u2019t violating user privacy, given that the tracking process is now far more opaque.\u00a0Rather than seeing server-side as a workaround, I recommend instead you focus on legitimate uses that let you still track key events like pageviews, purchases and signups. When you track anything, it should be anonymous by default. I suggest you employ the principle of least privilege, and only track absolutely what you need \u2013 most companies barely look at the majority of the data they collect anyway!There are downsides to server-side tracking to consider. One is the cost \u2013 this requires setting up a server on the Google cloud platform, which can cost anything from $20 to $200+ per month depending on your traffic. If you\u2019re a small website of less than 10,000 visitors a month, chances are you\u2019ll pay nothing for years, with the $300 free credit you get for signing up. In addition, it\u2019s far more technically complex to set up than traditional Google Tag Manager, and it is still in beta. If you aren\u2019t a developer or don\u2019t have someone technical in your team, you may struggle."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Setting Up Server-Side Tracking' for the blog post 'Server-Side Tracking'"}, {"role": "assistant", "content": "To get a Google Tag Manager server-side tracking container live, I recommend both the official Google documentation and Simo Ahava\u2019s fantastic guide \u2013 this is what I followed when setting mine up. I\u2019ll walk through how it all worked and hopefully this post can serve as a more accessible tutorial to getting started."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Step 1: Create a server container' for the blog post 'Server-Side Tracking'"}, {"role": "assistant", "content": "Log in to Google Tag Manager and click on the right ellipses menu, then select Create Container from the dropdown menu.You want to create one of the new Server containers, which as of the time of writing is still in beta."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Step 2: Add a billing account and create the server' for the blog post 'Server-Side Tracking'"}, {"role": "assistant", "content": "Next they\u2019re going to ask you for a billing account \u2013 this is to pay for the Google Cloud Platform storage, for which you should get a $300 free credit if you\u2019re new to the platform.\u00a0Once you create a server with the default details, you\u2019ll see it takes some time, but you\u2019ll eventually get to a screen that tells you the server was created. Make a note of the Cloud Platform Project ID and the Default URL."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Step 3: Set up a custom domain (optional)' for the blog post 'Server-Side Tracking'"}, {"role": "assistant", "content": "It\u2019s at this stage I recommend you follow the instructions to add your own custom subdomain to run the server on. This step is important because it allows you to set cookies in a 1st-party context. This means your tracking events will fire to something like analytics.yourdomain.com, and any cookies your server sets will be able to bypass the 7 day cookie rule on Safari.\u00a0Google will give you various TXT and A records you need to add with your domain provider (mine was GoDaddy), and when you\u2019re finished you can validate it worked. With this step you will be sending data to your own domain rather than a third party, so you can take full advantage of the power of server-side. Once you\u2019re done adding a custom domain, you might want to leave it for an hour, because it takes some time for Google to provision your SSL security certificate."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Step 4: Set up your triggers and tags' for the blog post 'Server-Side Tracking'"}, {"role": "assistant", "content": "Now it\u2019s time to set up your triggers and tags. This part works fairly similarly to how GTM works on the web, so it shouldn\u2019t be too unfamiliar. Google Analytics is the easiest tool to set up in Server Side GTM, so let\u2019s focus on that. Go to Tags and create a new tag. Choose Google Analytics: Universal Analytics.Then you want to click in the Triggering section to add a new Trigger. This is far simpler than most Triggers in the web containers, because there are less options. For the Custom trigger choose \u2018Some Events\u2019 and make the Client Name equal to Universal Analytics.The Client is what grabs your incoming data and \u2018claims\u2019 it, to run certain rules on. In this case we\u2019re just using the default Universal Analytics client, so we don\u2019t need to make any edits \u2013 when we send a hit in the right format for the GA measurement protocol, it\u2019ll get claimed by this Client."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Step 5: Test your container is working' for the blog post 'Server-Side Tracking'"}, {"role": "assistant", "content": "Now is a good time to check the container is working as promised. If you click the Preview button you should see a screen like this load up. If it\u2019s giving you an error you might need to wait an hour until Google provisions your SSL certificate.Now let\u2019s go to the GA Dev Tools Hit Builder, to create a measurement protocol endpoint to send our data to so we can test our setup.You\u2019ll want to create a Google Analytics account if you haven\u2019t already and grab the tracking ID of the account (starting with UA-) so we can send the hit and see it show up in our analytics.To build the hit, add your tracking ID in the tid field, add a dummy user ID (\u20181.2.3.4\u2019 works fine) and add the dl parameter with a location of a page on your website. Note I used a fake page /test_page so make sure I could easily see the hit in my Analytics account. Validate the hit then click \u2018Copy shareable link to hit\u2019.That should give you a URL like this one:https://ga-dev-tools.appspot.com/hit-builder/?v=1&t=pageview&tid=UA-167909558-2&cid=1.2.3.4&dl=https%3A%2F%2Fwww.saxifrage.xyz%2Ftest_pageYou want to remove the \u2018https://ga-dev-tools.appspot.com/hit-builder/\u2019 part and replace it with your own URL that you set server side tracking up with. For me it was ssa.saxifrage.xyz because that\u2019s the custom domain I used, but for you it will be something different.https://ssa.saxifrage.xyz/collect?v=1&t=pageview&tid=UA-167909558-2&cid=1.2.3.4&dl=https%3A%2F%2Fwww.saxifrage.xyz%2Ftest_pageIf you didn\u2019t set a custom domain and didn\u2019t note the URL they gave you when you created the server, just visit the Container Settings in GTM and it\u2019s the Default URL at the bottom.Now when you visit the URL you built with the hit builder (after swapping out the ga-dev-tools part for your custom domain or Default URL), you can go back to preview mode and see a hit.For more detail of what was fired you can click into the page_view event and see how the data was processed (if at all) and where it was sent, what the headers were and response code, etc.The true test however is seeing the data show up in Google Analytics in the Realtime section. If you used a test_page like I did it should be easy to distinguish the hit in the Realtime > Content section. It should show up as 1 active user on site, for that page."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Step 6: Finish configuring your tags' for the blog post 'Server-Side Tracking'"}, {"role": "assistant", "content": "Finally the last step you need is to fire the data from your website into the new server side container, which is what we just simulated with the measurement protocol hit. Switch back now to your client side Google Tag Manager container, which is where we\u2019ll track the data as usual and send it to our client side container, which then sends it to Universal Analytics.You can set this up as a normal pageview tag, with Google Analytics settings variable, but check the box to Enable overriding settings in this tag. Then scroll down to the Advanced Configuration section, and put your new custom URL (the one you sent the hit to) in the Transport URL field.Also do the same in Google Analytics settings (for this I set up a new Google Analytics account, you might not want to mess with any existing implementation). I also in this case added an anonymized IP address field (Field Name: anonymizeIP = true, because like I said earlier, the goal here is to track pageviews not users, and you should anonymize by default, if you don\u2019t have a good reason not to.Finally when the container is published, go back to your Google Analytics account Realtime section and visit your website to check your visits are showing up. Go to obscure sections of your site so you show up easily if you already have website traffic, or enter the website with a unique utm_source and utm_medium parameter.That\u2019s it, you\u2019re now running on server-side analytics. There\u2019s a lot more you can do, for example pulling data from other APIs to enrich your user behavior data. Because it\u2019s server side it\u2019s tolerable to wait longer for a call to say the weather API, than it would have been client side. To see the other benefits you get from going server side, check out the FPID cookie that GA server-side sets by default.\u00a0You can see this configured in the \u2018More Settings\u2019 section of the Tag in the server-side container. It stands for First Party Identifier, and because it\u2019s set from your domain via a server, it skips out on all of the rules Apple has for Intelligent Tracking Prevention, as well as ad blocking technology.If you visit the website you can see this for yourself by right clicking and going to \u2018inspect element\u2019, then going to Storage. You should see a cookie that has an expiration of something like 2 years in the future, with HttpOnly and Secure values of true. This is now how GA recognizes returning users, so you should now hopefully avoid most scenarios of data loss!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Closing Thoughts' for the blog post 'Server-Side Tracking'"}, {"role": "assistant", "content": "Even if this method works right now, it\u2019s highly likely that you\u2019ll need to change your analytics setup again in the future as Apple dances with Facebook and Google, blocking new attempts at workarounds. We should expect that at some point browsers will look at not just where data is being sent, but what data is being sent, and then there will be another arms race as more holes in tracking appear and more workarounds are added.In fact shortly after implementing this, one fellow growth engineer pointed out to me that the Brave browser was blocking my tags. This happens because they\u2019re recognizing the Google Tag Manager client side script, which is what\u2019s sending the data server side in the first place. To fix this I\u2019d have to hard code the call to the server side\u2026 but obviously then it gets harder for non-technical users to contribute events\u2026 and so the cycle continues!I won\u2019t weigh in further on the morality of tracking users who don\u2019t want to be tracked, or how necessary it might be for businesses to understand how people are using their products. What I will advise you is that you should never see analytics as a \u2018one and done\u2019 or \u2018set it and forget it\u2019 task.\u00a0This field is already complex, but is seeing rapidly accelerating innovation and you should expect to be constantly monitoring the situation. Reevaluate your stack, switching vendors and test new methods (or work with someone who does). I\u2019m also seeing more people trying alternative attribution methods like Marketing Mix Modeling / Econometrics. Of course another (completely valid) option is to step back from the bleeding edge and find other less complicated ways to understand your users to make your product better!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'A. Visibility' for the blog post '\u200dMinimum Viable Technical SEO Audit'"}, {"role": "assistant", "content": "This post is one of a series on my content production system, developed over 10 years and designed to scale content end-to-end in 6 months as an acquisition channel. Here are the other posts in the series:Why the winner takes all in Content MarketingWhat everyone gets wrong about Content Strategy\u200dBuilding Your Keyword Universe \u200dMinimum Viable Technical SEO Audit (this post)\u200dRecruiting good Freelance WritersHow to write blog content at scaleGrowth engineering for SEO\u200dLink building for authorityContent Repurposing for Social Promotion ---Now you have keywords to target, you want to make sure your site is healthy enough to rank. Many have tried to reverse engineer Google, but you don\u2019t have to be that smart \u2014 just give them what they want! Your site needs to be visible to the search engine crawlers, have intentionally thought through architecture and structured metadata: if you have these three things you\u2019ll be fine. The underlying technology of your site is the base on which you build relevance (content) and authority (links), so it\u2019s the most important pillar to get right.Google needs to be able to see your website, and they typically like to read static HTML. Add a sitemap with all of your pages on it, so Google knows where to look. Turn off JavaScript or install Google Search Console then look to see what the crawler sees. Also check your core web vitals: this is Google giving you a big hint as to what\u2019s wrong with your website load speed and other technical factors. Google is optimizing to finding their users\u2019 answers as quickly as possible, so the faster your page loads, the more they\u2019ll refer you."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'B. Architecture' for the blog post '\u200dMinimum Viable Technical SEO Audit'"}, {"role": "assistant", "content": "Every page should have a single job to do, and there should be no duplicate content. As a general rule try and rank for one keyword per page, and have that keyword as close as possible to the root domain of your URL (site.com/key-word). Think about how you want to link between pages, particularly in the header and footer navigation: this is where Google looks for clues as to what you think is important. You\u2019ll run into conflicts: there\u2019s limited real-estate and you\u2019ll have to decide what pages are more important than others. Think primarily about the user experience: what\u2019s good for the user is often good for Google."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'C. Metadata' for the blog post '\u200dMinimum Viable Technical SEO Audit'"}, {"role": "assistant", "content": "Google gives you all sorts of tools for adding structured data to your website, and it\u2019s generally wise to make their job easier by doing so. The most important are the meta title and meta description, because that\u2019s the copy that shows on the search results page when you rank for a term. The H1 and other header tags are also key, because it helps Google understand the topics covered, and is correlated with ranking.\u00a0It\u2019s also helpful to add alt tags to images, because Google Image Search is a powerhouse in its own right. Finally add social graph metadata, like og:image tags, because they\u2019ll help make the page more likely to attract clicks when shared on social. There are other ranking factors, and most SEO tools have technical audits you can run, but these are the main ones to cover off.If you struggle to get developer time, or can\u2019t easily push new releases to your website, it\u2019s worth experimenting with Google Tag Manager (GTM). Google executes JavaScript now, so it\u2019s possible to do a lot of SEO work in GTM, without going through the tech team. For example adding schema markup, optimizing title tags, and even running split tests and other experiments."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Methodology' for the blog post 'How much lost data does Server-Side Tracking actually help you recover?'"}, {"role": "assistant", "content": "The release of iOS14 has thrown more fuel on the user privacy fire that started with GDPR, ad blockers and ITP. Some marketers are finding ways to do their job without tracking user data, others have explored probabilistic attribution models like marketing mix modeling, and the rest are looking to server-side tracking to claw back what they lost.\u00a0Everything I\u2019ve seen written on server-side tracking has been theoretical \u2013 why it should work rather than proof that it does. I\u2019m not one for wishful thinking, so I decided to test it and share the results.\u00a0Does Server-Side really fix broken tracking?At the time I put this test live in October 2020, iOS14 had been released the month prior and I was working as an analytics consultant. This website was getting about 60 pageviews a day from ~30 users, so nothing major but enough to see differences.\u00a0A few weeks later I decided to focus on vexpower.com (a simulator-based course on marketing mix modeling) as a solution to this problem, so\u2026 I pretty much forgot about the experiment until today.It was about time I looked into the results and wrote them up \u2013 tracking & attribution are increasingly relevant topics. However I have limited time so I haven\u2019t gone deep into this. I thought I\u2019d just get a rough draft out there and see if anyone is interested. If you\u2019re curious about the results and want me to analyze the data further, tweet at me.I wanted to test if server-side tracking actually helped you recover lost data from users that opted out of tracking. The way server-side tracking works, is by firing an event to my own URL (ssa.saxifrage.xyz) rather than to Google Analytics\u2019 servers, then returning a server-side cookie, which is not deleted by Safari and other browsers the way normal cookies are (because they\u2019re typically used for logging in). In theory this helps you get round the ad blockers, because they don\u2019t recognize your own domain as \u2018tracking\u2019.Of course I still wanted to respect my user\u2019s wishes, so I used the \u2018anonymize IP\u2019 feature in Google Analytics where I tracked them past the cookie banner. The banner is a simple \u2018accept\u2019 or \u2018decline\u2019 notice, which sets a cookie if they accept, which I then read to decide to trigger tracking or not.My website is just a simple blog with no really important conversion metrics, and I don\u2019t run any ads, so my use case for analytics is simply to check if people are reading my content, and what content is popular. I actually don\u2019t need or care about user-level data, so I have no business incentive not to anonymize personally identifiable information.I wanted to see if I could \u2018hack\u2019 Google Analytics' measurement protocol to not even have the GA code on my website (i.e. a cookieless solution), and only send them pageviews and events. I put this code here on my github \u2013 it\u2019s open source if you want to use it. There are other privacy-friendly alternatives like Simple and Plausible, but since 56% of the web uses Google, finding a way to still use it without invading user privacy would be pretty cool.Finally I also wanted to test the new Google Analytics 4 \u2013 this is the biggest change to Google Analytics since the release of Universal Analytics, and even though I still haven\u2019t gotten used to the way it looks, I thought it\u2019d be worth seeing if there were measurement differences. There was also an \u2018enhanced\u2019 tracking feature that\u2019s on by default, and gathers extra event data automatically, that I wanted to include in the test.\u00a0That left me with 7 different tracking profiles:My existing Universal Analytics setup, tracking users who accept cookiesStandard Universal Analytics setup, but with anonymize IPs, tracking everyoneServer-Side implementation of Universal Analytics, also with anonymize IPsStandard Google Analytics 4 setup, with anonymize IPs, tracking everyoneStandard Google Analytics 4 setup, with anonymize IPs, \u2018enhanced\u2019 turned off1x1 Image Pixel, firing a hit to my tracking server, with anonymize IPs1x1 Image Pixel, firing a hit to Google Analytics, with anonymize IPsAll but the last two were implemented with Google Tag Manager on the client side. Even though ad blockers wouldn't know to block the hits to my tracking server, they could potentially block Google Tag Manager, or recognize Google Analytics in the URL if I sent the traffic there instead of to my custom domain. So I hard coded these in my Webflow site code, skipping GTM entirely. I didn\u2019t want to track users who didn\u2019t accept cookies because I live in the EU and don\u2019t want to pay a GDPR fine, but maybe someone braver will try that experiment and see how much anonymizing IP addresses affects measurement?"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Results' for the blog post 'How much lost data does Server-Side Tracking actually help you recover?'"}, {"role": "assistant", "content": "All the data I\u2019m reporting here was from the last 7 days, 14th June - 20th June, 2021 (today is the 21st). I am looking at Pageviews, Sessions and Users, because there should be big differences across the tracking methodologies. If you don\u2019t have uniquely identifiable information on a user to stitch together their behavior and recognize them again, you\u2019ll track more unique users and maybe even more sessions \u2013 so more equals bad. However pageviews should always be the same.\u200d*Embarrassingly, version G had a bug in the code (it declared a variable I had already declared elsewhere), so it completely failed to track anything (and I failed to notice). Another life lesson in avoiding hard-coding wherever possible... but of all the variations to fail, this is the least interesting one, so I\u2019m cool with it. I\u2019ve just pushed a fix, so I might update this later.The biggest takeaway here is that by only tracking the actions of users who accept cookies, I\u2019m measuring less than half of the pageviews on my content! The number of times my blog posts are read is my number one concern, and I don\u2019t need to track individual users, so this truly makes the case for more anonymized analytics.The server-side implementation gave the exact same numbers for sessions and pageviews as the standard Universal Analytics setup, though it did report a more accurate User count (a lower count means they managed to connect the dots better). This means Server-Side analytics (at least for my use case) was not worth the effort. Where this could be useful is if you have logged in users, and lots of events happening off site or in an app. It would also be useful if spending money on advertising, because you\u2019d be able to see the users that you acquired come back and buy something in another session. However for the intended use case of \u2018recovering data lost by ad blocking\u2019 it doesn\u2019t seem to help.Surprisingly sticking with Universal Analytics rather than upgrading to GA4 made a bigger difference to the numbers than implementing Server-Side. When Pageviews are the same but Users and Sessions are higher, that\u2019s a bad thing \u2013 it means we failed to stitch together those Sessions or recognize those Users when they came back. We inflated Users by 9 and counted 53 more Sessions with GA4 vs UA. This is probably due to some of the way GA4 has changed how events and sessions are calculated, but it looks like a step backwards. Enhanced actually did worse, in that they slightly inflated sessions (you would think they\u2019d be better able to stitch sessions together, by tracking more events automatically).Finally my pixel experiment was kind of weird. I tracked 54 Users\u2026 but there shouldn\u2019t have been any!? I passed 555 (a code for anonymous) in the tracking hit and passed no User ID, so I\u2019m not sure how there could have been any users tracked. I am also unsure as to how it tracked Sessions\u2026 is Google passing back a cookie somehow when I ping their API, even through Server-side Tracking? In any event I tracked 30 more Pageviews which was interesting. Potentially these are bot hits(?) or people refreshing the page, but judging by this I think it\u2019s worth adding some sort of \u2018log level\u2019 tracking to your app if you care about raw counts of an event.Update: 28 days dataOne question I immediately got was \u201ccan we see more than a week\u2019s worth of data\u201d? That\u2019s because Apple\u2019s Intelligent Tracking Prevention in Safari clears cookies after 7 days, so the effect would show up over a longer time period. Here\u2019s the same data but for the last 28 days \u2013 24th May to 20th June 2021.Looking over a longer 4-week timeframe, we can see that standard UA inflates your User count by about 35%, and your sessions by 6.5%. This is compared to about 25% user inflation, and no inflation of sessions for 7 days data \u2013 this difference could very well be the \u2018ITP-effect\u2019 we were looking for. GA4 inflated users by only 1% over 28 days, compared to 6% on a week\u2019s data, so this is very likely to be just a sampling or counting issue, nothing major to worry about."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Conclusions' for the blog post 'How much lost data does Server-Side Tracking actually help you recover?'"}, {"role": "assistant", "content": "This is a pretty limited experiment, and most businesses aren\u2019t small personal blogs so they have good reasons to track users. However I\u2019d say in this case at least, the answer is that Server-Side Tracking isn\u2019t a silver bullet! It doesn\u2019t seem to perform any better than the standard implementation of GA4 in recovering lost pageview data (i.e. people blocking tracking all together), though it does seem better at stitching together unique Users, deflating unique users by 35%, which is huge! That has important implications for advertising attribution, for example tracking people who clicked on an ad and then came back later to purchase \u2013 better stitching together of Users means better attribution to the right channels. The data might have been different if I ignored user privacy and didn\u2019t anonymize IPs, so I\u2019d love to see data there if anyone is willing to test it? There\u2019s definitely something to be said about tracking log level anonymous events with an image pixel, or some better method, but for an 8% boost in Pageviews it\u2019s probably not worth it. If anyone else has run a similar experiment and has different findings, I\u2019d love to hear about it!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Unpacking Value-Based Pricing' for the blog post 'The Dangers of Value Based Pricing in Agencies'"}, {"role": "assistant", "content": "In the contentious world of agency pricing, one debate has been going on forever: value-based pricing vs cost-based. The appeal of value-based pricing? A potential increase in profits, a shared focus on quality, and a tighter bond between agency and client. However, reality often reveals a different story.In my journey as the founder of Ladder, a 50-person marketing agency, I've had my fair share of encounters with the challenges of value-based pricing. This article will serve as your map, guiding you through the uncharted territories of this complex pricing strategy.Value-based pricing sounds straightforward enough: price your services based on the value your clients perceive they're getting, not just on your costs or what your competitors are charging. But here's the catch: value is a slippery concept, and it varies wildly from client to client.Think of it this way: it's like trying to price a painting. One person might see a priceless masterpiece, while another sees something their kid could have drawn. Therein lies the first challenge of value-based pricing \u2013 its subjectivity.Yet, the idea of potentially higher profits and a client-aligned model lures many of us in. I've watched this scenario play out at Ladder and in numerous other agencies. The appeal of value-based pricing is strong, but it's crucial to know what you're stepping into."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'The Attraction of Value-Based Pricing: More Than Meets the Eye' for the blog post 'The Dangers of Value Based Pricing in Agencies'"}, {"role": "assistant", "content": "The allure of value-based pricing is powerful. It's like a shiny new toy in the world of agency management. It whispers of higher earnings, satisfied clients, and a business model that aligns everyone's interests. Who wouldn't want to make more money? It's a tale that's hard to resist. I've been there myself, bewitched by the promise it holds.In some cases, value-based pricing can be the boost that introverted founders need. Those who, in their pursuit of honor and fairness, might seriously undervalue their product or service. This strategy can help them charge more - advice famously given by Patrick McKenzie, better known as @patio11, in his famous post \"You Can Probably Stand To Charge More\", which might be a contender for blog posts that have delivered the most collective increase in net worth.But there's a cautionary tale here too. It's easy to be drawn in by industry \"gurus\" who paint a rosy picture of value-based pricing. They'll tell you it's the next big thing, the secret to scaling your agency, and that you\u2019re a fool for leaving money on the table. However, it's essential to separate the hype from the reality. The potential benefits of value-based pricing are real, but they don't come easy. It's a path that requires careful navigation, strategic decision-making, and a deep understanding of your clients' needs and perceptions."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'The Reality Check: A Case Study from Ladder' for the blog post 'The Dangers of Value Based Pricing in Agencies'"}, {"role": "assistant", "content": "Let's step back from theory and dive into a real-world example. At Ladder, we once grappled with the challenge of pricing our tracking implementation service. On paper, value-based pricing seemed like the perfect strategy. After all, correct tracking can unlock enormous value for clients by providing them with crucial data to make informed decisions.But here's where the reality of value-based pricing kicked in. Our clients, mostly non-technical, often underestimated the complexity involved in proper tracking setup. As a result, the perceived value of the service was often much lower than its actual cost. In our attempt to align the price with perceived value, we ended up underpricing our service, leading to lower-than-expected revenues.I think this is the reason why professions such as accountancy and law typically charge by the hour rather than the value. Their clients, not being experts in these fields, often underestimate the complexity of the work. Unforeseen issues can turn into extra billable hours. If they were to charge a fixed fee based on perceived value, they'd risk undercharging and potentially even bankruptcy for prolonged engagements.While value-based pricing can be effective in certain situations, it's not always the best strategy. It's crucial to ensure that your costs are covered in any scenario, and then consider any additional earnings as upside."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'The Dangers of Value-Based Pricing' for the blog post 'The Dangers of Value Based Pricing in Agencies'"}, {"role": "assistant", "content": "Despite its potential benefits, value-based pricing is not without its perils. Its implementation requires a deep understanding of your customers' perceived value of your services, which can be incredibly complex and difficult to gauge. Misjudging this can lead to undercharging for your services, as we experienced at Ladder.Moreover, value-based pricing can inadvertently encourage a focus on short-term gains at the expense of long-term client relationships. If not carefully managed, this approach might lead to charging high prices without truly delivering corresponding value. This can damage your reputation and client relationships in the long run.One of the biggest risks of value-based pricing is the financial danger if you get the pricing wrong. If a contract turns out to be more challenging or time-consuming than initially expected, you may find yourself on the hook to deliver at a loss. In extreme cases, this could even lead to bankruptcy, particularly for smaller agencies or those with tighter margins.In sectors where the perceived value is significantly higher than the actual cost, or where a company holds a monopoly, value-based pricing can work effectively. However, in competitive markets where your brand is not well-known or where others can easily replicate your services, this pricing strategy can be more challenging.Finally, the implementation costs of value-based pricing can be higher due to the need for extensive research and effort to differentiate your service. Yet, despite these challenges, it's essential to remember that pricing strategies are not one-size-fits-all. Each agency must find a balance that works best for its unique situation."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Mitigating the Risks of Value-Based Pricing' for the blog post 'The Dangers of Value Based Pricing in Agencies'"}, {"role": "assistant", "content": "While value-based pricing comes with its own set of challenges, there are strategies to mitigate these risks and increase your chances of success. Here are some strategies:Ensure Costs are Covered: First and foremost, always ensure your costs are covered even in the worst case scenario. This approach provides a safety net, preventing any potential loss. For example we had a non-negotiable \u2018base\u2019 fee which covered our fixed costs, then the remaining fee was flexible based on performance.Regularly Review Pricing: Value changes over time as the market changes, competitors emerge, and as you build more credibility in the industry. Adjust your pricing strategy as you gain more knowledge and experience, or if competitive threats arise.Communicate Value: Clearly communicate the value your clients receive. Transparency helps build trust and sets the stage for long-term relationships, and the more perceived value you can transmit, the easier time you\u2019ll have charging more.Consider Tiered Services: providing tiered services allows clients to choose the level of service that matches their perceived value. This way, you can cater to different value perceptions and budget levels, with a mix of cost-plus and value-based pricing.Differentiate Your Services: Carve out a niche where you can truly excel and be recognized as a leader. This can help create a quasi-monopoly situation, enabling you to command higher prices based on your unrivaled expertise. Be selective with your clients and only work with those who recognize and appreciate the value you provide, or you risk burning out your team and tying up resources in bad relationships.Value-based pricing can be a powerful tool when used correctly. By being aware of the risks and taking steps to mitigate them, you can better align your services with your clients' perceived value and potentially unlock higher revenues."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Conclusion' for the blog post 'The Dangers of Value Based Pricing in Agencies'"}, {"role": "assistant", "content": "Value-based pricing in agencies is a complex yet rewarding pricing model. It's not a one-size-fits-all solution and demands a deep understanding of your clients' needs and perceived value, along with a keen awareness of market dynamics.While value-based pricing can potentially maximize revenue, it also requires diligent risk management. Remember to cover your costs, continue to learn and adapt, communicate transparently, and differentiate your services. Consider a hybrid model if value-based pricing seems too risky.Ultimately, the choice of a pricing model should be a strategic decision that aligns with your agency's capabilities, your clients' needs, and the market you operate in. As with all things in business, it's about finding the right balance.-----Note: this post was generated with AI assistance by ChatGPT, based on my answers to interview questions on the topic. If you want to see my process including all the prompts, it's outlined here: https://www.saxifrage.xyz/post/ai-writer"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Participation Rate' for the blog post 'Viral Growth Loops'"}, {"role": "assistant", "content": "Virality rarely just happens \u2014 like any good growth channel it needs to be engineered. The first step is mapping out your viral growth loops. What are the different stages a user goes through from experiencing your product for the first time, to participating in the sharing of your product. The output of this process should lead to the input for the beginning of the loop.To show how this works, let's map out a classic example of a viral growth loop \u2014 social networks.When we have a model like this built for the viral loop we plan to use to grow our business, we can make better decisions about what to optimize and model out its potential impact, as well as forecast future growth numbers. Let's go through each part of the model one by one, and define each metric. If you're interested in diving deeper into actually building a model of these calculations, check out our post on Modeling Viral Growth.When you sign up a new user, how many of those users invite their friends or colleagues? The core focus of the Facebook growth team was getting new users to 7 friends in 10 days, as this increased both virality and retention \u2014 Facebook is useless if your friends don't use it. For a social network this metric is key, as you can count any user that doesn't invite friends as lost.In our model we assumed 75% of users participate in sharing with friends. So if we have 100 new users, then 100 x 0.75 = 75 of them will invite friends."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Branching Factor' for the blog post 'Viral Growth Loops'"}, {"role": "assistant", "content": "When someone invites their friends or colleagues, how many do they send? Some might invite only 1 or 2 close friends, others might spam their entire address book. For Facebook it was 7 friends, but the average will vary depending on the product, audience and how well optimized the invitation flow is.For this model we assumed every user that participates in sharing, invites 7 people on average. In this case, with 75 people inviting friends, then 75 x 7 = 525 people will receive invites."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Clickthrough Rate' for the blog post 'Viral Growth Loops'"}, {"role": "assistant", "content": "If someone receives an invite to join, how many people click through to the website or app? This percentage will be highly dependent on how compelling the value proposition is, as well as their relationship to the friend or coworker that invited them. For example it would be high for a social network where you're invited to talk to a close friend, but much when someone you went to high school with invites you to play Candy Crush so they can earn in-game items.In the model we assumed a 50% clickthrough rate. This means that for 525 invites, we'll generate 525 x 0.5 = 263 clicks, or new visitors."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Conversion Rate' for the blog post 'Viral Growth Loops'"}, {"role": "assistant", "content": "When a new visitor arrives on your site, what's the probability they sign up to be a new user? Conversion rate optimization is a whole discipline in itself, and practitioners know that by removing friction and using psychological tricks, you can always find a way to get more users to convert. This is also dependent on trust, both of the platform they're signing up to and the friend that invited them \u2014 to some extent one can substitute for another.For the model we assumed a 40% conversion rate for our social network. From the 263 new visitors we drove through invites, we would expect to sign up 263 x 0.4 = 105 new users."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Viral Coefficient' for the blog post 'Viral Growth Loops'"}, {"role": "assistant", "content": "Finally, the last metric that factors in all proceeding metrics. Also called K-Factor (or in epidemiology, R0 or R-naught), this is a measure of how many new users you get through sharing, for every new user you acquire through other means. This is the primary measure of virality, and its importance can't be understated. If you manage to push this number above 1, you get more users in each cycle than you started with, meaning you will start to grow exponentially.You can calculate this metric by multiplying all previous metrics. So in our model 0.75 x 7 x 0.5 x 0.4 = 1.05. Alternatively you can divide the number of new users you get at the end by the users you started with, so 105 / 100 = 1.05."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Growth Multiplier' for the blog post 'Viral Growth Loops'"}, {"role": "assistant", "content": "In practice a Viral Coefficient of more than 1 is extremely difficult to achieve and sustain for any length of time \u2014 if you're lucky enough to 'go viral' you often saturate your audience and see a rapid decline when there's no one left to sign up. However every basis point of virality is valuable to your business, because it makes every other marketing channel perform more efficiently.For example imagine you were paying $10,000 to acquire 500 people on Facebook, a $20 cost per acquisition. Increase your Viral Coefficient to 0.20 by encouraging sharing, and those 500 people will bring 100 more, who themselves will bring 20, who bring 4.This downstream impact of new signups is called the Growth Multiplier, and you can work it out by dividing one by one minus the Viral Coefficient. So a viral coefficient of 0.2 would give you a growth multiplier of 1/(1-0.2) = 1.25. This means that every new user you drive from Facebook ads is worth 1.25 users \u2014 you can afford to pay 25% more for user acquisition.Note: this formula doesn't work for Viral Coefficients higher than 1, because they trend to infinity. Instead you must choose a time period to predict, or number of cycles into the future. The formula for this initial users x (viral coefficient ^ (cycle + 1) - 1) / (viral coefficient - 1). So for our viral coefficient of 1.05, to see 10 cycles into the future this would work out to be 100 x (1.05 ^ (10 + 1) - 1) / (viral coefficient - 1) = 1421 total users."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Week 1:' for the blog post 'Zero-Party Data: What Marketing Without Cookies Could Look Like (30 Day Playbook)'"}, {"role": "assistant", "content": "I\u2019ve had the term \u2018data-driven\u2019 in my LinkedIn profile for 10 years \u2013 and I\u2019m dreaming of a world without cookie data.I know more than most about how data gets used and abused in marketing \u2013 I came into the industry from an MSc in Economics, and have since been responsible for: $50m+ spend on Google and Facebook, founding a 50-person growth agency, teaching people data-driven marketing techniques... and I even learned to code so I could better work with big data.Now that the marketing world is reeling from the impact of Apple\u2019s privacy updates in iOS 14, and the wider privacy backlash from consumers, I have been thinking a lot about how my job would change if all user data went away.Would it bring about the marketing equivalent of the dark ages? Is this the death of marketing? Will we all lose our jobs? No, that's unlikely\u2026 advertising has been consistently 1% of GDP since the 1920s, so it couldn\u2019t get that bad. How bad would it be? Does it have to be bad? Could it be\u2026 better?\u00a0Maybe we could just do whatever we wanted without data to tell us otherwise? Perhaps we\u2019d go back to the Golden Age of Advertising and 3-Martini lunches? Yeah right\u2026 we\u2019re Math Men (and Women) now, not Mad Men: to make decisions we need data, and in this day and age, that means explicit informed consent.https://lafleur.marketing/blog/six-mad-men-marketing-tips-don-draper/Only using data your users have explicitly consented to is apparently called \u2018Zero-Party Data\u2019. As opposed to First-Party Data (assumed consent), Second-Party Data (from a partner), and Third-Party (traded online). I heard it first from Matt Bahr who runs a Post Purchase Survey Tool on Shopify, but I\u2019m now seeing it pop up everywhere as consultants / thought leaders see an opportunity to cash in.\u00a0As an operator in this space, I thought it\u2019d be more fun to do a thought experiment: if I was put in charge of growth for an Ecommerce company, how would I run marketing without user data? On day one of the new job, the UN declares all user-level tracking is banned, under the Universal Data Protection Regulation (UDPR). Only aggregated data (minimum cohort size: 30 people) is allowed, or you get fined 10% of revenue. How would I still do my job?\u00a0This would be my playbook in the first 30 days:I\u2019d rip out Google Analytics, the Facebook Pixel and every other unnecessary tracker. My dev team would thank me for shaving a few milliseconds off the page load speed, and conversion rate would go up a few percentage points in low bandwidth areas. I install a Privacy Friendly Analytics solution (or hack GA) that just counts Aggregated Data like pageviews and conversion events alongside meta-data on marketing channels.We\u2019d need to hack together a solution to track what ad campaigns drove conversions, so I\u2019d grab UTM parameters from the URL and store it in Local Storage (yes it\u2019s like cookies, but there\u2019s no Personally Identifiable Information (PID): just what channel they came from). When a user adds to cart or purchases I\u2019d fire an event, passing the utm source, medium and campaign.Then the real work begins! The first thing I\u2019d do is start sending out post-purchase User Surveys to the \u2018Thank You\u2019 page and the confirmation email (a purchase is consent!), that asks 3 questions:\u00a0How did you hear about us?How would you feel if you could no longer use our product?How likely are you to recommend us on a scale from 0 to 10?https://support.squarespace.com/hc/en-us/articles/360002095368-Adding-a-referral-survey-to-checkoutI\u2019d set the responses to come into a shared inbox or slack channel, and make sure they know they can hit reply to contact me directly (not one of those \u2018no-reply@\u2019 addresses. Anyone that responded negatively I\u2019d auto-escalate to customer support, and those that responded positively would get (optional) follow up questions so I could learn more about them.Then I\u2019d run a few SQL queries to do an RFM Analysis, getting a list of customers by Recency (when did they last purchase), Frequency (how often did they purchase) and Monetary value (how much did they spend). I\u2019d shoot off an email to the top 100 customers across all three dimensions introducing myself and offering a 15 minute call if they would mind giving feedback."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Week 2:' for the blog post 'Zero-Party Data: What Marketing Without Cookies Could Look Like (30 Day Playbook)'"}, {"role": "assistant", "content": "I have started my mission of actually Talking to Customers by taking calls and responding to emails. As I do so, I take note of the words they use to describe their problems, objections and how our products make them feel. I then start using our customers\u2019 words wherever possible in the adcopy of our ads, on the blog and website, and in our emails. This will Optimize Conversion Rate sitewide, which needs to happen to make up for the loss of personalized targeting.At the end of each customer conversation I ask if I could send them a small gift to say thanks, and get their address. That goes into an Airtable which pings an API to automatically mail them some company SWAG and 3 x 20% off Discount Vouchers: 1 for them and 2 for their friends.Now I\u2019ve talked to a couple of customers, and have seen the early post-purchase surveys, we can start thinking about our ad campaigns. It\u2019s been a week since the UN banned user-level tracking, so let\u2019s turn off any Non Converting Campaigns and cut spending for any that aren\u2019t under our CAC target (as reported by our hacked together solution).Now let\u2019s think about Contextual Targeting: based on what we know from our customer calls, where do similar people hang out online (or offline)? Are there ways we can get in front of them? Find creative ways to advertise anywhere that over-indexes on your audience. For example if you hear the name of a blog 3 times just cold email or tweet at the blog owner and pay them $500 to sponsor the blog: no tracking or affiliate links, just a simple banner and a few naturally placed mentions.At this point I\u2019d also start Deprivation Testing. Take something that nobody very senior is passionate about, that costs us a lot of money, but might have questionable incrementality, and just\u2026 turn it off. See if anyone complains or if the numbers dip. If you\u2019re risk-averse try just turning it off in one country or region. Good candidates for this type of test are Brand Keyword Ads, or Retargeting Ads or a Voucher code affiliate partner: chances are you get an easy win!https://medium.com/pinterest-engineering/demystifying-seo-with-experiments-a183b325cf4c"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Week 3:' for the blog post 'Zero-Party Data: What Marketing Without Cookies Could Look Like (30 Day Playbook)'"}, {"role": "assistant", "content": "The honeymoon period is probably over by now. At this point I\u2019d expect to have had at least a few negative customer calls and the cuts to advertising would have probably slowed top line growth. I\u2019d still have some breathing room because of how unprecedented the UN\u2019s legislation was, and the CEO\u2019s drinking buddies would be confirming that marketing performance is down across the board, but that\u2019s no excuse not to get things moving up and to the right.Now to really move the needle with our secret weapon: Creative Strategy. I\u2019d have a good enough grounding in why people buy from my interviews and surveys to form some hypotheses about how we can get them to buy more. I\u2019d write these up in the GET / WHO / TO / BY framework, aligned to the different user personas I\u2019ve noticed in my research. There isn\u2019t time to commission an agency or team of freelancers, so I\u2019d go it alone with Canva, Copy.ai and a bottle of Rum (write drunk, edit sober).I\u2019d turn off all existing ads except one: the current best performer. Then I\u2019d replace the old ads I turned off with the best new ad concepts I came up with. I\u2019d go for bigger bolder concept level changes, rather than smaller variations, and I\u2019d just stick them in the same ad sets rather than attempting a split test, just for speed \u2013 we\u2019re looking for big wins here not scientific proof.https://mobiledevmemo.com/mobile-ad-creative-how-to-produce-test-and-deploy-advertising-creative-at-scale/Finally I\u2019d feel ready to attempt a win back campaign. I\u2019d look at any customers from my RFM analysis that had high monetary value and frequency, but low recently: i.e. they used to be a good customer but now they\u2019re slipping away. They\u2019ll be especially unlikely to respond, so you\u2019d have to try something big: offer an item completely free (just pay for shipping), insider access to test a new product line, or a chance to win a generous prize (make it something only your ideal persona would want, nothing generic like an iPad)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Week 4:' for the blog post 'Zero-Party Data: What Marketing Without Cookies Could Look Like (30 Day Playbook)'"}, {"role": "assistant", "content": "This is where everything comes together. You have the infrastructure you need: you\u2019ve got aggregate campaign level data coming from your hacked together analytics setup. You have rich survey data to calibrate the attribution from analytics, and you continue to personally take customer calls to keep your ear to the ground and train your gut intuition on what they want.\u00a0I\u2019d do one more round of ad optimization: turn off or cut your worst campaigns, brainstorm new contextual placements to replace them and scale budgets on the channels that are working. Cut your worst performing ad concepts, and bring in freelancers to create better variants of your best performers, while adding new concepts and themes into the mix.Finally I\u2019d do some rudimentary Marketing Mix Modeling. In about 4-8 hours you can build a basic Econometric model in GSheets that will backup and calibrate your existing insights from customer interviews, privacy-friendly tracking and deprivation testing. Combining these methods you could triangulate a single truth about what\u2019s working (or not) in your marketing, and elevate your decision-making above guesswork (all without using any non-consensual user data!). All of this would go in a nice presentation for the boss \u2013 fingers crossed!https://www.saxifrage.xyz/post/econometrics-gsheets"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Write the section 'Week 5+:' for the blog post 'Zero-Party Data: What Marketing Without Cookies Could Look Like (30 Day Playbook)'"}, {"role": "assistant", "content": "Assuming I kept the job (for now, marketers have the shortest tenure), this is what I\u2019d do to consolidate my wins.Talking to Customers: It sometimes feels like a distraction, but there\u2019s nothing better for building intuition on what will work in marketing: quantitative is precise, but qualitative is fast, and it\u2019s speed you need when you\u2019re making most of your decisions.Aggregated Data: This is the new normal: don\u2019t expect to be able to drill into a user profile until they\u2019ve given permission. The truth is most user-level data sits in data warehouses and never gets looked at: you aren\u2019t missing much.User Surveys: People lie on surveys, but their cookie data lies too, just in different ways (seriously check out some of the things Google \u2018knows\u2019 about you). The right questions properly calibrated with other techniques, can be remarkably accurate for attribution.Contextual Targeting: To be honest, the best ads were always contextual and retargeting was never that incremental. Google\u2019s not worried about cookies going away, because it doesn\u2019t take a cookie to serve printer ads to someone searching for printers.Deprivation Testing: For the really big decisions, there\u2019s no substitute for A/B testing. For channels where you can\u2019t easily A/B test, find ways to turn it off for a randomly assigned group of people: make a change on 50% of your URLs or just in one country.Creative Strategy: you can never get enough of this. The best creative ideas work on any medium and can pay dividends for decades. \u201cNever stop testing and your advertising will never stop improving\u201d - no it wasn\u2019t a growth hacker that said that, it was David Ogily back in the 60s (pre-internet, for those paying attention)Marketing Mix Modeling: I\u2019d work with a vendor or hire an internal team to do MMM properly, using Python code or R to make it more scalable. This would be the primary source of truth for budget allocation once per quarter, though I\u2019d do small weekly or biweekly updates to track the accuracy of predicted vs actuals.I hope that was a useful exercise: now back to reality. You should probably do all of that stuff even if you don\u2019t expect tracking to go away anytime soon! It\u2019s just good marketing. The fundamentals. Basic stuff. It\u2019s actually surprisingly easy to think of ways to improve marketing effectiveness without invading user privacy. In fact, when you think about it, how often do you even use all that data? I\u2019m not worried about a post-data world: in fact I think it might even lead to better outcomes!Oh and if you\u2019re reading this and thinking \u201cwe should just hire Mike to do this for us\u201d, I\u2019m working full time on my own business after leaving my other business and I really promised myself I wouldn\u2019t take another job. So unless you\u2019re offering some ludicrous amount of money, or are working to make the human race interplanetary, offer the opportunity to some ambitious young intern instead, and hand them this guide."}]}
