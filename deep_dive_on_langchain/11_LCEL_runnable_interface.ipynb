{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Expression Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchain_openai langchain-community --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"API_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the basic syntax of [LangChain Expression Language](https://python.langchain.com/docs/expression_language/), which uses the pipe symbol `|` to connect components. Each component represents a specific task or action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it as easy as possible to create custom chains, LangChain implemented a `Runnable` protocol. The Runnable protocol is implemented for most components. This is a standard interface, which makes it easy to define custom chains as well as invoke them in a standard way. The standard interface includes:\n",
    "\n",
    "- `stream`: stream back chunks of the response\n",
    "- `invoke`: call the chain on an input\n",
    "- `batch`: call the chain on a list of inputs\n",
    "\n",
    "These also have corresponding async methods:\n",
    "\n",
    "- `astream`: stream back chunks of the response async\n",
    "- `ainvoke`: call the chain on an input async\n",
    "- `abatch`: call the chain on a list of inputs async\n",
    "- `astream_log`: stream back intermediate steps as they happen, in addition to the final response\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Runnable Protocol:\n",
    "\n",
    "A unit of work that can be invoked, batched, streamed, transformed and composed.\n",
    "\n",
    "All methods accept an optional config argument, which can be used to configure execution, add tags and metadata for tracing and debugging etc.\n",
    "\n",
    "Runnables expose schematic information about their input, output and config via the input_schema property, the output_schema property and config_schema method.\n",
    "\n",
    "The LangChain Expression Language (LCEL) is a declarative way to compose Runnables into chains. Any chain constructed this way will automatically have sync, async, batch, and streaming support.\n",
    "\n",
    "The main composition primitives are `RunnableSequence` and `RunnableParallel`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.schema.runnable.base.RunnableLambda'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "print(type(RunnableLambda(lambda x: x + 1))) # <class 'langchain.schema.runnable.RunnableLambda'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableLambda(lambda x: x + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RunnableSequence\n",
    "\n",
    "`RunnableSequence` invokes a series of runnables sequentially, with one runnable’s output serving as the next’s input. Construct using the `|` operator or by passing a list of runnables to RunnableSequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.schema.runnable.base.RunnableSequence'>\n",
      "\n",
      "\n",
      "---\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4, 6, 8]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A RunnableSequence constructed using the `|` operator\n",
    "sequence = RunnableLambda(lambda x: x + 1) | (lambda x: x * 2)\n",
    "\n",
    "print(type(sequence)) # <class 'langchain.schema.runnable.RunnableSequence'>\n",
    "print('\\n\\n---')\n",
    "print(sequence.invoke(1)) # 4\n",
    "sequence.batch([1, 2, 3]) # [4, 6, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RunnableParallel\n",
    "\n",
    "The `RunnableParallel`, allows for multiple runnables to be invoked in parallel, construct using a dictionary of runnables to invoke in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mul_2': 4, 'mul_5': 10}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A sequence that contains a RunnableParallel constructed using a dict literal\n",
    "sequence = RunnableLambda(lambda x: x + 1) | {\n",
    "    \"mul_2\": RunnableLambda(lambda x: x * 2),\n",
    "    \"mul_5\": RunnableLambda(lambda x: x * 5),\n",
    "}\n",
    "sequence.invoke(1)  # {'mul_2': 4, 'mul_5': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "## Combining the output of multiple runnables into a single response\n",
    "\n",
    "A sequence that contains a RunnableParallel constructed using a dict literal, this is then followed by a RunnableLambda that consumes the output of the RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = RunnableLambda(lambda x: x + 1) | {\n",
    "    'mul_2': RunnableLambda(lambda x: x * 2),\n",
    "    'mul_5': RunnableLambda(lambda x: x * 5)\n",
    "} | RunnableLambda(lambda x: x['mul_2'] + x['mul_5'])\n",
    "sequence.invoke(1) # {'mul_2': 4, 'mul_5': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.schema.runnable.base.RunnableParallel'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "parallel = RunnableParallel({\n",
    "    'mul_2': RunnableLambda(lambda x: x * 2),\n",
    "    'mul_5': RunnableLambda(lambda x: x * 5)\n",
    "})\n",
    "\n",
    "# This is a dictionary, however it will be composed with other runnables when used in a sequence:\n",
    "parallel_two = {\n",
    "    'mul_2': RunnableLambda(lambda x: x['input_one'] * 2),\n",
    "    'mul_5': RunnableLambda(lambda x: x['input_two'] * 5)\n",
    "}\n",
    "\n",
    "print(type(parallel)) # <class 'langchain.schema.runnable.RunnableParallel'>\n",
    "print(type(parallel_two)) # <class 'dict'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = parallel | RunnableLambda(lambda x: x['mul_2'] + x['mul_5']) \n",
    "chain.invoke(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_chain = parallel_two | RunnableLambda(lambda x: x['mul_2'] + x['mul_5']) \n",
    "second_chain.invoke({'input_one': 5, 'input_two': 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "\n",
    "### You only need a _`Runnable` at the start_, you can use other Python functions _after the first `Runnable`_\n",
    "\n",
    "Technically you only need a `RunnableLambda` or `RunnableParallel` as the first expression after that you can use Python functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <lambda> at 0x7f9a1019a160>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_y/20jl658s4jl0zvy5c0x0c5140000gn/T/ipykernel_27474/765711858.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;34m|\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "parallel = RunnableParallel({\n",
    "    'mul_2': RunnableLambda(lambda x: x * 2),\n",
    "    'mul_5': RunnableLambda(lambda x: x * 5)\n",
    "})\n",
    "\n",
    "# This is bad practice:\n",
    "test = lambda x : x + 1  | parallel\n",
    "print(test)\n",
    "test.invoke(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=RunnableLambda(lambda x: x + 1) last={\n",
      "  mul_2: RunnableLambda(...),\n",
      "  mul_5: RunnableLambda(...)\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mul_2': 12, 'mul_5': 30}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is good practice:\n",
    "test = RunnableLambda(lambda x: x + 1) | parallel\n",
    "print(test)\n",
    "test.invoke(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Combining Steps in A Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "parallel = RunnableParallel({\n",
    "    'item_one': RunnableLambda(lambda x: f\"Hello {x['name']} \"),\n",
    "    'item_two': RunnableLambda(lambda x: 'Welcome to the World!')\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(x):\n",
    "    return x['item_one'] + x['item_two']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello James Welcome to the World!'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_chain_example = parallel | combine\n",
    "parallel_chain_example.invoke({'name': \"James\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_example = RunnableLambda(lambda x: {'item_one': 'Hello ', 'item_two': 'World'})\n",
    "lambda_chain_example = lambda_example | combine\n",
    "lambda_chain_example.invoke({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
