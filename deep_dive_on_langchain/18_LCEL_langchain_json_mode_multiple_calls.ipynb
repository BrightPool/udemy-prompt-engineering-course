{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install langchain langchain_openai langchain-community --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"API_KEY_HERE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers.json import SimpleJsonOutputParser "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", \n",
        "                  model_kwargs={'response_format': {\"type\": \"json_object\"}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "chat_prompt = ChatPromptTemplate.from_messages(\n",
        "    (\"system\", \"\"\"I want you to extract the person name, age and a description from the following text.\n",
        "    Here is the JSON schema:\n",
        "    \"name\": string\n",
        "    \"age\": int\n",
        "    \"description\": string\n",
        "    {message_to_extract}\n",
        "    --- \n",
        "    If there are multiple people, then put them in a 'persons' key, which is a list of the above schema.\n",
        "    \"\"\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "chain = (\n",
        "    chat_prompt\n",
        "    | chat\n",
        "    | SimpleJsonOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'persons': [{'name': 'James', 'age': 30, 'description': 'James is a software engineer, he likes to play tennis and he lives in London.'}, {'name': 'John', 'age': 35, 'description': 'John is a data engineer and he lives in New York, He likes to play football.'}, {'name': 'Mark', 'age': 40, 'description': \"Mark is a Java Developer and he lives in London. He doesn't have many hobbies.\"}]}\n"
          ]
        }
      ],
      "source": [
        "multiple_results = chain.invoke({\n",
        "    \"message_to_extract\": '''James is 30 years old and he is a software engineer, he likes to play tennis and he lives in London.\n",
        "    John is 35 years old and he is a data engineer and he lives in New York, He likes to play football.\n",
        "    Mark is 40 years old is a Java Developer and he lives in London. He doesn't have many hobbies.\n",
        "    '''\n",
        "})\n",
        "\n",
        "print(multiple_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parallel Function Calling with Pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic.v1 import BaseModel\n",
        "from typing import List\n",
        "from langchain.chains.openai_tools import create_extraction_chain_pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make sure to use a recent model that supports tools\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Person(BaseModel):\n",
        "    \"\"\"A person object that we want to extract from the text\"\"\"\n",
        "    name: str\n",
        "    age: int\n",
        "\n",
        "# Previous we had to write this:\n",
        "class Persons(BaseModel):\n",
        "    persons: List[Person]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "chain = create_extraction_chain_pydantic(Person, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Person(name='James', age=30), Person(name='Sarah', age=26)]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"James is 30 and Sarah is 26 years old.\"})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
