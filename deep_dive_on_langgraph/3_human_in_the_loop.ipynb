{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3931b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langsmith langchain-openai tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0828830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6d3dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c52923c-5665-4f8c-a1ba-9799e369c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1da240-ec9b-441f-9d47-44c6dc85d540",
   "metadata": {},
   "source": [
    "## Human-in-the-loop\n",
    "\n",
    "Agents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended.\n",
    "\n",
    "LangGraph supports `human-in-the-loop` workflows in a number of ways. In this section, we will use LangGraph's `interrupt_before` functionality to always break the tool node.\n",
    "\n",
    "First, start from our existing code. The following is copied from Part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a81608a-373a-4339-b1c6-65b73a92b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813505b2-18c1-46e9-b891-20a34232808b",
   "metadata": {},
   "source": [
    "Now, compile the graph, specifying to `interrupt_before` the `action` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0883e32-1a39-4ce9-ae32-bbd66708fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # This is new!\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # Note: can also interrupt __after__ actions, if desired.\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f318020-ab7e-415b-a5e2-eddec6d9f3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_QbncOjIgKqiyOVED2gmMbeTA)\n",
      " Call ID: call_QbncOjIgKqiyOVED2gmMbeTA\n",
      "  Args:\n",
      "    query: LangGraph programming language overview\n",
      "  tavily_search_results_json (call_6K6AuOBkfaor6qQAyGW3V9FE)\n",
      " Call ID: call_6K6AuOBkfaor6qQAyGW3V9FE\n",
      "  Args:\n",
      "    query: LangGraph tutorials and learning resources\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39405637-13b1-40b1-a51e-6d60bf675ff1",
   "metadata": {},
   "source": [
    "Let's inspect the graph state to confirm it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bb7af46-9b4f-4bb1-b8b9-e9ddf7dbc82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89326046-2b11-4812-8b6d-8780306ec275",
   "metadata": {},
   "source": [
    "**Notice** that unlike last time, the \"next\" node is set to **'action'**. We've interrupted here! Let's check the tool invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3facda0a-e6ad-4b28-b627-753ad8c90c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'LangGraph programming language overview'},\n",
       "  'id': 'call_QbncOjIgKqiyOVED2gmMbeTA'},\n",
       " {'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'LangGraph tutorials and learning resources'},\n",
       "  'id': 'call_6K6AuOBkfaor6qQAyGW3V9FE'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "existing_message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55a4c70-7226-4be0-8562-391f72bc1f2b",
   "metadata": {},
   "source": [
    "This query seems reasonable. Nothing to filter here. The simplest thing the human can do is just let the graph continue executing. Let's do that below.\n",
    "\n",
    "Next, continue the graph! Passing in `None` will just let the graph continue where it left off, without adding anything new to the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "effb95d9-b7d5-40c5-9253-253d193b23b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://langchain-ai.github.io/langgraph/tutorials/\", \"content\": \"These notebooks introduce LangGraph through building various language agents and applications. Introduction to LangGraph\\u00b6 Learn the basics of LangGraph through the onboarding tutorials. Introduction to LangGraph; Use cases\\u00b6 Learn from example implementations of graphs designed for specific scenarios and that implement common design patterns ...\"}, {\"url\": \"https://github.com/LangGraph-GUI/LangGraph-learn/\", \"content\": \"Introduction. LangGraph-learn is designed to foster a collaborative learning environment for individuals interested in AI and machine learning. Our goal is to provide practical examples and tutorials that demonstrate how to use LangGraph, LangChain, and other related tools to build efficient and reusable workflows involving language models.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here's a summary of the information I found about LangGraph:\n",
      "\n",
      "### Overview of LangGraph\n",
      "1. **LangGraph** is a library focused on building stateful, multi-actor applications using Large Language Models (LLMs). It extends the LangChain Expression Language by enabling the coordination of multiple chains (or actors) across different tasks.\n",
      "   - **Source**: [Medium Guide on LangGraph](https://medium.com/@bhavikjikadara/langgraph-a-comprehensive-guide-for-beginners-ef17d3dd5383)\n",
      "   - **Source**: [Introduction to LangGraph](https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141)\n",
      "\n",
      "### Tutorials and Learning Resources\n",
      "1. **Official LangGraph Tutorials**: The LangGraph tutorials introduce the basics through various notebooks. These resources provide practical examples and demonstrate how to build language agents and applications using LangGraph.\n",
      "   - **Source**: [LangGraph Tutorials](https://langchain-ai.github.io/langgraph/tutorials/)\n",
      "\n",
      "2. **LangGraph-Learn on GitHub**: This repository is designed to foster a collaborative learning environment for AI and machine learning enthusiasts. It offers practical examples and tutorials on using LangGraph, LangChain, and related tools to create efficient and reusable workflows involving language models.\n",
      "   - **Source**: [LangGraph-Learn GitHub Repository](https://github.com/LangGraph-GUI/LangGraph-learn/)\n",
      "\n",
      "### Summary\n",
      "LangGraph is a powerful extension of the LangChain library, aimed at creating stateful applications with multiple actors using LLMs. The learning resources available, including official tutorials and a GitHub repository, provide a solid foundation for getting started with LangGraph.\n"
     ]
    }
   ],
   "source": [
    "# `None` will append nothing new to the current state, letting it resume as if it had never been interrupted\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e78a97-474f-4709-b51d-9d5e8323e14c",
   "metadata": {},
   "source": [
    "Review this call's [LangSmith trace](https://smith.langchain.com/public/6a9012c0-bfa2-4fba-8dce-961d233f9512/r) to see the exact work that was done in the above call. Notice that the state is loaded in the first step so that your chatbot can continue where it left off.\n",
    "\n",
    "**Congrats!** You've used an `interrupt` to add human-in-the-loop execution to your chatbot, allowing for human oversight and intervention when needed. This opens up the potential UIs you can create with your AI systems. Since we have already added a **checkpointer**, the graph can be paused **indefinitely** and resumed at any time as if nothing had happened.\n",
    "\n",
    "Next, we'll explore how to further customize the bot's behavior using custom state updates.\n",
    "\n",
    "Below is a copy of the code you used in this section. The only difference between this and the previous parts is the addition of the `interrupt_before` argument.\n",
    "\n",
    "<details>\n",
    "<summary>Full Code</summary>\n",
    "    <pre>\n",
    "\n",
    "```python\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # This is new!\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # Note: can also interrupt __after__ actions, if desired.\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")\n",
    "```\n",
    "</pre>\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
