{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3931b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langsmith langchain-openai tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0828830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc6d3dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c52923c-5665-4f8c-a1ba-9799e369c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88d4c9e-65c8-4093-a6c2-c261475f7c07",
   "metadata": {},
   "source": [
    "## Customizing State\n",
    "\n",
    "So far, we've relied on a simple state (it's just a list of messages!). You can go far with this simple state, but if you want to define complex behavior without relying on the message list, you can add additional fields to the state. In this section, we will extend our chat bot with a new node to illustrate this.\n",
    "\n",
    "In the examples above, we involved a human deterministically: the graph __always__ interrupted whenever an tool was invoked. Suppose we wanted our chat bot to have the choice of relying on a human.\n",
    "\n",
    "One way to do this is to create a passthrough \"human\" node, before which the graph will always stop. We will only execute this node if the LLM invokes a \"human\" tool. For our convenience, we will include an \"ask_human\" flag in our graph state that we will flip if the LLM calls this tool.\n",
    "\n",
    "Below, define this new graph, with an updated `State`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cf7e042-1718-4625-ae30-a9917f595449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # This flag is new\n",
    "    ask_human: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87f2cb8-c066-4b54-acc4-e8c7399c5f3d",
   "metadata": {},
   "source": [
    "Next, define a schema to show the model to let it decide to request assistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5192e54-6a28-42fe-a8a7-62d45d61f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"Escalate the conversation to an expert. Use this if you are unable to assist directly or if the user requires support beyond your permissions.\n",
    "\n",
    "    To use this function, relay the user's 'request' so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19c61b-2087-463b-adf8-96dbc193f41c",
   "metadata": {},
   "source": [
    "Next, define the chatbot node. The primary modification here is flip the `ask_human` flag if we see that the chat bot has invoked the `RequestAssistance` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa59b266-14e5-4c75-8b3d-54fac28e8290",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "# We can bind the llm to a tool definition, a pydantic model, or a json schema\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    ask_human = False\n",
    "    if (\n",
    "        response.tool_calls\n",
    "        and response.tool_calls[0][\"name\"] == RequestAssistance.__name__\n",
    "    ):\n",
    "        ask_human = True\n",
    "    return {\"messages\": [response], \"ask_human\": ask_human}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca0f57-2519-49c2-9499-888b5a884897",
   "metadata": {},
   "source": [
    "Next, create the graph builder and add the chatbot and tools nodes to the graph, same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f4464d2-288b-4689-aaf0-329a55dcb85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=[tool]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a0ff3-b671-45c8-8157-ce5db411d370",
   "metadata": {},
   "source": [
    "Next, create the \"human\" `node`. This `node` function is mostly a placeholder in our graph that will trigger an interrupt. If the human does __not__ manually update the state during the `interrupt`, it inserts a tool message so the LLM knows the user was requested but didn't respond. This node also unsets the `ask_human` flag so the graph knows not to revisit the node unless further requests are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d70b5a4-ce50-47dc-aa43-ffb5c48c46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "\n",
    "def create_response(response: str, ai_message: AIMessage):\n",
    "    return ToolMessage(\n",
    "        content=response,\n",
    "        tool_call_id=ai_message.tool_calls[0][\"id\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def human_node(state: State):\n",
    "    new_messages = []\n",
    "    if not isinstance(state[\"messages\"][-1], ToolMessage):\n",
    "        # Typically, the user will have updated the state during the interrupt.\n",
    "        # If they choose not to, we will include a placeholder ToolMessage to\n",
    "        # let the LLM continue.\n",
    "        new_messages.append(\n",
    "            create_response(\"No response from human.\", state[\"messages\"][-1])\n",
    "        )\n",
    "    return {\n",
    "        # Append the new messages\n",
    "        \"messages\": new_messages,\n",
    "        # Unset the flag\n",
    "        \"ask_human\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"human\", human_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e5c65-f7b7-48bd-b0b5-fc8e590eca7d",
   "metadata": {},
   "source": [
    "Next, define the conditional logic. The `select_next_node` will route to the `human` node if the flag is set. Otherwise, it lets the prebuilt `tools_condition` function choose the next node.\n",
    "\n",
    "Recall that the `tools_condition` function simply checks to see if the `chatbot` has responded with any `tool_calls` in its response message. If so, it routes to the `action` node. Otherwise, it ends the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "586a0d07-8303-47f4-b3cf-3bdd043e762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_node(state: State):\n",
    "    if state[\"ask_human\"]:\n",
    "        return \"human\"\n",
    "    # Otherwise, we can route as before\n",
    "    return tools_condition(state)\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    select_next_node,\n",
    "    {\"human\": \"human\", \"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd0bb1-b13e-477e-a08a-a7e657e2c19e",
   "metadata": {},
   "source": [
    "Finally, add the simple directed edges and compile the graph. These edges instruct the graph to **always** flow from node `a`->`b` whenever `a` finishes executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84101737-0048-4635-9f68-45b0c508b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest is the same\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(\"human\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # We interrupt before 'human' here instead.\n",
    "    interrupt_before=[\"human\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f855593-8690-4a18-9ef8-7f3ccdc335bf",
   "metadata": {},
   "source": [
    "If you have the visualization dependencies installed, you can see the graph structure below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3220ae2-cba0-4447-96d1-eb0be4684e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b73851-810e-4466-89d8-37fba87e8494",
   "metadata": {},
   "source": [
    "The chat bot can either request help from a human (chatbot->select->human), invoke the search engine tool (chatbot->select->action), or directly respond (chatbot->select->__end__). Once an action or request has been made, the graph will transition back to the `chatbot` node to continue operations.\n",
    "\n",
    "Let's see this graph in action. We will request for expert assistance to illustrate our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1955d79-a1e4-47d0-ba79-b45bd5752a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I need some expert guidance for building this AI agent. Could you request assistance for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  RequestAssistance (call_Y5pUQgwjsoQO8AaYNXm9zP76)\n",
      " Call ID: call_Y5pUQgwjsoQO8AaYNXm9zP76\n",
      "  Args:\n",
      "    request: I need expert guidance for building an AI agent.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I need some expert guidance for building this AI agent. Could you request assistance for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3945ea4-8dbd-4e14-ae2a-34da7f05a0c1",
   "metadata": {},
   "source": [
    "**Notice:** the LLM has invoked the \"`RequestAssistance`\" tool we provided it, and the interrupt has been set. Let's inspect the graph state to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5320ba05-5696-4194-8278-5385c571264d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human',)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2dd02e-f0a6-4f63-a7d6-e49ecf40db21",
   "metadata": {},
   "source": [
    "The graph state is indeed **interrupted** before the `'human'` node. We can act as the \"expert\" in this scenario and manually update the state by adding a new ToolMessage with our input.\n",
    "\n",
    "Next, respond to the chatbot's request by:\n",
    "1. Creating a `ToolMessage` with our response. This will be passed back to the `chatbot`.\n",
    "2. Calling `update_state` to manually update the graph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cbac924-61ce-4282-9b1c-77f9090ea1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'thread_ts': '1ef35586-6bf3-6328-8002-e6e095c5b799'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message = snapshot.values[\"messages\"][-1]\n",
    "human_response = (\n",
    "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
    "    \" It's much more reliable and extensible than simple autonomous agents.\"\n",
    ")\n",
    "tool_message = create_response(human_response, ai_message)\n",
    "graph.update_state(config, {\"messages\": [tool_message]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79492363-7fc6-4ec7-977d-9030648029bc",
   "metadata": {},
   "source": [
    "You can inspect the state to confirm our response was added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b986c66-1c65-4da8-a404-db7e28f8364e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='I need some expert guidance for building this AI agent. Could you request assistance for me?', id='83324c97-4ff7-4862-9438-17e4f9841b39'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Y5pUQgwjsoQO8AaYNXm9zP76', 'function': {'arguments': '{\"request\":\"I need expert guidance for building an AI agent.\"}', 'name': 'RequestAssistance'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 160, 'total_tokens': 184}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_ce0793330f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-471890f7-cab7-422e-9495-64f252336202-0', tool_calls=[{'name': 'RequestAssistance', 'args': {'request': 'I need expert guidance for building an AI agent.'}, 'id': 'call_Y5pUQgwjsoQO8AaYNXm9zP76'}], usage_metadata={'input_tokens': 160, 'output_tokens': 24, 'total_tokens': 184}),\n",
       " ToolMessage(content=\"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\", id='ceff742f-c7b2-4522-abe6-bb733791e102', tool_call_id='call_Y5pUQgwjsoQO8AaYNXm9zP76')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b8616-de10-44d6-a8f0-3ac73c3c3680",
   "metadata": {},
   "source": [
    "Next, **resume** the graph by invoking it with `None` as the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b32914d-4d60-491f-8e11-1e6867e38ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've relayed your request to an expert. They've recommended checking out LangGraph for building your AI agent, as it's more reliable and extensible than simple autonomous agents. If you have any specific questions or need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0559b-d653-4dab-8928-b001004d14cb",
   "metadata": {},
   "source": [
    "**Notice** that the chat bot has incorporated the updated state in its final response. Since **everything** was checkpointed, the \"expert\" human in the loop could perform the update at any time without impacting the graph's execution.\n",
    "\n",
    "**Congratulations!** you've now added an additional node to your assistant graph to let the chat bot decide for itself whether or not it needs to interrupt execution. You did so by updating the graph `State` with a new `ask_human` field and modifying the interruption logic when compiling the graph. This lets you dynamically include a human in the loop while maintaining full **memory** every time you execute the graph.\n",
    "\n",
    "We're almost done with the tutorial, but there is one more concept we'd like to review before finishing that connects `checkpointing` and `state updates`. \n",
    "\n",
    "This section's code is reproduced below for your reference.\n",
    "\n",
    "<details>\n",
    "<summary>Full Code</summary>\n",
    "    <pre>\n",
    "\n",
    "```python\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # This flag is new\n",
    "    ask_human: bool\n",
    "\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"Escalate the conversation to an expert. Use this if you are unable to assist directly or if the user requires support beyond your permissions.\n",
    "\n",
    "    To use this function, relay the user's 'request' so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "# We can bind the llm to a tool definition, a pydantic model, or a json schema\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    ask_human = False\n",
    "    if (\n",
    "        response.tool_calls\n",
    "        and response.tool_calls[0][\"name\"] == RequestAssistance.__name__\n",
    "    ):\n",
    "        ask_human = True\n",
    "    return {\"messages\": [response], \"ask_human\": ask_human}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=[tool]))\n",
    "\n",
    "\n",
    "def create_response(response: str, ai_message: AIMessage):\n",
    "    return ToolMessage(\n",
    "        content=response,\n",
    "        tool_call_id=ai_message.tool_calls[0][\"id\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def human_node(state: State):\n",
    "    new_messages = []\n",
    "    if not isinstance(state[\"messages\"][-1], ToolMessage):\n",
    "        # Typically, the user will have updated the state during the interrupt.\n",
    "        # If they choose not to, we will include a placeholder ToolMessage to\n",
    "        # let the LLM continue.\n",
    "        new_messages.append(\n",
    "            create_response(\"No response from human.\", state[\"messages\"][-1])\n",
    "        )\n",
    "    return {\n",
    "        # Append the new messages\n",
    "        \"messages\": new_messages,\n",
    "        # Unset the flag\n",
    "        \"ask_human\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"human\", human_node)\n",
    "\n",
    "\n",
    "def select_next_node(state: State):\n",
    "    if state[\"ask_human\"]:\n",
    "        return \"human\"\n",
    "    # Otherwise, we can route as before\n",
    "    return tools_condition(state)\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    select_next_node,\n",
    "    {\"human\": \"human\", \"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(\"human\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[\"human\"],\n",
    ")\n",
    "```\n",
    "</pre>\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
