{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI API Examples Notebook\n",
    "# \n",
    "# This notebook demonstrates key features of the OpenAI API for developers.\n",
    "# It provides practical examples of the most important capabilities with executable code.\n",
    "\n",
    "# First, let's set up our environment by installing the OpenAI Python library\n",
    "%pip install openai numpy matplotlib pydantic --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the OpenAI library\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client\n",
    "# Note: In a real application, you would use an environment variable or secure method\n",
    "# to store your API key. This is just for demonstration.\n",
    "client = OpenAI(\n",
    "    # Replace with your actual API key or use: api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"YOUR_API_KEY_HERE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Write a one-sentence bedtime story about a unicorn.\n",
      "Response: Under a silvery moon, a gentle unicorn named Luna danced through a field of enchanted flowers, spreading dreams of magic to all the sleeping children nearby.\n",
      "\n",
      "With controlled parameters:\n",
      "Response (controlled): Under a blanket of twinkling stars, a gentle unicorn named Luna danced through a moonlit meadow, leaving trails of shimmering dreams for children to find as they drifted off to sleep.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a one-sentence bedtime story about a unicorn.\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Response: {response.output_text}\")\n",
    "\n",
    "# Show how to control generation with parameters\n",
    "print(\"\\nWith controlled parameters:\")\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt,\n",
    "    temperature=0.7,  # Lower for more deterministic outputs\n",
    "    top_p=0.9         # Nucleus sampling\n",
    ")\n",
    "\n",
    "print(f\"Response (controlled): {response.output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "   model=MODEL,\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a UI generator AI. Convert the user input into a UI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Make a User Profile Form\"}\n",
    "    ],\n",
    "    text={\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"ui\",\n",
    "            \"description\": \"Dynamically generated UI\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"type\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The type of the UI component\",\n",
    "                        \"enum\": [\"div\", \"button\", \"header\", \"section\", \"field\", \"form\"]\n",
    "                    },\n",
    "                    \"label\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The label of the UI component, used for buttons or form fields\"\n",
    "                    },\n",
    "                    \"children\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"description\": \"Nested UI components\",\n",
    "                        \"items\": {\"$ref\": \"#\"}\n",
    "                    },\n",
    "                    \"attributes\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"description\": \"Arbitrary attributes for the UI component, suitable for any element\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                              \"name\": {\n",
    "                                  \"type\": \"string\",\n",
    "                                  \"description\": \"The name of the attribute, for example onClick or className\"\n",
    "                              },\n",
    "                              \"value\": {\n",
    "                                  \"type\": \"string\",\n",
    "                                  \"description\": \"The value of the attribute\"\n",
    "                              }\n",
    "                          },\n",
    "                          \"required\": [\"name\", \"value\"],\n",
    "                          \"additionalProperties\": False\n",
    "                      }\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"type\", \"label\", \"children\", \"attributes\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "ui = json.loads(response.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.1 Structured Outputs with Pydantic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps=[Step(explanation='Start by subtracting 7 from both sides to isolate the term with x.', output='8x + 7 - 7 = -23 - 7'), Step(explanation='Simplify both sides; 7 - 7 is 0, and -23 - 7 is -30.', output='8x = -30'), Step(explanation='Divide both sides by 8 to solve for x.', output='8x / 8 = -30 / 8'), Step(explanation='Simplify -30 divided by 8 to get x alone. You can reduce this fraction by dividing numerator and denominator by 2.', output='x = -15/4')] final_answer='x = -15/4'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class MathReasoning(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: str\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\"},\n",
    "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"}\n",
    "    ],\n",
    "    response_format=MathReasoning,\n",
    ")\n",
    "\n",
    "math_reasoning = completion.choices[0].message\n",
    "\n",
    "# If the model refuses to respond, you will get a refusal message\n",
    "if (math_reasoning.refusal):\n",
    "    print(math_reasoning.refusal)\n",
    "else:\n",
    "    print(math_reasoning.parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Multimodal Capabilities - Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image shows a smooth gradient of colors blending into each other. The colors include shades of red, pink, orange, yellow, green, blue, and purple, creating a soft and visually pleasing transition across the image. There are no distinct shapes or objects visible; it is purely an abstract color gradient.\n"
     ]
    }
   ],
   "source": [
    "# For notebook demonstration, we'll use a placeholder URL\n",
    "image_url = \"https://images.unsplash.com/photo-1579546929518-9e396f3cc809?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxleHBsb3JlLWZlZWR8MXx8fGVufDB8fHx8&w=1000&q=80\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_text\", \"text\": \"what's in this image?\"},\n",
    "            {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": image_url,\n",
    "            },\n",
    "        ],\n",
    "    }],\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Audio Capabilities - Text to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_file_path = \"speech.mp3\"\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"coral\",\n",
    "    input=\"Today is a wonderful day to build something people love!\",\n",
    "    instructions=\"Speak in a cheerful and positive tone.\",\n",
    ") as response:\n",
    "    response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.1 Audio Capabilities - Speech to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is a wonderful day to build something people love.\n"
     ]
    }
   ],
   "source": [
    "audio_file= open(\"speech.mp3\", \"rb\")\n",
    "\n",
    "transcription = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\", \n",
    "    file=audio_file\n",
    ")\n",
    "\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']\n",
    "\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"latitude\": {\"type\": \"number\"},\n",
    "            \"longitude\": {\"type\": \"number\"}\n",
    "        },\n",
    "        \"required\": [\"latitude\", \"longitude\"],\n",
    "        \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "}]\n",
    "\n",
    "input_messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Paris today?\"}]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tool call and arguments\n",
    "tool_call = response.output[0]\n",
    "args = json.loads(tool_call.arguments)\n",
    "# Call the function\n",
    "result = get_weather(args[\"latitude\"], args[\"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current temperature in Paris today is approximately 13.8°C. If you need more details like conditions (sunny, rainy, etc.), feel free to specify!\n"
     ]
    }
   ],
   "source": [
    "# Append the tool call and result to the input messages\n",
    "input_messages.append(tool_call) # append model's function call message\n",
    "input_messages.append({ # append result message\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": tool_call.call_id,\n",
    "    \"output\": str(result)\n",
    "})\n",
    "\n",
    "response_2 = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")\n",
    "print(response_2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Reasoning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "o3-mini Response:\n",
      "Here’s a step-by‑step recipe for implementing a basic hash table with separate chaining (i.e. each slot holds a linked list of key‑value pairs). You can adapt this to your favorite language.\n",
      "\n",
      "1. Choose your core parameters  \n",
      "   • Table size N (preferably a prime or power of two)  \n",
      "   • A hash function h(key) that maps keys to integers in [0..N–1]  \n",
      "\n",
      "2. Define your data structures  \n",
      "   • Entry { key, value, next }   // for a singly linked list node  \n",
      "   • HashTable { buckets: array of Entry pointers of length N, count }  \n",
      "\n",
      "3. Initialize  \n",
      "   • Allocate the buckets array of size N, initialize each bucket to null  \n",
      "   • Set count = 0  \n",
      "\n",
      "4. Hash function  \n",
      "   • If keys are integers: h(k) = (a·k + b) mod N  \n",
      "   • If strings: e.g. compute a rolling polynomial hash over characters, then mod N  \n",
      "   • Always reduce the result to [0..N–1]  \n",
      "\n",
      "5. Insert(key, value)  \n",
      "   idx = h(key)  \n",
      "   node = buckets[idx]  \n",
      "   while node ≠ null:  \n",
      "     if node.key == key:  \n",
      "       node.value = value    // update existing  \n",
      "       return  \n",
      "     node = node.next  \n",
      "   // not found, prepend new entry  \n",
      "   newNode = new Entry(key, value, buckets[idx])  \n",
      "   buckets[idx] = newNode  \n",
      "   count += 1  \n",
      "\n",
      "   Optional: if load factor count/N exceeds a threshold (e.g. 0.75), resize.\n",
      "\n",
      "6. Lookup(key) → value or null  \n",
      "   idx = h(key)  \n",
      "   node = buckets[idx]  \n",
      "   while node ≠ null:  \n",
      "     if node.key == key: return node.value  \n",
      "     node = node.next  \n",
      "   return null  // not found  \n",
      "\n",
      "7. Delete(key)  \n",
      "   idx = h(key)  \n",
      "   prev = null; node = buckets[idx]  \n",
      "   while node ≠ null:  \n",
      "     if node.key == key:  \n",
      "       if prev == null: buckets[idx] = node.next  \n",
      "       else prev.next = node.next  \n",
      "       free(node)  \n",
      "       count -= 1  \n",
      "       return true  \n",
      "     prev = node; node = node.next  \n",
      "   return false  // not found  \n",
      "\n",
      "8. Resizing (to keep operations O(1) on average)  \n",
      "   function resize(newN):  \n",
      "     oldBuckets = buckets; oldN = N  \n",
      "     allocate buckets[newN], set each to null; N = newN; count = 0  \n",
      "     for each bucket in oldBuckets:  \n",
      "       node = bucket  \n",
      "       while node ≠ null:  \n",
      "         Insert(node.key, node.value)  // rehashes into new table  \n",
      "         node = node.next  \n",
      "     free oldBuckets  \n",
      "\n",
      "9. Complexity  \n",
      "   • Insert/Search/Delete: O(1 + α) average, where α = load factor = count/N  \n",
      "   • Resizing is O(N) but happens infrequently  \n",
      "\n",
      "10. Variations & notes  \n",
      "   • Open addressing (linear probing, quadratic, double hashing) avoids pointers but requires “tombstones” for delete.  \n",
      "   • Choose N and hash function to minimize collisions.  \n",
      "   • For high‑performance, use power‑of‑two N plus bit‑masking and well‑distributed hash.  \n",
      "   • In languages with generics, parameterize by Key and Value types.  \n",
      "\n",
      "That’s the core of a hash‑table implementation. You just need to pick your language’s memory primitives and translate the above pseudocode into classes/structs and methods.\n"
     ]
    }
   ],
   "source": [
    "# response_o1 = client.responses.create(\n",
    "#     model=\"o1\",\n",
    "#     input=\"Design an algorithm to find the shortest path in a graph.\"\n",
    "# )\n",
    "\n",
    "# print(\"o1 Response:\")\n",
    "# print(response_o1.output_text)\n",
    "\n",
    "# Using o4-mini for faster reasoning\n",
    "response_o4 = client.responses.create(\n",
    "    model=\"o4-mini\",\n",
    "    input=\"Explain how to implement a hash table.\"\n",
    ")\n",
    "\n",
    "print(\"\\no3-mini Response:\")\n",
    "print(response_o4.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the reasoning configuration for o3-mini: Reasoning(effort='medium', generate_summary=None, summary=None)\n"
     ]
    }
   ],
   "source": [
    "## With reasoning models, you can view the reasoning process and the steps taken to arrive at the answer.\n",
    "print(\"This is the reasoning configuration for o4-mini:\", response_o4.reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 3072\n",
      "Number of embeddings: 10\n",
      "\n",
      "Similarity Matrix (Dot Products):\n",
      "          king     queen    man      woman    apple    banana   orange   pear     castle   throne  \n",
      "king       1.0000   0.5552   0.4183   0.2938   0.3243   0.3305   0.2879   0.2802   0.3615   0.4027  \n",
      "queen      0.5552   1.0000   0.3072   0.4132   0.3145   0.3191   0.2983   0.2996   0.2969   0.3354  \n",
      "man        0.4183   0.3072   1.0000   0.5713   0.3098   0.3495   0.2972   0.2695   0.2998   0.2650  \n",
      "woman      0.2938   0.4132   0.5713   1.0000   0.3199   0.2937   0.2784   0.2533   0.2449   0.2491  \n",
      "apple      0.3243   0.3145   0.3098   0.3199   1.0000   0.4619   0.4588   0.4391   0.3002   0.2340  \n",
      "banana     0.3305   0.3191   0.3495   0.2937   0.4619   1.0000   0.4579   0.3636   0.2777   0.2075  \n",
      "orange     0.2879   0.2983   0.2972   0.2784   0.4588   0.4579   1.0000   0.3822   0.2848   0.2174  \n",
      "pear       0.2802   0.2996   0.2695   0.2533   0.4391   0.3636   0.3822   1.0000   0.2788   0.1929  \n",
      "castle     0.3615   0.2969   0.2998   0.2449   0.3002   0.2777   0.2848   0.2788   1.0000   0.3888  \n",
      "throne     0.4027   0.3354   0.2650   0.2491   0.2340   0.2075   0.2174   0.1929   0.3888   1.0000  \n",
      "\n",
      "Specific relationships:\n",
      "Similarity between 'king' and 'queen': 0.5552\n",
      "Similarity between 'apple' and 'banana': 0.4619\n",
      "Similarity between 'king' and 'apple': 0.3243\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# First, let's create embeddings for a set of words\n",
    "words = [\n",
    "    \"king\", \"queen\", \"man\", \"woman\", \n",
    "    \"apple\", \"banana\", \"orange\", \"pear\",\n",
    "    \"castle\", \"throne\"\n",
    "]\n",
    "\n",
    "# Get embeddings for all words\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    input=words,\n",
    "    encoding_format=\"float\"\n",
    ")\n",
    "\n",
    "# Extract the embeddings\n",
    "embeddings = [data.embedding for data in response.data]\n",
    "\n",
    "print(f\"Embedding dimension: {len(embeddings[0])}\")\n",
    "print(f\"Number of embeddings: {len(embeddings)}\")\n",
    "\n",
    "# Function to compute dot product between two vectors\n",
    "import numpy as np\n",
    "\n",
    "def dot_product(vec1, vec2):\n",
    "    return np.dot(vec1, vec2)\n",
    "\n",
    "# Compute similarity matrix (dot products between all pairs)\n",
    "similarity_matrix = np.zeros((len(words), len(words)))\n",
    "for i in range(len(words)):\n",
    "    for j in range(len(words)):\n",
    "        similarity_matrix[i][j] = dot_product(embeddings[i], embeddings[j])\n",
    "\n",
    "# Print similarity matrix with labels\n",
    "print(\"\\nSimilarity Matrix (Dot Products):\")\n",
    "print(\"          \" + \" \".join(f\"{word:<8}\" for word in words))\n",
    "for i, word in enumerate(words):\n",
    "    row_values = \" \".join(f\"{similarity_matrix[i][j]:.4f}  \" for j in range(len(words)))\n",
    "    print(f\"{word:<10} {row_values}\")\n",
    "\n",
    "# Check specific relationships\n",
    "king_queen_similarity = dot_product(embeddings[0], embeddings[1])\n",
    "apple_banana_similarity = dot_product(embeddings[4], embeddings[5])\n",
    "\n",
    "print(\"\\nSpecific relationships:\")\n",
    "print(f\"Similarity between 'king' and 'queen': {king_queen_similarity:.4f}\")\n",
    "print(f\"Similarity between 'apple' and 'banana': {apple_banana_similarity:.4f}\")\n",
    "print(f\"Similarity between 'king' and 'apple': {dot_product(embeddings[0], embeddings[4]):.4f}\")\n",
    "\n",
    "# We expect king/queen to be closer to each other than king/apple\n",
    "# And apple/banana to be closer to each other than queen/banana\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
