{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI API Examples Notebook\n",
    "# \n",
    "# This notebook demonstrates key features of the OpenAI API for developers.\n",
    "# It provides practical examples of the most important capabilities with executable code.\n",
    "\n",
    "# First, let's set up our environment by installing the OpenAI Python library\n",
    "%pip install openai numpy matplotlib pydantic --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the OpenAI library\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client\n",
    "# Note: In a real application, you would use an environment variable or secure method\n",
    "# to store your API key. This is just for demonstration.\n",
    "client = OpenAI(\n",
    "    # Replace with your actual API key or use: api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"YOUR_API_KEY_HERE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Write a one-sentence bedtime story about a unicorn.\n",
      "Response: Under a sky sprinkled with twinkling stars, a gentle unicorn with a shimmering silver mane whispered magical dreams to the sleeping forest.\n",
      "\n",
      "With controlled parameters:\n",
      "Response (controlled): Under a sky sprinkled with twinkling stars, a gentle unicorn with a shimmering silver horn whispered magical dreams to every child as they drifted peacefully to sleep.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a one-sentence bedtime story about a unicorn.\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Response: {response.output_text}\")\n",
    "\n",
    "# Show how to control generation with parameters\n",
    "print(\"\\nWith controlled parameters:\")\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt,\n",
    "    temperature=0.7,  # Lower for more deterministic outputs\n",
    "    top_p=0.9         # Nucleus sampling\n",
    ")\n",
    "\n",
    "print(f\"Response (controlled): {response.output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "response = client.responses.create(\n",
    "   model=MODEL,\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a UI generator AI. Convert the user input into a UI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Make a User Profile Form\"}\n",
    "    ],\n",
    "    text={\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"ui\",\n",
    "            \"description\": \"Dynamically generated UI\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"type\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The type of the UI component\",\n",
    "                        \"enum\": [\"div\", \"button\", \"header\", \"section\", \"field\", \"form\"]\n",
    "                    },\n",
    "                    \"label\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The label of the UI component, used for buttons or form fields\"\n",
    "                    },\n",
    "                    \"children\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"description\": \"Nested UI components\",\n",
    "                        \"items\": {\"$ref\": \"#\"}\n",
    "                    },\n",
    "                    \"attributes\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"description\": \"Arbitrary attributes for the UI component, suitable for any element\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                              \"name\": {\n",
    "                                  \"type\": \"string\",\n",
    "                                  \"description\": \"The name of the attribute, for example onClick or className\"\n",
    "                              },\n",
    "                              \"value\": {\n",
    "                                  \"type\": \"string\",\n",
    "                                  \"description\": \"The value of the attribute\"\n",
    "                              }\n",
    "                          },\n",
    "                          \"required\": [\"name\", \"value\"],\n",
    "                          \"additionalProperties\": False\n",
    "                      }\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"type\", \"label\", \"children\", \"attributes\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "ui = json.loads(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'form',\n",
       " 'label': 'User Profile Form',\n",
       " 'children': [{'type': 'field',\n",
       "   'label': 'First Name',\n",
       "   'children': [],\n",
       "   'attributes': [{'name': 'type', 'value': 'text'},\n",
       "    {'name': 'name', 'value': 'firstName'}]},\n",
       "  {'type': 'field',\n",
       "   'label': 'Last Name',\n",
       "   'children': [],\n",
       "   'attributes': [{'name': 'type', 'value': 'text'},\n",
       "    {'name': 'name', 'value': 'lastName'}]},\n",
       "  {'type': 'field',\n",
       "   'label': 'Email',\n",
       "   'children': [],\n",
       "   'attributes': [{'name': 'type', 'value': 'email'},\n",
       "    {'name': 'name', 'value': 'email'}]},\n",
       "  {'type': 'field',\n",
       "   'label': 'Password',\n",
       "   'children': [],\n",
       "   'attributes': [{'name': 'type', 'value': 'password'},\n",
       "    {'name': 'name', 'value': 'password'}]},\n",
       "  {'type': 'field',\n",
       "   'label': 'Date of Birth',\n",
       "   'children': [],\n",
       "   'attributes': [{'name': 'type', 'value': 'date'},\n",
       "    {'name': 'name', 'value': 'dob'}]},\n",
       "  {'type': 'field',\n",
       "   'label': 'Bio',\n",
       "   'children': [],\n",
       "   'attributes': [{'name': 'type', 'value': 'textarea'},\n",
       "    {'name': 'name', 'value': 'bio'}]},\n",
       "  {'type': 'button',\n",
       "   'label': 'Submit',\n",
       "   'children': [],\n",
       "   'attributes': [{'name': 'type', 'value': 'submit'}]}],\n",
       " 'attributes': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.1 Structured Outputs with Pydantic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps=[Step(explanation='Start with the equation 8x + 7 = -23. First, isolate the term with x by subtracting 7 from both sides of the equation.', output='8x + 7 - 7 = -23 - 7; simplifying gives 8x = -30.'), Step(explanation='Now, solve for x by dividing both sides of the equation by 8.', output='(8x)/8 = (-30)/8; simplifying gives x = -30/8.'), Step(explanation='Simplify the fraction -30/8 by dividing numerator and denominator by their greatest common divisor, which is 2.', output='x = (-30 ÷ 2)/(8 ÷ 2) = -15/4.')] final_answer='x = -15/4'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class MathReasoning(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: str\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\"},\n",
    "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"}\n",
    "    ],\n",
    "    response_format=MathReasoning,\n",
    ")\n",
    "\n",
    "math_reasoning = completion.choices[0].message\n",
    "\n",
    "# If the model refuses to respond, you will get a refusal message\n",
    "if (math_reasoning.refusal):\n",
    "    print(math_reasoning.refusal)\n",
    "else:\n",
    "    print(math_reasoning.parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Step(explanation='Start with the equation 8x + 7 = -23. First, isolate the term with x by subtracting 7 from both sides of the equation.', output='8x + 7 - 7 = -23 - 7; simplifying gives 8x = -30.')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_reasoning.parsed.steps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Multimodal Capabilities - Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image contains a smooth gradient with a blend of various colors. On the left side, there are shades of pink and red, transitioning through orange and yellow near the center, then shifting to light green, cyan, and finally blue and purple on the bottom right. The colors blend softly into each other, creating a visually appealing gradient effect. There are no distinct objects or shapes present in the image.\n"
     ]
    }
   ],
   "source": [
    "# For notebook demonstration, we'll use a placeholder URL\n",
    "image_url = \"https://images.unsplash.com/photo-1579546929518-9e396f3cc809?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxleHBsb3JlLWZlZWR8MXx8fGVufDB8fHx8&w=1000&q=80\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_text\", \"text\": \"what's in this image?\"},\n",
    "            {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": image_url,\n",
    "            },\n",
    "        ],\n",
    "    }],\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Audio Capabilities - Text to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_file_path = \"speech.mp3\"\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"coral\",\n",
    "    input=\"Today is a wonderful day to build something people love!\",\n",
    "    instructions=\"Speak in a cheerful and positive tone.\",\n",
    ") as response:\n",
    "    response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.1 Audio Capabilities - Speech to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's a wonderful day to build something people love!\n"
     ]
    }
   ],
   "source": [
    "audio_file= open(\"speech.mp3\", \"rb\")\n",
    "\n",
    "transcription = client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\", \n",
    "    file=audio_file\n",
    ")\n",
    "\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']\n",
    "\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"latitude\": {\"type\": \"number\"},\n",
    "            \"longitude\": {\"type\": \"number\"}\n",
    "        },\n",
    "        \"required\": [\"latitude\", \"longitude\"],\n",
    "        \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "}]\n",
    "\n",
    "input_messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Paris today?\"}]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tool call and arguments\n",
    "tool_call = response.output[0]\n",
    "args = json.loads(tool_call.arguments)\n",
    "# Call the function\n",
    "result = get_weather(args[\"latitude\"], args[\"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current temperature in Paris is 16 degrees Celsius. If you want more detailed information about the weather, such as conditions (sunny, rainy, etc.), please let me know!\n"
     ]
    }
   ],
   "source": [
    "# Append the tool call and result to the input messages\n",
    "input_messages.append(tool_call) # append model's function call message\n",
    "input_messages.append({ # append result message\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": tool_call.call_id,\n",
    "    \"output\": str(result)\n",
    "})\n",
    "\n",
    "response_2 = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")\n",
    "print(response_2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Reasoning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "o3-mini Response:\n",
      "A hash‑table is essentially an array (“table”) plus a hash function that maps each key to an array index.  Collisions—two keys mapping to the same slot—are handled by a “collision‐resolution” strategy.  Here’s a sketch of how you might build one in pseudocode, first with separate chaining and then with open addressing.\n",
      "\n",
      "1.  Data Structures  \n",
      "   •  Let N be the number of buckets (initial table size).  \n",
      "   •  table[0…N–1]: array of bucket‑heads (for chaining), or array of entries (for open addressing).  \n",
      "   •  Each “entry” stores (key, value), and—if you’re chaining—a pointer to the next entry in that bucket.\n",
      "\n",
      "2.  A Good Hash Function h(key) → [0…N–1]  \n",
      "   •  For integers: h(k) = (a·k + b) mod p mod N, with p prime, a≠0.  \n",
      "   •  For strings: treat as base‑B number, then reduce mod N (or use built‑in string hash).  \n",
      "   •  Aim for uniform spread.\n",
      "\n",
      "3.  Separate Chaining  \n",
      "   – table[i] points to the head of a linked list of all entries whose keys hash to i.  \n",
      "   a) init: for i in 0…N–1: table[i]=null  \n",
      "   b) insert(key,value):  \n",
      "      idx = h(key)  \n",
      "      scan the list at table[idx]:  \n",
      "        if an entry’s key == key, overwrite value and return  \n",
      "      else prepend new Entry(key,value) to table[idx]  \n",
      "   c) search(key):  \n",
      "      idx = h(key)  \n",
      "      walk list at table[idx], return value if found, else “not found.”  \n",
      "   d) delete(key):  \n",
      "      idx = h(key)  \n",
      "      unlink the matching node from the list, free it.  \n",
      "   e) resize: when total_entries / N > load_threshold (e.g. 0.75),  \n",
      "        • allocate new table of size N’≈2N  \n",
      "        • re‑hash every existing (key,value) into new table  \n",
      "        • replace table/N←N’\n",
      "\n",
      "4.  Open Addressing (e.g. Linear Probing)  \n",
      "   – table[i] holds either an entry or is empty or a “tombstone.”  \n",
      "   a) states: EMPTY, OCCUPIED, DELETED  \n",
      "   b) hash1(key) = h(key); probe step = 1 (or another function)  \n",
      "   c) insert(key,value):  \n",
      "      for i from 0 to N–1:  \n",
      "        idx = (hash1(key) + i) mod N  \n",
      "        if table[idx].state is EMPTY or DELETED:  \n",
      "          store (key,value), mark OCCUPIED, return  \n",
      "        if OCCUPIED and table[idx].key == key:  \n",
      "          overwrite value, return  \n",
      "      error: table full  \n",
      "   d) search(key):  \n",
      "      for i from 0 to N–1:  \n",
      "        idx = (hash1(key) + i) mod N  \n",
      "        if table[idx].state is EMPTY: break → not found  \n",
      "        if OCCUPIED and table[idx].key == key: return value  \n",
      "      return not found  \n",
      "   e) delete(key):  \n",
      "      find it by the same probe loop, if found mark table[idx].state = DELETED  \n",
      "   f) resize when load factor gets too high; re‑insert skipping tombstones.\n",
      "\n",
      "5.  Complexity  \n",
      "   • Average case (with good hash & load factor α):  \n",
      "     – chaining: O(1 + α) per op  \n",
      "     – open addressing: O(1/(1–α)) per op  \n",
      "   • Worst case (bad hash or very loaded): O(n)  \n",
      "\n",
      "6.  Tips  \n",
      "   • Pick N a prime (or power‑of‑two with bit‑mask hashing).  \n",
      "   • Keep load factor ≤0.7 before resizing.  \n",
      "   • For open addressing, consider double hashing to reduce clustering:  \n",
      "       idx = (h1(key) + i·h2(key)) mod N  \n",
      "   • In a real implementation you’ll need to handle memory allocation, rehashing efficiently, and choose your key‑equality test carefully.\n",
      "\n",
      "That’s the core: an array, a hash function, collision handling (chaining or probing), and dynamic resizing to keep operations O(1) on average.\n"
     ]
    }
   ],
   "source": [
    "# response_o1 = client.responses.create(\n",
    "#     model=\"o1\",\n",
    "#     input=\"Design an algorithm to find the shortest path in a graph.\"\n",
    "# )\n",
    "\n",
    "# print(\"o1 Response:\")\n",
    "# print(response_o1.output_text)\n",
    "\n",
    "# Using o4-mini for faster reasoning\n",
    "response_o4 = client.responses.create(\n",
    "    model=\"o4-mini\",\n",
    "    input=\"Explain how to implement a hash table.\"\n",
    ")\n",
    "\n",
    "print(\"\\no3-mini Response:\")\n",
    "print(response_o4.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the reasoning configuration for o3-mini: Reasoning(effort='medium', generate_summary=None, summary=None)\n"
     ]
    }
   ],
   "source": [
    "## With reasoning models, you can view the reasoning process and the steps taken to arrive at the answer.\n",
    "print(\"This is the reasoning configuration for o4-mini:\", response_o4.reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 3072\n",
      "Number of embeddings: 10\n",
      "\n",
      "Similarity Matrix (Dot Products):\n",
      "          king     queen    man      woman    apple    banana   orange   pear     castle   throne  \n",
      "king       1.0000   0.5524   0.4120   0.2923   0.3221   0.3272   0.2868   0.2761   0.3563   0.3967  \n",
      "queen      0.5524   1.0000   0.3072   0.4132   0.3145   0.3191   0.2983   0.2996   0.2969   0.3354  \n",
      "man        0.4120   0.3072   1.0000   0.5713   0.3098   0.3495   0.2972   0.2695   0.2998   0.2650  \n",
      "woman      0.2923   0.4132   0.5713   1.0000   0.3199   0.2937   0.2784   0.2533   0.2449   0.2491  \n",
      "apple      0.3221   0.3145   0.3098   0.3199   1.0000   0.4619   0.4588   0.4391   0.3002   0.2340  \n",
      "banana     0.3272   0.3191   0.3495   0.2937   0.4619   1.0000   0.4579   0.3636   0.2777   0.2075  \n",
      "orange     0.2868   0.2983   0.2972   0.2784   0.4588   0.4579   1.0000   0.3822   0.2848   0.2174  \n",
      "pear       0.2761   0.2996   0.2695   0.2533   0.4391   0.3636   0.3822   1.0000   0.2788   0.1929  \n",
      "castle     0.3563   0.2969   0.2998   0.2449   0.3002   0.2777   0.2848   0.2788   1.0000   0.3888  \n",
      "throne     0.3967   0.3354   0.2650   0.2491   0.2340   0.2075   0.2174   0.1929   0.3888   1.0000  \n",
      "\n",
      "Specific relationships:\n",
      "Similarity between 'king' and 'queen': 0.5524\n",
      "Similarity between 'apple' and 'banana': 0.4619\n",
      "Similarity between 'king' and 'apple': 0.3221\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# First, let's create embeddings for a set of words\n",
    "words = [\n",
    "    \"king\", \"queen\", \"man\", \"woman\", \n",
    "    \"apple\", \"banana\", \"orange\", \"pear\",\n",
    "    \"castle\", \"throne\"\n",
    "]\n",
    "\n",
    "# Get embeddings for all words\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    input=words,\n",
    "    encoding_format=\"float\"\n",
    ")\n",
    "\n",
    "# Extract the embeddings\n",
    "embeddings = [data.embedding for data in response.data]\n",
    "\n",
    "print(f\"Embedding dimension: {len(embeddings[0])}\")\n",
    "print(f\"Number of embeddings: {len(embeddings)}\")\n",
    "\n",
    "# Function to compute dot product between two vectors\n",
    "def dot_product(vec1, vec2):\n",
    "    return np.dot(vec1, vec2)\n",
    "\n",
    "# Compute similarity matrix (dot products between all pairs)\n",
    "similarity_matrix = np.zeros((len(words), len(words)))\n",
    "for i in range(len(words)):\n",
    "    for j in range(len(words)):\n",
    "        similarity_matrix[i][j] = dot_product(embeddings[i], embeddings[j])\n",
    "\n",
    "# Print similarity matrix with labels\n",
    "print(\"\\nSimilarity Matrix (Dot Products):\")\n",
    "print(\"          \" + \" \".join(f\"{word:<8}\" for word in words))\n",
    "for i, word in enumerate(words):\n",
    "    row_values = \" \".join(f\"{similarity_matrix[i][j]:.4f}  \" for j in range(len(words)))\n",
    "    print(f\"{word:<10} {row_values}\")\n",
    "\n",
    "# Check specific relationships\n",
    "king_queen_similarity = dot_product(embeddings[0], embeddings[1])\n",
    "apple_banana_similarity = dot_product(embeddings[4], embeddings[5])\n",
    "\n",
    "print(\"\\nSpecific relationships:\")\n",
    "print(f\"Similarity between 'king' and 'queen': {king_queen_similarity:.4f}\")\n",
    "print(f\"Similarity between 'apple' and 'banana': {apple_banana_similarity:.4f}\")\n",
    "print(f\"Similarity between 'king' and 'apple': {dot_product(embeddings[0], embeddings[4]):.4f}\")\n",
    "\n",
    "# We expect king/queen to be closer to each other than king/apple\n",
    "# And apple/banana to be closer to each other than queen/banana"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
