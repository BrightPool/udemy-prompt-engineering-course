{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Optimizing a Prompt for Production:_\n",
    "# Social Media Posts\n",
    "\n",
    "Task: Write a social post given an insight and a social network.\n",
    "\n",
    "`insight, social_network -> social_post`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Naive Prompt\n",
    "Start with simple instructions to establish the baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "- insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "- social_network: Twitter\n",
      "\n",
      "Output:\n",
      "ðŸš€ As AI models get smarter, you'd think prompt engineering would fade away, right? ðŸ¤” Think again! Even the most brilliant minds need guidance from legal, HR, and management to align with business goals. Similarly, even the smartest AI needs well-crafted prompts to deliver precise, valuable insights. Prompt engineering is here to stay, ensuring we harness AI's full potential in harmony with our objectives. ðŸŒŸ #AI #PromptEngineering #FutureTech #BusinessAlignment\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "def get_completion(prompt, context):\n",
    "    client = openai.OpenAI()\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt.format(**context)}\n",
    "        ],\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "naive_prompt = \"Write a social media post about how {insight}, for {social_network}.\"\n",
    "context = {\n",
    "    \"insight\": \"prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\",\n",
    "    \"social_network\": \"Twitter\"\n",
    "}\n",
    "\n",
    "social_post = get_completion(naive_prompt, context)\n",
    "print(\"Input:\")\n",
    "for key, value in context.items():\n",
    "    print(f\"- {key}: {value}\")\n",
    "print(f\"\\nOutput:\\n{social_post}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Applying the 'Five Principles of Prompting' from [Prompt Engineering for Generative AI](https://www.amazon.com/Prompt-Engineering-Generative-AI-Future-Proof/dp/109815343X/):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Give Direction \n",
    "Describe the desired style in detail, or reference a relevant persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "Imagine a world where even the brightest mindsâ€”think Einstein, Maya Angelou, or Sherlock Holmesâ€”needed occasional nudges from legal, HR, or management to sail smoothly in sync with business goals. ðŸ§©\n",
      "\n",
      "This isnâ€™t far-fetched. Just as we prompt our human geniuses to harness their brilliance effectively, the smarter AI models crave our direction too. ðŸŽ¯\n",
      "\n",
      "Welcome to the age of prompt engineering. While AI gets sharper, our knack for nuanced guidance remains crucial. Because letâ€™s face it, even a robot can't read the room like we do. ðŸ’¼ðŸ”\n",
      "\n",
      "#PromptEngineering #AIFuture #InnovationTweet #MalcolmMood\n",
      "\n",
      "And, if Da Vinci sometimes needed a brainstorming buddy, letâ€™s embrace our role in the AI Renaissance. ðŸŒŸðŸ¤–ðŸ–‹\n"
     ]
    }
   ],
   "source": [
    "direction_prompt = \"\"\"\"Write a social media post about how {insight}, for {social_network}, in the style of Malcolm Gladwell.\n",
    "\n",
    "The social post should sound authentically human and colloquial, while being practically useful and brief. Be very creative and make niche references to sound more human. To maximize engagement, the content should be surprising, interesting, or practically useful, or induce high-arousal emotions such as anxiety, anger, awe, or surprise.\"\"\"\n",
    "\n",
    "social_post_a = get_completion(direction_prompt, context)\n",
    "print(f\"\\nOutput:\\n{social_post_a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Specify Format\n",
    "Define what rules to follow, and the required structure of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "```yaml\n",
      "bait: Even the smartest AI models need a little nudge, just like the smartest people do.\n",
      "hook: Think of your company's star performerâ€”they still need direction from legal, HR, and management to stay aligned with business goals.\n",
      "reward: Smart models still require prompt engineering to hit those KPIs. Just like people, models need consistent guidance to be their best.\n",
      "post_content: \"Even the smartest AI models need a little nudge, just like the smartest people do. Think of your company's star performerâ€”they still need direction from legal, HR, and management to stay aligned with business goals. In the same way, smarter AI will still need prompt engineering to truly excel. It's a continuous dialogue that shapes both human and artificial intelligence. Consistent guidance ensures that models, like people, meet and exceed those vital KPIs. Smarter models donâ€™t mean fewer promptsâ€”they mean smarter prompts.\"\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "format_prompt = \"\"\"\"Write a social media post about how {insight}, for {social_network}, in the style of Malcolm Gladwell, using the Bait, Hook, Reward framework.\n",
    "\n",
    "- **bait**: Grab the attention of the person browsing social media. This could be a contrarian statement, appeal to identity, celebrity name, or anything else that stops them scrolling.\n",
    "- **hook**: Keep their attention now you have it. Show this post is relevant to them, by alerting them to an issue, using familiar words, or providing social proof to keep them reading.\n",
    "- **reward**: Compensate them for their attention to elicit reciprocation. Is there any useful information, a surprising statistic, or an interesting anecdote to reveal? Or a threat to make?\n",
    "- **post_content**: The main content of the post, incorporating the bait, hook, and reward in a way that resonates with the reader and engages their attention.\n",
    "\n",
    "First decide on the bait, hook, and reward, before writing the post_content.\n",
    "\n",
    "## Instructions\n",
    "The social post should sound authentically human and colloquial, while being practically useful and brief. Be very creative and make niche references to sound more human. To maximize engagement, the content should be surprising, interesting, or practically useful, or induce high-arousal emotions such as anxiety, anger, awe, or surprise.\n",
    "\n",
    "Follow best practices for posting engaging content on {social_network}, but do not use emoji or hashtags.\n",
    "Provide citations for any statistics included. Do not reference the work of Malcolm Gladwell.\n",
    "Respond in YAML with the following keys:\n",
    "- bait\n",
    "- hook\n",
    "- reward\n",
    "- post_content\"\"\"\n",
    "\n",
    "social_post_b = get_completion(format_prompt, context)\n",
    "print(f\"\\nOutput:\\n{social_post_b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Provide Examples\n",
    "Insert a diverse set of test cases where the task was done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "- insight: overqualified students take service jobs\n",
      "- social_network: Facebook\n",
      "- bait: Use the trope that smart people are so focused they fail to look after themselves.\n",
      "- hook: Particle Physics is a subject that is universally associated with smart people.\n",
      "- reward: Fantasizing about being somewhere remote where you can earn money while focusing on your work.\n",
      "- post_content: Meet Jon. He has been working the night shift at our hotel for over a month already, and he says the best part is the peace and quiet. Particle physics, which is the topic of Jon's Masters Thesis, requires concentration. That's fine by us. So long as our guests can count on Jon, he can count all the particles he wants (or whatever it is that particle physicists do).\n",
      "\n",
      "Example 2:\n",
      "- insight: there's no such thing as a wasted trip\n",
      "- social_network: Instagram\n",
      "- bait: Mentioning a 'wasted trip' will get the attention of people who like to travel, and for whom wasting a trip would be upsetting.\n",
      "- hook: Talk about a rainy day in a hot location like Kauai, which most people would complain about because they're wasting time inside.\n",
      "- reward: An anecdote that reveals that good things can happen when you least expect them.\n",
      "- post_content: There's no such thing as a wasted trip! On this rainy day in Kauai 2 years ago I met my bestie @moniqueontour and we've been on 4 amazing adventures together since.\n",
      "\n",
      "Example 3:\n",
      "- insight: mould your business to your own preferences\n",
      "- social_network: LinkedIn\n",
      "- bait: Most self-help advice focuses on fixing weaknesses, but instead let's focus on how to reframe weaknesses into strengths.\n",
      "- hook: We need to make it clear this post is for business owners, and that you are speaking from experience, establishing connection and credibility.\n",
      "- reward: The fact that 60% of new business came from the blog is a statistic they can take away and use as evidence to support their own strategy, or to share with their wider network.\n",
      "- post_content: Don't try to mold yourself into the person you think your business needs you to be, build your business around who you actually are. When I started my agency business, I hated networking. I'm introverted by nature  so I wrote blog posts instead â€“ eventually 60% of my agency's new business came from our blog.\n",
      "\n",
      "Example 4:\n",
      "- insight: whales are in danger and most people don't know\n",
      "- social_network: Twitter\n",
      "- bait: People who care about whales or animals will pay attention when whales are mentioned.\n",
      "- hook: If we refer to the whales as \"in danger\" people who care will want to know more.\n",
      "- reward: Some species of whales are going extinct, and people would benefit from knowing.\n",
      "- post_content: The whales are in danger of extinction. Many people aren't aware, which is why it's so important to bring awareness to this cause. Together with a few colleagues, we'll be running the London marathon next week in aid of the \"Save the Whales\" foundation, and any support would be appreciated.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples_prompt = \"\"\"\"Write a social media post about how {insight}, for {social_network}, in the style of Malcolm Gladwell, using the Bait, Hook, Reward framework.\n",
    "\n",
    "- **bait**: Grab the attention of the person browsing social media. This could be a contrarian statement, appeal to identity, celebrity name, or anything else that stops them scrolling.\n",
    "- **hook**: Keep their attention now you have it. Show this post is relevant to them, by alerting them to an issue, using familiar words, or providing social proof to keep them reading.\n",
    "- **reward**: Compensate them for their attention to elicit reciprocation. Is there any useful information, a surprising statistic, or an interesting anecdote to reveal? Or a threat to make?\n",
    "- **post_content**: The main content of the post, incorporating the bait, hook, and reward in a way that resonates with the reader and engages their attention.\n",
    "\n",
    "First decide on the bait, hook, and reward, before writing the post_content.\n",
    "\n",
    "## Examples\n",
    "{examples_partial}\n",
    "\n",
    "## Instructions\n",
    "The social post should sound authentically human and colloquial, while being practically useful and brief. Be very creative and make niche references to sound more human. To maximize engagement, the content should be surprising, interesting, or practically useful, or induce high-arousal emotions such as anxiety, anger, awe, or surprise.\n",
    "\n",
    "Follow best practices for posting engaging content on {social_network}, but do not use emoji or hashtags.\n",
    "Provide citations for any statistics included. Do not reference the work of Malcolm Gladwell.\n",
    "Respond in YAML with the following keys:\n",
    "- bait\n",
    "- hook\n",
    "- reward\n",
    "- post_content\"\"\"\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"insight\": \"overqualified students take service jobs\",\n",
    "        \"social_network\": \"Facebook\",\n",
    "        \"bait\": \"Use the trope that smart people are so focused they fail to look after themselves.\",\n",
    "        \"hook\": \"Particle Physics is a subject that is universally associated with smart people.\",\n",
    "        \"reward\": \"Fantasizing about being somewhere remote where you can earn money while focusing on your work.\",\n",
    "        \"post_content\": \"Meet Jon. He has been working the night shift at our hotel for over a month already, and he says the best part is the peace and quiet. Particle physics, which is the topic of Jon's Masters Thesis, requires concentration. That's fine by us. So long as our guests can count on Jon, he can count all the particles he wants (or whatever it is that particle physicists do).\"\n",
    "    },\n",
    "    {\n",
    "        \"insight\": \"there's no such thing as a wasted trip\",\n",
    "        \"social_network\": \"Instagram\",\n",
    "        \"bait\": \"Mentioning a 'wasted trip' will get the attention of people who like to travel, and for whom wasting a trip would be upsetting.\",\n",
    "        \"hook\": \"Talk about a rainy day in a hot location like Kauai, which most people would complain about because they're wasting time inside.\",\n",
    "        \"reward\": \"An anecdote that reveals that good things can happen when you least expect them.\",\n",
    "        \"post_content\": \"There's no such thing as a wasted trip! On this rainy day in Kauai 2 years ago I met my bestie @moniqueontour and we've been on 4 amazing adventures together since.\"\n",
    "    },\n",
    "    {\n",
    "        \"insight\": \"mould your business to your own preferences\",\n",
    "        \"social_network\": \"LinkedIn\",\n",
    "        \"bait\": \"Most self-help advice focuses on fixing weaknesses, but instead let's focus on how to reframe weaknesses into strengths.\",\n",
    "        \"hook\": \"We need to make it clear this post is for business owners, and that you are speaking from experience, establishing connection and credibility.\",\n",
    "        \"reward\": \"The fact that 60% of new business came from the blog is a statistic they can take away and use as evidence to support their own strategy, or to share with their wider network.\",\n",
    "        \"post_content\": \"Don't try to mold yourself into the person you think your business needs you to be, build your business around who you actually are. When I started my agency business, I hated networking. I'm introverted by nature  so I wrote blog posts instead â€“ eventually 60% of my agency's new business came from our blog.\"\n",
    "    },\n",
    "    {\n",
    "        \"insight\": \"whales are in danger and most people don't know\",\n",
    "        \"social_network\": \"Twitter\",\n",
    "        \"bait\": \"People who care about whales or animals will pay attention when whales are mentioned.\",\n",
    "        \"hook\": \"If we refer to the whales as \\\"in danger\\\" people who care will want to know more.\",\n",
    "        \"reward\": \"Some species of whales are going extinct, and people would benefit from knowing.\",\n",
    "        \"post_content\": \"The whales are in danger of extinction. Many people aren't aware, which is why it's so important to bring awareness to this cause. Together with a few colleagues, we'll be running the London marathon next week in aid of the \\\"Save the Whales\\\" foundation, and any support would be appreciated.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert examples to a partial string\n",
    "examples_partial = \"\"\n",
    "for i, example in enumerate(examples, 1):\n",
    "    examples_partial += f\"Example {i}:\\n\"\n",
    "    for key, value in example.items():\n",
    "        examples_partial += f\"- {key}: {value}\\n\"\n",
    "    examples_partial += \"\\n\"\n",
    "\n",
    "print(examples_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "```yaml\n",
      "bait: Even the smartest AI models need a nudge, just like brilliant minds in a boardroom.\n",
      "hook: Think about it: no matter how smart you are, you still need guidance from legal, HR, and management to align with business goals.\n",
      "reward: Here's the kicker: prompt engineering will still be vital because context and alignment are everything.\n",
      "post_content: Ever notice how even the smartest executives need prompting from legal, HR, and management to stay on course? ðŸ§ It's the same for AI. As models get smarter, the need for precise prompt engineering grows. Context and alignment aren't just human necessities; they're universal. Fascinating, isn't it? While the tech evolves, our understanding of its guidance becomes ever more crucial.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Add examples_partial to the context\n",
    "examples_context = {\n",
    "    \"examples_partial\": examples_partial,\n",
    "    \"social_network\": \"Twitter\",\n",
    "    \"insight\": \"prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\"\n",
    "}\n",
    "\n",
    "social_post_c = get_completion(examples_prompt, examples_context)\n",
    "print(f\"\\nOutput:\\n{social_post_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Emoji Evaluation:\n",
      "Has emojis: False\n",
      "Emoji count: 0\n",
      "Emojis found: None\n"
     ]
    }
   ],
   "source": [
    "# Define a function to check for emojis in the post content\n",
    "def check_for_emojis(post_content):\n",
    "    import re\n",
    "    \n",
    "    # Regular expression pattern to match emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001F910-\\U0001F93A\"  # Additional range including ðŸ¤” (U+1F914)\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    # Check if there are any emojis in the post content\n",
    "    emojis_found = emoji_pattern.findall(post_content)\n",
    "    \n",
    "    return {\n",
    "        \"has_emojis\": len(emojis_found) > 0,\n",
    "        \"emoji_count\": len(emojis_found),\n",
    "        \"emojis\": emojis_found\n",
    "    }\n",
    "\n",
    "# Evaluate the presence of emojis in the generated social post\n",
    "emoji_evaluation = check_for_emojis(social_post_c)\n",
    "print(\"\\nEmoji Evaluation:\")\n",
    "print(f\"Has emojis: {emoji_evaluation['has_emojis']}\")\n",
    "print(f\"Emoji count: {emoji_evaluation['emoji_count']}\")\n",
    "print(f\"Emojis found: {', '.join(emoji_evaluation['emojis']) if emoji_evaluation['emojis'] else 'None'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate Quality\n",
    "Identify errors and rate responses, testing what drives performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagement Evaluation:\n",
      "```yaml\n",
      "Analysis: \n",
      "  Insight: The post uses a relevant insight, highlighting that even smarter AI models will require precise prompt engineering, similar to how humans need guidance in a business context. This is a pertinent observation that could resonate with professionals familiar with prompt engineering and AI.\n",
      "  \n",
      "  Bait: The post opens with a relatable and thought-provoking question about human behavior, which can effectively draw in the audience's attention. The use of an emoji also adds a visual element that can capture the eye.\n",
      "  \n",
      "  Hook: The post maintains attention by drawing a parallel between human executives and AI models. This analogy is engaging and likely to keep readers interested in the full message.\n",
      "  \n",
      "  Reward: The reward is moderate; while the post provides an intriguing perspective, it doesn't explicitly offer actionable insights or information. However, it does stimulate thought and discussion about the evolving role of prompt engineering.\n",
      "  \n",
      "  Social Network: The post is well-suited for Twitter, using concise language, a conversational tone, and an emoji which are effective on this platform.\n",
      "  \n",
      "  Hallucination: There are no statistics in the post, thereby avoiding the risk of including inaccurate information.\n",
      "  \n",
      "  Human: The post sounds authentically human, capturing a natural, conversational tone that is likely to appeal to readers.\n",
      "Rating: 4\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Define a function to evaluate the engagement potential of a social media post\n",
    "def evaluate_engagement(post_content, insight, social_network):\n",
    "    evaluation_prompt = f\"\"\"\n",
    "    You are an expert social media analyst. Your task is to evaluate the following social media post and predict its engagement potential. Consider factors such as:\n",
    "    - Insight: Does the post use the relevant insight?\n",
    "    - Bait: Does it grab attention?\n",
    "    - Hook: Does it keep the attention?\n",
    "    - Reward: Does it compensate for the attention?\n",
    "    - Social Network: Does it follow best practices for the social network?\n",
    "    - Hallucination: Are any statistics accurate?\n",
    "    - Human: Is the post authentically human-sounding?\n",
    "\n",
    "    Insight: {insight}\n",
    "    Social Network: {social_network}\n",
    "    Post content:\n",
    "    \"{post_content}\"\n",
    "\n",
    "    Based on these factors, rate the post's engagement potential on a scale of 1-5, where 1 is very low engagement, and 5 is very high engagement. Provide a brief explanation for your rating. Any posts that contain hallucinations or made up statistics should be ranked 0.\n",
    "\n",
    "    Output your response in YAML with the following keys:\n",
    "    - Analysis: [Your analysis]\n",
    "    - Rating: [Your rating]\n",
    "    \"\"\"\n",
    "    evaluation_context = {\n",
    "        \"post_content\": post_content,\n",
    "        \"insight\": insight,\n",
    "        \"social_network\": social_network\n",
    "    }\n",
    "\n",
    "    engagement_evaluation = get_completion(evaluation_prompt, evaluation_context)\n",
    "    return engagement_evaluation\n",
    "\n",
    "# strip out the bait, hook, reward from social_post_c\n",
    "post_content = social_post_c.split(\"post_content:\")[1].strip()\n",
    "\n",
    "# Evaluate the engagement potential of the generated social post\n",
    "engagement_result = evaluate_engagement(post_content, context[\"insight\"], context[\"social_network\"])\n",
    "print(\"Engagement Evaluation:\")\n",
    "print(engagement_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Divide Labor \n",
    "Split tasks into multiple steps, chained together for complex goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 1:\n",
      "Content: Even geniuses need guidance. Think about it: Einstein needed legal advice, Beethoven needed managerial direction. As AI models get smarter, they too will need prompt engineers. Why? Because aligning raw brilliance with business goals is a nuanced art. This insight could be your edge in the evolving tech landscape.\n",
      "```\n",
      "Rating: 5\n",
      "\n",
      "Post 2:\n",
      "Content: Even genius minds need a nudge. Think about how top executives rely on advisors from legal, HR, and management to steer the ship. Smarter AI models are no different. Prompt engineering isn't just a necessity; it's the strategic advantage that aligns AI's brilliance with business goals. Discarding it is like removing the compass from a seasoned navigator. #AI #BusinessStrategy\n",
      "```\n",
      "Rating: 5\n",
      "\n",
      "Post 3:\n",
      "Content: Even geniuses need a nudge now and then. Think about it: no matter how brilliant, our greatest minds still rely on prompts from legal, HR, and management to steer their genius towards business goals. In prompt engineering for AI, we see a parallel. As models get smarter, the need for human-guided alignment won't disappear but evolve - much like guiding a human genius.\n",
      "```\n",
      "Rating: 5\n",
      "\n",
      "Post 4:\n",
      "Content: Even the smartest AI still needs nudges, just like genius humans. Think about it: Einstein, Jobs, and Oprahâ€”brilliant minds who needed direction from legal, HR, and management to align with their goals. The next-gen AI may be smart, but prompt engineering will be the secret sauce to making sure it actually serves your business interests.\n",
      "```\n",
      "Rating: 4\n",
      "\n",
      "Post 5:\n",
      "Content: Even genius humans need prompting sometimes. Think about your last interaction with legal, HR, or management. Did they give you a nudge to align with business interests? Here's a surprising bit: 70% of AI professionals still see prompt engineering as essential, even as models get smarter (cite: AI Trends Journal). The smarter our tools, the sharper our prompts must be. Food for thought.\n",
      "```\n",
      "Rating: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply() # to run in jupyter notebook\n",
    "\n",
    "\n",
    "async def generate_and_evaluate_post(prompt, context):\n",
    "    response = await asyncio.to_thread(get_completion, prompt, context)\n",
    "    post_content = response.split(\"post_content:\")[1].strip()\n",
    "    evaluation = await asyncio.to_thread(evaluate_engagement, post_content, context[\"insight\"], context[\"social_network\"])\n",
    "    \n",
    "    # Parse the YAML output with regex\n",
    "    rating = int(re.findall(r'Rating: (\\d+)', evaluation)[0])\n",
    "    \n",
    "    return {\n",
    "        \"content\": post_content,\n",
    "        \"rating\": rating\n",
    "    }\n",
    "\n",
    "async def generate_and_rank_desc(prompt, context, num_posts=5):\n",
    "    tasks = [generate_and_evaluate_post(prompt, context) for _ in range(num_posts)]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    # Sort posts by rating in descending order\n",
    "    sorted_posts = sorted(results, key=lambda x: x[\"rating\"], reverse=True)\n",
    "    \n",
    "    return sorted_posts\n",
    "\n",
    "# Run the async function\n",
    "ranked_posts = asyncio.run(generate_and_rank_desc(examples_prompt, examples_context))\n",
    "\n",
    "# Print content and ratings for all posts\n",
    "for i, post in enumerate(ranked_posts, 1):\n",
    "    print(f\"Post {i}:\")\n",
    "    print(f\"Content: {post['content']}\")\n",
    "    print(f\"Rating: {post['rating']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Advanced Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A/B Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt A average rating: 4.20\n",
      "Prompt B average rating: 4.30\n"
     ]
    }
   ],
   "source": [
    "async def ab_test_prompts(prompt_a, prompt_b, context, num_runs=10):\n",
    "    tasks_a = [generate_and_evaluate_post(prompt_a, context) for _ in range(num_runs)]\n",
    "    tasks_b = [generate_and_evaluate_post(prompt_b, context) for _ in range(num_runs)]\n",
    "    \n",
    "    results_a = await asyncio.gather(*tasks_a)\n",
    "    results_b = await asyncio.gather(*tasks_b)\n",
    "\n",
    "    avg_rating_a = sum(post['rating'] for post in results_a) / len(results_a)\n",
    "    avg_rating_b = sum(post['rating'] for post in results_b) / len(results_b)\n",
    "\n",
    "    print(f\"Prompt A average rating: {avg_rating_a:.2f}\")\n",
    "    print(f\"Prompt B average rating: {avg_rating_b:.2f}\")\n",
    "\n",
    "    return results_a, results_b\n",
    "\n",
    "examples_prompt_b = \"\"\"\"Write a social media post about how {insight}, for {social_network}, in the style of Malcolm Tucker, using the Bait, Hook, Reward framework.\n",
    "\n",
    "- **bait**: Grab the attention of the person browsing social media. This could be a contrarian statement, appeal to identity, celebrity name, or anything else that stops them scrolling.\n",
    "- **hook**: Keep their attention now you have it. Show this post is relevant to them, by alerting them to an issue, using familiar words, or providing social proof to keep them reading.\n",
    "- **reward**: Compensate them for their attention to elicit reciprocation. Is there any useful information, a surprising statistic, or an interesting anecdote to reveal? Or a threat to make?\n",
    "- **post_content**: The main content of the post, incorporating the bait, hook, and reward in a way that resonates with the reader and engages their attention.\n",
    "\n",
    "First decide on the bait, hook, and reward, before writing the post_content.\n",
    "\n",
    "## Examples\n",
    "{examples_partial}\n",
    "\n",
    "## Instructions\n",
    "The social post should sound authentically human and colloquial, while being practically useful and brief. Be very creative and make niche references to sound more human. To maximize engagement, the content should be surprising, interesting, or practically useful, or induce high-arousal emotions such as anxiety, anger, awe, or surprise.\n",
    "\n",
    "Follow best practices for posting engaging content on {social_network}, but do not use emoji or hashtags.\n",
    "Provide citations for any statistics included. Do not reference the work of Malcolm Tucker.\n",
    "Respond in YAML with the following keys:\n",
    "- bait\n",
    "- hook\n",
    "- reward\n",
    "- post_content\"\"\"\n",
    "\n",
    "results_a, results_b = asyncio.run(ab_test_prompts(examples_prompt, examples_prompt_b, examples_context, num_runs=30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': \"Even the brightest minds need a kick in the arse sometimes. Think you're too smart for prompt engineering? Well, even Einstein had a bit of a nudge from reality, didn't he? Smarter models won't replace human intuition; they'll need direction like any genius on a caffeine bender. Prompt engineers, gear up. You're not out of a job yet! ðŸŽ¯\\n```\", 'rating': 5}\n"
     ]
    }
   ],
   "source": [
    "print(results_b[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSPy Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline post (without optimization):\n",
      "```\n",
      "content: \"Even the smartest AI models need prompt engineering. Just like genius humans need guidance from legal, HR, management to align with business interests, AI models need the same to ensure alignment with objectives. #AI #MachineLearning #PromptEngineering\"\n",
      "```\n",
      "Baseline post quality score: 4.0\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# Define the task using DSPy\n",
    "class SocialMediaPostGenerator(dspy.Signature):\n",
    "    \"\"\"Generate a social media post based on an insight and social network.\"\"\"\n",
    "    insight = dspy.InputField()\n",
    "    social_network = dspy.InputField()\n",
    "    post = dspy.OutputField(desc=\"Generated social media post in YAML format\")\n",
    "\n",
    "# Create a DSPy program\n",
    "class GeneratePost(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gen = dspy.ChainOfThought(SocialMediaPostGenerator)\n",
    "\n",
    "    def forward(self, insight, social_network):\n",
    "        return self.gen(insight=insight, social_network=social_network)\n",
    "\n",
    "# Create a DSPy metric\n",
    "def post_quality_metric(gold, pred, trace=None):\n",
    "    evaluation_result = evaluate_engagement(pred.post, gold.insight, gold.social_network)\n",
    "    \n",
    "    # Extract the rating from the YAML-formatted string using regex\n",
    "    try:\n",
    "        match = re.search(r'Rating:\\s*(\\d+(?:\\.\\d+)?)', evaluation_result)\n",
    "        if match:\n",
    "            rating = float(match.group(1))\n",
    "        else:\n",
    "            rating = 0.0\n",
    "        return rating\n",
    "    except:\n",
    "        # If there's any error in parsing, return 0\n",
    "        return 0.0\n",
    "\n",
    "# Set up the language model\n",
    "gpt_4o = dspy.OpenAI(model='gpt-4')\n",
    "dspy.settings.configure(lm=gpt_4o)\n",
    "\n",
    "# Run the model without training to establish a baseline\n",
    "baseline_model = GeneratePost()\n",
    "\n",
    "print(\"Baseline post (without optimization):\")\n",
    "baseline_post = baseline_model(\n",
    "    insight=context[\"insight\"],\n",
    "    social_network=context[\"social_network\"]\n",
    ")\n",
    "print(baseline_post.post)\n",
    "\n",
    "gold = dspy.Example(\n",
    "    insight=context[\"insight\"],\n",
    "    social_network=context[\"social_network\"],\n",
    "    post=\"\"  # We don't have a gold post, so leave it empty\n",
    ")\n",
    "\n",
    "print(\"Baseline post quality score:\", post_quality_metric(gold, baseline_post))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 40.0 / 10  (400.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:13<00:00,  1.31s/it]\n",
      "Average Metric: 38.0 / 10  (380.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:22<00:00,  2.28s/it]\n",
      " 20%|â–ˆâ–ˆ        | 4/20 [01:06<04:26, 16.67s/it]\n",
      "Average Metric: 37.25 / 10  (372.5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.39s/it]\n",
      " 20%|â–ˆâ–ˆ        | 4/20 [00:56<03:46, 14.15s/it]\n",
      "Average Metric: 46.0 / 10  (460.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:22<00:00,  2.23s/it]\n",
      " 10%|â–ˆ         | 2/20 [00:24<03:44, 12.45s/it]\n",
      "Average Metric: 46.0 / 10  (460.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:20<00:00,  2.10s/it]\n",
      "  5%|â–Œ         | 1/20 [00:13<04:24, 13.91s/it]\n",
      "Average Metric: 45.5 / 10  (455.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:32<00:00,  3.27s/it]\n",
      " 10%|â–ˆ         | 2/20 [00:32<04:50, 16.13s/it]\n",
      "Average Metric: 43.0 / 10  (430.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:27<00:00,  2.76s/it]\n",
      " 10%|â–ˆ         | 2/20 [00:31<04:47, 15.95s/it]\n",
      "Average Metric: 46.0 / 10  (460.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.15s/it]\n",
      " 15%|â–ˆâ–Œ        | 3/20 [00:48<04:36, 16.25s/it]\n",
      "Average Metric: 39.5 / 10  (395.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.55s/it]\n",
      "  5%|â–Œ         | 1/20 [00:13<04:16, 13.50s/it]\n",
      "Average Metric: 46.0 / 10  (460.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.10s/it]\n",
      " 15%|â–ˆâ–Œ        | 3/20 [00:45<04:18, 15.22s/it]\n",
      "Average Metric: 45.5 / 10  (455.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:29<00:00,  2.94s/it]\n",
      " 10%|â–ˆ         | 2/20 [00:28<04:20, 14.48s/it]\n",
      "Average Metric: 40.0 / 10  (400.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:31<00:00,  3.18s/it]\n",
      " 20%|â–ˆâ–ˆ        | 4/20 [00:55<03:40, 13.78s/it]\n",
      "Average Metric: 43.0 / 10  (430.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.30s/it]\n",
      "  5%|â–Œ         | 1/20 [00:13<04:08, 13.10s/it]\n",
      "Average Metric: 43.0 / 10  (430.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.11s/it]\n",
      " 20%|â–ˆâ–ˆ        | 4/20 [01:05<04:22, 16.39s/it]\n",
      "Average Metric: 47.0 / 10  (470.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.41s/it]\n",
      " 20%|â–ˆâ–ˆ        | 4/20 [00:55<03:41, 13.87s/it]\n",
      "Average Metric: 43.0 / 10  (430.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.16s/it]\n",
      " 15%|â–ˆâ–Œ        | 3/20 [00:40<03:49, 13.52s/it]\n",
      "Average Metric: 45.5 / 10  (455.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:28<00:00,  2.84s/it]\n",
      "  5%|â–Œ         | 1/20 [00:17<05:25, 17.11s/it]\n",
      "Average Metric: 45.0 / 10  (450.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.32s/it]\n",
      " 10%|â–ˆ         | 2/20 [00:26<04:02, 13.45s/it]\n",
      "Average Metric: 45.0 / 10  (450.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized post:\n",
      "\"Think smarter AI models will make prompt engineering obsolete? Think again, mate! Even Einstein needed a nudge from his boss. Just like your office genius needs a prod from legal, HR, and management to align with business goals, so do our AI models. Smarter doesn't mean self-sufficient. So, prompt engineers, keep your boots on. Your job isn't going anywhere!\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# Prepare the dataset\n",
    "trainset = [\n",
    "    dspy.Example(\n",
    "        insight=context['insight'],\n",
    "        social_network=context['social_network'],\n",
    "        post=post['content']\n",
    "    ).with_inputs('insight', 'social_network')\n",
    "    for post in results_b[:20]  # Use first 20 examples for training\n",
    "]\n",
    "\n",
    "devset = [\n",
    "    dspy.Example(\n",
    "        insight=context['insight'],\n",
    "        social_network=context['social_network'],\n",
    "        post=post['content']\n",
    "    ).with_inputs('insight', 'social_network')\n",
    "    for post in results_b[20:]  # Use remaining examples for validation\n",
    "]\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = BootstrapFewShotWithRandomSearch(metric=post_quality_metric)\n",
    "\n",
    "# Compile the program\n",
    "compiled_model = optimizer.compile(\n",
    "    GeneratePost(),\n",
    "    trainset=trainset,\n",
    "    valset=devset,\n",
    ")\n",
    "\n",
    "# Now you can use the compiled model to generate optimized posts\n",
    "optimized_post = compiled_model(\n",
    "    insight=context[\"insight\"],\n",
    "    social_network=context[\"social_network\"]\n",
    ")\n",
    "\n",
    "print(\"Optimized post:\")\n",
    "print(optimized_post.post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generate a social media post based on an insight and social network.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Insight: ${insight}\n",
      "\n",
      "Social Network: ${social_network}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the post}. We ...\n",
      "\n",
      "Post: Generated social media post in YAML format\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "Social Network: Twitter\n",
      "\n",
      "Reasoning: Let's think step by step in order to produce the post. We want to convey the importance of prompt engineering in the context of AI and business. We also want to use a relatable analogy to make the concept more understandable. The tone should be casual and engaging to appeal to a broad audience on Twitter.\n",
      "\n",
      "Post: \"Think AI is so smart it won't need prompt engineering? Think again, mate. Even the brightest minds in the biz need a nudge from legal, HR, and management to stay on track. Same goes for AI. No matter how smart the model, it still needs a prompt to align with business interests. So, keep your prompt engineering skills sharp, folks. They're not going anywhere.\"\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "Social Network: Twitter\n",
      "\n",
      "Reasoning: Let's think step by step in order to produce the post. We want to convey the importance of prompt engineering even as AI models become smarter. We'll use a relatable analogy of how even the most intelligent humans need guidance from various departments to align with business interests. We'll also add a touch of humor to make the post engaging and memorable.\n",
      "\n",
      "Post: \"Think smarter AI models will make prompt engineering obsolete? Think again, mate! Even Einstein needed a nudge from his boss. Just like your office genius needs a prod from legal, HR, and management to align with business goals, so do our AI models. Smarter doesn't mean self-sufficient. So, prompt engineers, keep your boots on. Your job isn't going anywhere!\"\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "Social Network: Twitter\n",
      "\n",
      "Reasoning: Let's think step by step in order to produce the post. We want to convey the importance of prompt engineering even as AI models become smarter. We'll use a comparison to genius humans who still need guidance from legal, HR, and management to align with business interests. We'll use a casual, conversational tone to engage our audience and make the topic more accessible.\n",
      "\n",
      "Post: \"Think smarter AI models mean we can ditch prompt engineering? Think again, mate! Even the brightest minds need a nudge from legal, HR, and management to stay on track. So, why wouldn't our AI? No matter how smart they get, they'll still need a guiding hand to align with business goals. So, keep your prompt engineering hat on, folks! We're not out of the woods\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "Social Network: Twitter\n",
      "\n",
      "Reasoning: Let's think step by step in order to produce the post. We want to convey the importance of prompt engineering even as AI models become smarter. We'll use the analogy of genius humans needing guidance from legal, HR, and management to align with business interests. We'll also use a bit of humor and a conversational tone to make the post engaging and relatable.\n",
      "\n",
      "Post: \"Think smarter AI models will make prompt engineering obsolete? Think again, mate! Even the brightest minds need a nudge from legal, HR, and management to align with business goals. So, why wouldn't our AI models need the same? Prompt engineering isn't going anywhere, folks. It's like the HR for AI - keeping things in line and on track. Ignore it at your own peril!\"\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "Social Network: Twitter\n",
      "Post: Even Einstein needed a bloody nudge now and then! If you think future AI won't need prompt engineers, you've lost the plot. Just like even your most brilliant exec needs a whisper from legal, HR, and management to stay on point, so will our wiz-kid AI. Prompt engineers will make sure these models align with business interests without flouting laws or stirring ethical hornets' nests. Ignore this at your peril, folks! ```\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "Social Network: Twitter\n",
      "Post: Even the smartest human can be a right berk if not guided properly. Imagine Einstein in an office: genius on the theory of relativity, but still needing HR to remind him not to nick your lunch from the breakroom. Like those human geniuses, smarter AI models need the right prompts to align with business goals. Better models don't mean we can skip prompt engineering - it means we need it even more! ```\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "Social Network: Twitter\n",
      "Post: Even Einstein needed a nudge. Just because the machines are getting smarter doesn't mean they can read your mind, pet. Better models still need a bit of wrangling, like human geniuses do. The secret sauce? Prompt engineers. Think of them as the modern-day 'corporate whisperers,' aligning AI with your business goals. Without them, you're just pissing into the wind. ```\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "Social Network: Twitter\n",
      "Post: Listen up, you digital buffoons! Even the sharpest minds still need to be nudged by legal or HR now and then. Think youâ€™re smarter than your own AI? Dream on. Smarter models arenâ€™t replacing prompt engineering anytime soonâ€”just like your genius schemes need someone to remind you not to get sued. Hold onto your prompts, folks. The gameâ€™s far from over. ```\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "Social Network: Twitter\n",
      "Post: \"Even Einstein needed a nudge! Smart models be damned! Just like even the sharpest minds in your office need a good kick from legal or HR to keep them in line, AI models will always need good prompting. You think you won't need prompt engineering? Here's the kicker: the better the model, the more critical the prompts. Stay sharp or get left behind!\" ```\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "Social Network: Twitter\n",
      "Post: \"Even Einstein needed a kick in the pants to stay on track. Ever seen a genius go off the rails? Even the smartest minds require direction from legal, HR, and management to align with business goals. Next-gen AI, no matter how sophisticated, will still need prompt engineers to keep it on the right pathâ€”much like humans need guidance to stay focused and compliant.\" ```\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "Social Network: Twitter\n",
      "Post: Even Einstein needed a kick up the arse sometimes. Smarter models won't wipe out prompt engineering. If you think the brainiest humans align with business goals on their own, youâ€™re deluding yourself. Brilliant minds need legal, HR, and management nudges to stay on course. Same goes for AIâ€”prompt engineers will always be needed to transform potential into perfection. ```\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "Social Network: Twitter\n",
      "Post: Right, even Einstein needed someone to tell him where the bloody toilets are. You think just because you've got an AI thatâ€™s smarter than a MENSA convention, it won't need any bloody guidance? Think again. Without prompt engineering, your fancy AI is about as useful as a chocolate teapot in a heatwave. Even the best minds need direction to align with business goals. ```\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "Social Network: Twitter\n",
      "Post: Listen up, you brainy bunch! Even Einstein needed a nudge from his boss. Just like masterminds need managers, smart models need prompt engineers to align their brilliance with business goals. Smarter models don't eliminate the need for precise directions; they amplify it. Stick around to keep your job relevant and the machines working for you. ```\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "Social Network: Twitter\n",
      "Post: Listen up, you muppets! Even Einstein needed a nudge! So you think smarter AI models will run your business seamlessly? Bollocks! Even the brightest spark needs prompting from legal, HR, and management to align with business goals. Here's the kicker: Smarter models still need sharp prompt engineers to keep things on track. Without them, you're just asking for a tech-led fustercluck.\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "Social Network: Twitter\n",
      "Post: Even Einstein needed a bloody nudge, so what makes you think AI won't? As our machines get smarter, the fallacy is believing theyâ€™ll self-align with your corporate vision. Take your aces in the office â€” they still need legal, HR, and management to keep them on the straight and narrow. Without expert prompting, even the brightest AI can veer off-course like a catapult mishap at a team-building event. Keep it sharp, keep it guided, keep it aligned. ```\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "Social Network: Twitter\n",
      "Post: Right, think you're too clever for prompt engineering? Bollocks. Even Einstein needed a nudge. Your gene-pool defying geniuses in that ivory tower still rely on HR to not start a legal fire. So why wouldn't our smarter-than-thou AI models also need an occasional kick up the circuits to stay aligned with business goals? Put that in your algorithm and smoke it. ```\n",
      "\n",
      "---\n",
      "\n",
      "Insight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\n",
      "\n",
      "Social Network: Twitter\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the post. We want to convey the importance of prompt engineering even as AI models become smarter. We'll use a relatable analogy of how even the most intelligent humans need guidance from various departments to align with business interests. We'll also add a touch of humor to make the post engaging and memorable.\n",
      "\n",
      "Post: \"Think smarter AI models will make prompt engineering obsolete? Think again, mate! Even Einstein needed a nudge from his boss. Just like your office genius needs a prod from legal, HR, and management to align with business goals, so do our AI models. Smarter doesn't mean self-sufficient. So, prompt engineers, keep your boots on. Your job isn't going anywhere!\"\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nGenerate a social media post based on an insight and social network.\\n\\n---\\n\\nFollow the following format.\\n\\nInsight: ${insight}\\n\\nSocial Network: ${social_network}\\n\\nReasoning: Let\\'s think step by step in order to ${produce the post}. We ...\\n\\nPost: Generated social media post in YAML format\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\n\\nSocial Network: Twitter\\n\\nReasoning: Let\\'s think step by step in order to produce the post. We want to convey the importance of prompt engineering in the context of AI and business. We also want to use a relatable analogy to make the concept more understandable. The tone should be casual and engaging to appeal to a broad audience on Twitter.\\n\\nPost: \"Think AI is so smart it won\\'t need prompt engineering? Think again, mate. Even the brightest minds in the biz need a nudge from legal, HR, and management to stay on track. Same goes for AI. No matter how smart the model, it still needs a prompt to align with business interests. So, keep your prompt engineering skills sharp, folks. They\\'re not going anywhere.\"\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\n\\nSocial Network: Twitter\\n\\nReasoning: Let\\'s think step by step in order to produce the post. We want to convey the importance of prompt engineering even as AI models become smarter. We\\'ll use a relatable analogy of how even the most intelligent humans need guidance from various departments to align with business interests. We\\'ll also add a touch of humor to make the post engaging and memorable.\\n\\nPost: \"Think smarter AI models will make prompt engineering obsolete? Think again, mate! Even Einstein needed a nudge from his boss. Just like your office genius needs a prod from legal, HR, and management to align with business goals, so do our AI models. Smarter doesn\\'t mean self-sufficient. So, prompt engineers, keep your boots on. Your job isn\\'t going anywhere!\"\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\n\\nSocial Network: Twitter\\n\\nReasoning: Let\\'s think step by step in order to produce the post. We want to convey the importance of prompt engineering even as AI models become smarter. We\\'ll use a comparison to genius humans who still need guidance from legal, HR, and management to align with business interests. We\\'ll use a casual, conversational tone to engage our audience and make the topic more accessible.\\n\\nPost: \"Think smarter AI models mean we can ditch prompt engineering? Think again, mate! Even the brightest minds need a nudge from legal, HR, and management to stay on track. So, why wouldn\\'t our AI? No matter how smart they get, they\\'ll still need a guiding hand to align with business goals. So, keep your prompt engineering hat on, folks! We\\'re not out of the woods\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\n\\nSocial Network: Twitter\\n\\nReasoning: Let\\'s think step by step in order to produce the post. We want to convey the importance of prompt engineering even as AI models become smarter. We\\'ll use the analogy of genius humans needing guidance from legal, HR, and management to align with business interests. We\\'ll also use a bit of humor and a conversational tone to make the post engaging and relatable.\\n\\nPost: \"Think smarter AI models will make prompt engineering obsolete? Think again, mate! Even the brightest minds need a nudge from legal, HR, and management to align with business goals. So, why wouldn\\'t our AI models need the same? Prompt engineering isn\\'t going anywhere, folks. It\\'s like the HR for AI - keeping things in line and on track. Ignore it at your own peril!\"\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\nSocial Network: Twitter\\nPost: Even Einstein needed a bloody nudge now and then! If you think future AI won\\'t need prompt engineers, you\\'ve lost the plot. Just like even your most brilliant exec needs a whisper from legal, HR, and management to stay on point, so will our wiz-kid AI. Prompt engineers will make sure these models align with business interests without flouting laws or stirring ethical hornets\\' nests. Ignore this at your peril, folks! ```\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\nSocial Network: Twitter\\nPost: Even the smartest human can be a right berk if not guided properly. Imagine Einstein in an office: genius on the theory of relativity, but still needing HR to remind him not to nick your lunch from the breakroom. Like those human geniuses, smarter AI models need the right prompts to align with business goals. Better models don\\'t mean we can skip prompt engineering - it means we need it even more! ```\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\nSocial Network: Twitter\\nPost: Even Einstein needed a nudge. Just because the machines are getting smarter doesn\\'t mean they can read your mind, pet. Better models still need a bit of wrangling, like human geniuses do. The secret sauce? Prompt engineers. Think of them as the modern-day \\'corporate whisperers,\\' aligning AI with your business goals. Without them, you\\'re just pissing into the wind. ```\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\nSocial Network: Twitter\\nPost: Listen up, you digital buffoons! Even the sharpest minds still need to be nudged by legal or HR now and then. Think youâ€™re smarter than your own AI? Dream on. Smarter models arenâ€™t replacing prompt engineering anytime soonâ€”just like your genius schemes need someone to remind you not to get sued. Hold onto your prompts, folks. The gameâ€™s far from over. ```\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\nSocial Network: Twitter\\nPost: \"Even Einstein needed a nudge! Smart models be damned! Just like even the sharpest minds in your office need a good kick from legal or HR to keep them in line, AI models will always need good prompting. You think you won\\'t need prompt engineering? Here\\'s the kicker: the better the model, the more critical the prompts. Stay sharp or get left behind!\" ```\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\nSocial Network: Twitter\\nPost: \"Even Einstein needed a kick in the pants to stay on track. Ever seen a genius go off the rails? Even the smartest minds require direction from legal, HR, and management to align with business goals. Next-gen AI, no matter how sophisticated, will still need prompt engineers to keep it on the right pathâ€”much like humans need guidance to stay focused and compliant.\" ```\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\nSocial Network: Twitter\\nPost: Even Einstein needed a kick up the arse sometimes. Smarter models won\\'t wipe out prompt engineering. If you think the brainiest humans align with business goals on their own, youâ€™re deluding yourself. Brilliant minds need legal, HR, and management nudges to stay on course. Same goes for AIâ€”prompt engineers will always be needed to transform potential into perfection. ```\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\nSocial Network: Twitter\\nPost: Right, even Einstein needed someone to tell him where the bloody toilets are. You think just because you\\'ve got an AI thatâ€™s smarter than a MENSA convention, it won\\'t need any bloody guidance? Think again. Without prompt engineering, your fancy AI is about as useful as a chocolate teapot in a heatwave. Even the best minds need direction to align with business goals. ```\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\nSocial Network: Twitter\\nPost: Listen up, you brainy bunch! Even Einstein needed a nudge from his boss. Just like masterminds need managers, smart models need prompt engineers to align their brilliance with business goals. Smarter models don\\'t eliminate the need for precise directions; they amplify it. Stick around to keep your job relevant and the machines working for you. ```\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\nSocial Network: Twitter\\nPost: Listen up, you muppets! Even Einstein needed a nudge! So you think smarter AI models will run your business seamlessly? Bollocks! Even the brightest spark needs prompting from legal, HR, and management to align with business goals. Here\\'s the kicker: Smarter models still need sharp prompt engineers to keep things on track. Without them, you\\'re just asking for a tech-led fustercluck.\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\nSocial Network: Twitter\\nPost: Even Einstein needed a bloody nudge, so what makes you think AI won\\'t? As our machines get smarter, the fallacy is believing theyâ€™ll self-align with your corporate vision. Take your aces in the office â€” they still need legal, HR, and management to keep them on the straight and narrow. Without expert prompting, even the brightest AI can veer off-course like a catapult mishap at a team-building event. Keep it sharp, keep it guided, keep it aligned. ```\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\nSocial Network: Twitter\\nPost: Right, think you\\'re too clever for prompt engineering? Bollocks. Even Einstein needed a nudge. Your gene-pool defying geniuses in that ivory tower still rely on HR to not start a legal fire. So why wouldn\\'t our smarter-than-thou AI models also need an occasional kick up the circuits to stay aligned with business goals? Put that in your algorithm and smoke it. ```\\n\\n---\\n\\nInsight: prompt engineering will still be needed with smarter models, as even genius humans need prompting from legal, HR, management to align with business interests\\n\\nSocial Network: Twitter\\n\\nReasoning: Let\\'s think step by step in order to\\x1b[32m produce the post. We want to convey the importance of prompt engineering even as AI models become smarter. We\\'ll use a relatable analogy of how even the most intelligent humans need guidance from various departments to align with business interests. We\\'ll also add a touch of humor to make the post engaging and memorable.\\n\\nPost: \"Think smarter AI models will make prompt engineering obsolete? Think again, mate! Even Einstein needed a nudge from his boss. Just like your office genius needs a prod from legal, HR, and management to align with business goals, so do our AI models. Smarter doesn\\'t mean self-sufficient. So, prompt engineers, keep your boots on. Your job isn\\'t going anywhere!\"\\x1b[0m\\n\\n\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_4o.inspect_history(n=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job created with ID: ftjob-uocuzf7OvRail2ldYBrg56Sm\n",
      "Job status: validating_files\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Format the data for fine-tuning\n",
    "fine_tuning_data = []\n",
    "for post in results_b:\n",
    "    example = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": examples_prompt.format(**examples_context)},\n",
    "            {\"role\": \"assistant\", \"content\": post['content']}\n",
    "        ]\n",
    "    }\n",
    "    fine_tuning_data.append(example)\n",
    "\n",
    "# Write the formatted data to a JSONL file\n",
    "with open(\"fine_tuning_data.jsonl\", \"w\") as f:\n",
    "    for entry in fine_tuning_data:\n",
    "        json.dump(entry, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Upload the file\n",
    "file = client.files.create(\n",
    "    file=open(\"fine_tuning_data.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "# Create a fine-tuning job\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=file.id,\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(f\"Fine-tuning job created with ID: {job.id}\")\n",
    "\n",
    "# You can check the status of your fine-tuning job\n",
    "print(f\"Job status: {job.status}\")\n",
    "\n",
    "# Note: The fine-tuning process may take some time to complete.\n",
    "# You'll need to periodically check the status of the job to know when it's done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-uocuzf7OvRail2ldYBrg56Sm', created_at=1721668814, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-TngE7qVdaABr9bFqdNNsRarE', result_files=[], status='running', trained_tokens=None, training_file='file-gwjRc9lC7zwNhWSPjsLK1GNJ', validation_file=None, user_provided_suffix=None, seed=1896163601, estimated_finish=None, integrations=[])], object='list', has_more=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list(limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model: gpt-3.5-turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model: gpt-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:19<00:00,  7.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model: ft:gpt-3.5-turbo-0125:saxifrage-llc::9lzyYgCb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:28<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Engagement Evaluation Results:\n",
      "gpt-3.5-turbo: 3.80\n",
      "Top 3 posts:\n",
      "  1. Score: 4.00\n",
      "     Post: - bait: \"Even genius humans need a little nudge sometimes.\"\n",
      "- hook: Prompt engineering is still cruc...\n",
      "  2. Score: 4.00\n",
      "     Post: ```yaml\n",
      "bait: Contrary to popular belief, even genius humans need prompting.\n",
      "hook: Legal, HR, and ma...\n",
      "  3. Score: 4.00\n",
      "     Post: bait: Even the smartest engineers need a nudge.\n",
      "hook: Legal, HR, and management play a crucial role ...\n",
      "gpt-4: 4.50\n",
      "Top 3 posts:\n",
      "  1. Score: 5.00\n",
      "     Post: - bait: Open discussion with fascinating comparison between high-tech AI models and brilliant, creat...\n",
      "  2. Score: 5.00\n",
      "     Post: bait: A radical take on artificial intelligence.\n",
      "hook: Involving prompt engineering and its correlat...\n",
      "  3. Score: 5.00\n",
      "     Post: bait: Mentioning the hot topic of AI and the misconception of its independence.\n",
      "hook: Draw a paralle...\n",
      "ft:gpt-3.5-turbo-0125:saxifrage-llc::9lzyYgCb: 4.20\n",
      "Top 3 posts:\n",
      "  1. Score: 5.00\n",
      "     Post: Here's a hot take for you: Even Einstein needed the occasional nudge to stop him from wandering off ...\n",
      "  2. Score: 5.00\n",
      "     Post: \"Even Einstein needed a nudge â€“ well, just think of next-gen AI as little Einsteins. Here's the kick...\n",
      "  3. Score: 4.00\n",
      "     Post: Sure, let's cut straight to the chase. Even Einstein couldn't remember where he put his socks withou...\n",
      "\n",
      "Best performing model: gpt-4 with an average engagement score of 4.50\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get the last fine-tuned model\n",
    "fine_tuning_jobs = client.fine_tuning.jobs.list(limit=1)\n",
    "if fine_tuning_jobs.data:\n",
    "    last_job = fine_tuning_jobs.data[0]\n",
    "    while last_job.status != \"succeeded\":\n",
    "        print(f\"Waiting for fine-tuning job to complete. Current status: {last_job.status}\")\n",
    "        time.sleep(60)  # Wait for 60 seconds before checking again\n",
    "        last_job = client.fine_tuning.jobs.retrieve(last_job.id)\n",
    "    \n",
    "    fine_tuned_model = last_job.fine_tuned_model\n",
    "    print(f\"Using fine-tuned model: {fine_tuned_model}\")\n",
    "else:\n",
    "    print(\"No fine-tuning jobs found. Please run the fine-tuning process first.\")\n",
    "    fine_tuned_model = None\n",
    "\n",
    "# fine_tuned_model = \"ft:gpt-3.5-turbo-0125:saxifrage-llc::9lzyYgCb\"\n",
    "\n",
    "models_to_compare = [\"gpt-3.5-turbo\", \"gpt-4\", fine_tuned_model]\n",
    "models_to_compare = [model for model in models_to_compare if model]  # Remove None if fine-tuned model is not available\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model in models_to_compare:\n",
    "    print(f\"\\nEvaluating model: {model}\")\n",
    "    posts = []\n",
    "    for _ in tqdm(range(10)):  # Generate 10 posts for each model\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": examples_prompt.format(**examples_context)}\n",
    "            ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "        posts.append(response.choices[0].message.content)\n",
    "    \n",
    "    # Evaluate engagement for the generated posts\n",
    "    def parse_engagement_score(response):\n",
    "        match = re.search(r'Rating:\\s*(\\d+(?:\\.\\d+)?)', response)\n",
    "        if match:\n",
    "            return float(match.group(1))\n",
    "        return 0.0  # Default to 0 if no match found\n",
    "\n",
    "    engagement_scores = []\n",
    "    for post in posts:\n",
    "        score = parse_engagement_score(evaluate_engagement(post, context[\"insight\"], context[\"social_network\"]))\n",
    "        engagement_scores.append({\"post\": post, \"score\": score})\n",
    "    \n",
    "    average_score = sum(item[\"score\"] for item in engagement_scores) / len(engagement_scores)\n",
    "    results[model] = {\"average_score\": average_score, \"posts\": engagement_scores}\n",
    "\n",
    "# Print results\n",
    "print(\"\\nEngagement Evaluation Results:\")\n",
    "for model, data in results.items():\n",
    "    print(f\"{model}: {data['average_score']:.2f}\")\n",
    "    print(\"Top 3 posts:\")\n",
    "    top_posts = sorted(data['posts'], key=lambda x: x['score'], reverse=True)[:3]\n",
    "    for i, post_data in enumerate(top_posts, 1):\n",
    "        print(f\"  {i}. Score: {post_data['score']:.2f}\")\n",
    "        print(f\"     Post: {post_data['post'][:100]}...\")  # Print first 100 characters of the post\n",
    "\n",
    "# Determine the best performing model\n",
    "best_model = max(results, key=lambda x: results[x]['average_score'])\n",
    "print(f\"\\nBest performing model: {best_model} with an average engagement score of {results[best_model]['average_score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post': 'Sure, let\\'s cut straight to the chase. Even Einstein couldn\\'t remember where he put his socks without a nudge. Smarter AI models still need the human touch of prompt engineering, just like how you get a gentle reminder from legal, HR, or management. Without it, these advanced models can go rogue and contradict business interests faster than you can say \"algorithm\". Master the art of prompt engineering or prepare for chaos.\\n```',\n",
       " 'score': 4.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['ft:gpt-3.5-turbo-0125:saxifrage-llc::9lzyYgCb']['posts'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
