{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjvV7jJ45z4I"
      },
      "source": [
        "Source: https://www.pinecone.io/learn/openai-gen-qa/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxORK4FaMcsI"
      },
      "outputs": [],
      "source": [
        "%pip install -qU openai pinecone datasets cohere tiktoken --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1aROn2v57nB"
      },
      "outputs": [],
      "source": [
        "# Get the openai secret key\n",
        "import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass.getpass('Please enter your openai key: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiA3F9lU52jw"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Get API key from top-right dropdown on OpenAI website\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "MODEL = \"gpt-4.1-mini\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYQnXTcV6MBY"
      },
      "outputs": [],
      "source": [
        "query = \"who was the 12th person on the moon and when did they land?\"\n",
        "\n",
        "# Now query WITHOUT context\n",
        "res = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": query,\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "res.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJ2ibIyX6PHR"
      },
      "outputs": [],
      "source": [
        "# First let's make it simpler to get answers\n",
        "def complete(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "query = (\n",
        "    \"Which training method should I use for sentence transformers when \" +\n",
        "    \"I only have pairs of related sentences?\"\n",
        ")\n",
        "\n",
        "complete(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8G83i3cE6VNx"
      },
      "outputs": [],
      "source": [
        "# Use OpenAI's text embedding model\n",
        "embed_model = \"text-embedding-3-small\"\n",
        "\n",
        "res = client.embeddings.create(\n",
        "    input=[\n",
        "        \"Sample document text goes here\",\n",
        "        \"there will be several phrases in each batch\"\n",
        "    ],\n",
        "    model=embed_model\n",
        ")\n",
        "\n",
        "# Vector embeddings for each document\n",
        "res.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PG76DgVx6Ykp"
      },
      "outputs": [],
      "source": [
        "# We have created two vectors (one for each sentence input)\n",
        "len(res.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoCcRCSz6bDh"
      },
      "outputs": [],
      "source": [
        "# We have created two 1536-dimensional vectors\n",
        "len(res.data[0].embedding), len(res.data[1].embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsDlqGVeQ1NH"
      },
      "outputs": [],
      "source": [
        "# We can also get the vector for a single sentence\n",
        "res.data[0].embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE9yGmGc6dnJ"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data = load_dataset('jamescalam/youtube-transcriptions', split='train')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2flD74a6fCZ"
      },
      "outputs": [],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqZcBAWg6gtB"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "new_data = []\n",
        "\n",
        "window = 20  # number of sentences to combine\n",
        "stride = 4  # number of sentences to 'stride' over, used to create overlap\n",
        "\n",
        "for i in tqdm(range(0, len(data), stride)):\n",
        "    i_end = min(len(data)-1, i+window)\n",
        "    if data[i]['title'] != data[i_end]['title']:\n",
        "        # in this case we skip this entry as we have start/end of two videos\n",
        "        continue\n",
        "    text = ' '.join(data[i:i_end]['text'])\n",
        "    # create the new merged dataset\n",
        "    new_data.append({\n",
        "        'start': data[i]['start'],\n",
        "        'end': data[i_end]['end'],\n",
        "        'title': data[i]['title'],\n",
        "        'text': text,\n",
        "        'id': data[i]['id'],\n",
        "        'url': data[i]['url'],\n",
        "        'published': data[i]['published'],\n",
        "        'channel_id': data[i]['channel_id']\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFj8AH5E6ibZ"
      },
      "outputs": [],
      "source": [
        "new_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtvqPDnF6rlw"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "import os\n",
        "\n",
        "PINECONE_API_KEY = getpass.getpass(\"Please enter your pinecone key: \")\n",
        "\n",
        "# Initialize connection (get API key at app.pinecone.io):\n",
        "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suHuS4Tw6lFJ"
      },
      "outputs": [],
      "source": [
        "index_name = \"employee-handbook\"\n",
        "pc = Pinecone()  # This reads the PINECONE_API_KEY env var\n",
        "\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=1536,  # Using the same vector dimensions as text-embedding-ada-002\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbYXHc_VMcsM"
      },
      "outputs": [],
      "source": [
        "# Connect to Index:\n",
        "index = pc.Index(name=index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHEvVt_jMcsM"
      },
      "outputs": [],
      "source": [
        "# Describe the Index:\n",
        "description = pc.describe_index(name=index_name)\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGMbYLNP6y4J"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import datetime\n",
        "import time\n",
        "from time import sleep\n",
        "\n",
        "# Wait for the index to be ready\n",
        "while not pc.describe_index(index_name).status['ready']:\n",
        "    time.sleep(1)\n",
        "\n",
        "batch_size = 100  # how many embeddings we create and insert at once\n",
        "\n",
        "for i in tqdm(range(0, len(new_data), batch_size)):\n",
        "    # find end of batch\n",
        "    i_end = min(len(new_data), i+batch_size)\n",
        "    meta_batch = new_data[i:i_end]\n",
        "\n",
        "    # get texts to encode\n",
        "    texts = [x['text'] for x in meta_batch]\n",
        "\n",
        "    # create embeddings (try-except added to avoid RateLimitError)\n",
        "    try:\n",
        "        res = client.embeddings.create(input=texts, model=embed_model)\n",
        "    except:\n",
        "        done = False\n",
        "        while not done:\n",
        "            sleep(5)\n",
        "            try:\n",
        "                res = client.embeddings.create(input=texts, model=embed_model)\n",
        "                done = True\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    # prepare vectors for upsert\n",
        "    vectors = []\n",
        "    for data, embedding in zip(meta_batch, res.data):\n",
        "        vectors.append({\n",
        "            \"id\": data['id'],\n",
        "            \"values\": embedding.embedding,\n",
        "            \"metadata\": {\n",
        "                'start': data['start'],\n",
        "                'end': data['end'],\n",
        "                'title': data['title'],\n",
        "                'text': data['text'],\n",
        "                'url': data['url'],\n",
        "                'published': data['published'],\n",
        "                'channel_id': data['channel_id']\n",
        "            }\n",
        "        })\n",
        "\n",
        "    # Upsert to Pinecone\n",
        "    index.upsert(vectors=vectors, namespace=\"ns1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwcYwF71601h"
      },
      "outputs": [],
      "source": [
        "res = client.embeddings.create(\n",
        "    input=[query],\n",
        "    model=embed_model\n",
        ")\n",
        "\n",
        "# retrieve from Pinecone\n",
        "xq = res.data[0].embedding\n",
        "\n",
        "# get relevant contexts (including the questions)\n",
        "res = index.query(namespace=\"ns1\", vector=xq, top_k=2, include_metadata=True)\n",
        "\n",
        "# Print search results in a readable format\n",
        "print(\"Search results:\")\n",
        "print(\"-\" * 80)\n",
        "for i, match in enumerate(res['matches'], 1):\n",
        "    print(f\"\\nMatch {i} (Score: {match['score']:.3f})\")\n",
        "    print(f\"ID: {match['id']}\")\n",
        "    print(\"\\nMetadata:\")\n",
        "    print(f\"  Title: {match['metadata']['title']}\")\n",
        "    print(f\"  Time: {match['metadata']['start']:.1f}s - {match['metadata']['end']:.1f}s\")\n",
        "    print(f\"  URL: {match['metadata']['url']}\")\n",
        "    print(f\"  Published: {match['metadata']['published']}\")\n",
        "    print(\"\\nText:\")\n",
        "    print(\"  \" + match['metadata']['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeSJK-LC63gZ"
      },
      "outputs": [],
      "source": [
        "limit = 3750\n",
        "\n",
        "def retrieve(query):\n",
        "    res = client.embeddings.create(\n",
        "        input=[query],\n",
        "        model=embed_model\n",
        "    )\n",
        "\n",
        "    # retrieve from Pinecone\n",
        "    xq = res.data[0].embedding\n",
        "\n",
        "    # get relevant contexts\n",
        "    res = index.query(namespace=\"ns1\", vector=xq, top_k=3, include_metadata=True)\n",
        "    contexts = [\n",
        "        x['metadata']['text'] for x in res['matches']\n",
        "    ]\n",
        "\n",
        "    # build our prompt with the retrieved contexts included\n",
        "    prompt_start = (\n",
        "        \"Answer the question based on the context below.\\n\\n\"+\n",
        "        \"Context:\\n\"\n",
        "    )\n",
        "    prompt_end = (\n",
        "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
        "    )\n",
        "\n",
        "    # Initialize prompt with all contexts\n",
        "    prompt = (\n",
        "        prompt_start +\n",
        "        \"\\n\\n---\\n\\n\".join(contexts) +\n",
        "        prompt_end\n",
        "    )\n",
        "\n",
        "    # If total length exceeds limit, reduce contexts one by one\n",
        "    for i in range(len(contexts)-1, 0, -1):\n",
        "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) < limit:\n",
        "            prompt = (\n",
        "                prompt_start +\n",
        "                \"\\n\\n---\\n\\n\".join(contexts[:i]) +\n",
        "                prompt_end\n",
        "            )\n",
        "            break\n",
        "\n",
        "    return prompt\n",
        "\n",
        "# First we retrieve relevant items from Pinecone\n",
        "query_with_contexts = retrieve(query)\n",
        "print(query_with_contexts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeySU_cB687P"
      },
      "outputs": [],
      "source": [
        "# Then we complete the context-infused query\n",
        "print(complete(query_with_contexts))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}